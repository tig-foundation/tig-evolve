{
  "id": "c5447a3c-eb69-497d-a1ff-8e5b0fa7bf89",
  "idea": {
    "description": "Hybrid Memetic Algorithm integrating local search within Genetic Algorithm for Quadratic Knapsack Problem.",
    "motivation": "Integrating local search techniques to refine solution quality and avoid local optima.",
    "implementation_notes": "Use multiple-neighborhood tabu search for local optimization. Regularly evaluate interactions using pairwise matrices. Employ hyperparameter optimization techniques for tuning performance.",
    "pseudocode": "fn memetic_algorithm(weights, values, interaction_values, max_weight) {\n    pop = initialize_population();\n    while !converged {\n        eval_population(pop);\n        parents = select_parents(pop);\n        offspring = crossover(parents);\n        apply_mutation(offspring);\n        local_search(offspring);\n        pop = select_next_population(pop, offspring);\n    }\n    return best_solution(pop);\n}",
    "originality": {
      "score": 8,
      "positive": "The idea uniquely integrates local search refinements into a traditional GA.",
      "negative": "Similar hybrid approaches exist but may not be tailored to QKP specifics."
    },
    "future_potential": {
      "score": 9,
      "positive": "The approach is likely to spark further research and improvement in QKP optimization, especially in hyperparameter tuning and local search strategies.",
      "negative": "The performance may hinge on effective parameter tuning."
    },
    "code_difficulty": {
      "score": 6,
      "positive": "Conceptually clear and can be implemented incrementally, especially with defined steps for local optimization.",
      "negative": "Requires a solid understanding of both GA and local search techniques."
    }
  },
  "timestamp": 1765883655.8773682,
  "parent_id": "fcdeec5f-3b0e-4f29-826f-c4cf63f074c0",
  "evolution_history": [
    {
      "description": "Using a Genetic Algorithm with Interaction Scoring approach to solve the QKP, leveraging item synergies while maintaining a focus on item values and weights. The method aligns closely with findings from the Breakpoints Algorithm and linearization techniques.",
      "motivation": "The combination allows for exploring solutions beyond simple heuristics by assessing item interactions alongside their individual contributions, aiming for superior total value while emphasizing scalability and efficiency.",
      "implementation_notes": "Adopt a structured framework to ensure easy traversal of solution spaces using genetic approaches, evaluating item interactions efficiently during each population assessment. Incorporate advanced techniques such as those found in the Breakpoints Algorithm for additional scalability and effectiveness.",
      "pseudocode": "function genetic_algorithm(interaction_values, weights, values, max_weight):\n    population = initialize_population()\n    for generation in range(MAX_GENERATIONS):\n        scores = evaluate_population(population, interaction_values, weights, values)\n        parents = select_parents(population, scores)\n        offspring = crossover_and_mutate(parents)\n        population = replacement_strategy(population, offspring)\n    return best_solution(population)",
      "originality": {
        "score": 8,
        "positive": "Novel integration of interaction values into a genetic approach, enhancing solution quality over standard greedy methods, with appropriate support from existing literature like the Breakpoints Algorithm.",
        "negative": "Building on existing concepts of genetic algorithms means it may not seem entirely novel."
      },
      "future_potential": {
        "score": 9,
        "positive": "Offers a strong foundation for future enhancements and explorations into hybrid models, promising broader applications in similar problems across various scales.",
        "negative": "Implementation complexity may pose challenges, limiting immediate usability."
      },
      "code_difficulty": {
        "score": 7,
        "positive": "While relatively straightforward in concept, the intricacies of maintaining population diversity and interaction evaluations may complicate the codebase, requiring diligent management of solution dynamics.",
        "negative": "Efficient implementation requires robust handling of the population and evaluation metrics, which may increase initial development time."
      }
    },
    {
      "description": "Hybrid Memetic Algorithm integrating local search within Genetic Algorithm for Quadratic Knapsack Problem.",
      "motivation": "Integrating local search techniques to refine solution quality and avoid local optima.",
      "implementation_notes": "Use multiple-neighborhood tabu search for local optimization. Regularly evaluate interactions using pairwise matrices. Employ hyperparameter optimization techniques for tuning performance.",
      "pseudocode": "fn memetic_algorithm(weights, values, interaction_values, max_weight) {\n    pop = initialize_population();\n    while !converged {\n        eval_population(pop);\n        parents = select_parents(pop);\n        offspring = crossover(parents);\n        apply_mutation(offspring);\n        local_search(offspring);\n        pop = select_next_population(pop, offspring);\n    }\n    return best_solution(pop);\n}",
      "originality": {
        "score": 8,
        "positive": "The idea uniquely integrates local search refinements into a traditional GA.",
        "negative": "Similar hybrid approaches exist but may not be tailored to QKP specifics."
      },
      "future_potential": {
        "score": 9,
        "positive": "The approach is likely to spark further research and improvement in QKP optimization, especially in hyperparameter tuning and local search strategies.",
        "negative": "The performance may hinge on effective parameter tuning."
      },
      "code_difficulty": {
        "score": 6,
        "positive": "Conceptually clear and can be implemented incrementally, especially with defined steps for local optimization.",
        "negative": "Requires a solid understanding of both GA and local search techniques."
      }
    }
  ],
  "iteration_found": 2,
  "metrics": {
    "combined_score": 0.0
  },
  "metadata": {
    "parent_metrics": {
      "combined_score": 0.0
    },
    "island": 0
  },
  "language": "rust",
  "report": "# Evolved Algorithm for Quadratic Knapsack Problem (QKP)\n\n## Synthesis of Insights and Proposed Directions\nThe Quadratic Knapsack Problem (QKP) presents a significant challenge in combinatorial optimization, focusing on both item values and complex pairwise interactions. Our starting approach leverages a Genetic Algorithm (GA) combined with Interaction Scoring, influenced by methods such as the Breakpoints Algorithm and Quantum-Inspired approaches. Below are insights drawn from prior works:\n\n### Insights from the Starting Point\n1. **Genetic Algorithm Foundation**: GAs utilize selection, crossover, and mutation to iteratively improve solutions. By introducing interaction scoring, the genetic operations can better capture item synergies that can lead to higher total values.\n2. **Hybridization Potential**: Incorporating elements from both local optimization strategies and metaheuristics can enhance exploration capabilities and solution refinement.\n3. **Importance of Synergies**: The need to consider item interactions is critical to maximizing total value, highlighting that traditional value-based evaluations may inadequately reflect true value generation from synergistic item combinations.\n\n### Insights from Related Works\n1. **Hybrid Optimization Techniques**: Studies show that hybrid algorithms combining evolutionary strategies with local search yield compelling results. For example, a memetic algorithm framework efficiently optimizes knapsack solutions by blending exploration with local search refinements.\n2. **Parameter Tuning in GAs**: Research indicates that optimal settings for genetic parameters dramatically affect performance, particularly in QKP instances where synergies drive value aggregation. Important parameters to consider include population size, crossover rate, mutation rate, selection strategy, and termination criteria.\n3. **Dynamic Programming Heuristics**: Recent approaches have shown significant gains in solution quality by considering the cooperative effects of selected items, leading to near-optimal solutions quicker than traditional methods.\n\n## Organized Research Directions\nBased on the insights, we organize the directions into the following actionable categories:\n1. **Improved Synergy Modeling**\n   - Implement Choquet integrals to quantify interactions.\n2. **Hybrid Algorithms**\n   - Integrate GAs with local search techniques, such as tabu search and dynamic programming heuristics.\n3. **Parameter Optimization**\n   - Explore parameter tuning techniques to enhance GA performance based on varying input scenarios, utilizing methods like Bayesian optimization and adaptive hyperheuristic frameworks.\n\n## Structured Framework of Existing Methods\nA taxonomy of approaches can be created as follows:\n- **Heuristic Approaches**\n  - Dynamic Programming Heuristics\n  - Breakpoints Algorithm\n- **Metaheuristic Frameworks**\n  - Basic Genetic Algorithm\n  - Memetic Algorithms\n  - Hybrid Evolutionary Algorithms\n- **Quantum-Inspired and Advanced Techniques**\n  - Quantum Approximate Optimization Algorithm\n  - Extended Ising Machine\n\n## Generated and Evaluated Ideas\nHere are several algorithmic concepts for further development:\n\n### Proposed Ideas\n1. **GA with Choquet Integral Synergy**\n   - **Pseudocode**:\n     ```rust\n     for each generation:\n         evaluate fitness using Choquet integral\n         select parents\n         apply crossover and mutation\n     ```\n   - **Assessment**: Originality (7), Future Potential (9), Code Difficulty (5)\n\n2. **Hybrid Memetic Algorithm with Local Search**\n   - **Pseudocode**:\n     ```rust\n     while not converged:\n         conduct local search on offspring\n         evolve via GA adjustments\n     ```\n   - **Assessment**: Originality (8), Future Potential (9), Code Difficulty (6)\n\n3. **Dynamic Programming Enhanced GA**\n   - **Pseudocode**:\n     ```rust\n     incorporate DP to enhance selected solutions during evaluations\n     ```\n   - **Assessment**: Originality (6), Future Potential (7), Code Difficulty (7)\n\n4. **Quantum-Inspired GA for Synergy Optimization**\n   - **Pseudocode**:\n     ```rust\n     adapt quantum principles in selection process\n     ```\n   - **Assessment**: Originality (9), Future Potential (8), Code Difficulty (8)\n\n5. **Parameter Optimized Genetic Algorithm**\n   - **Pseudocode**:\n     ```rust\n     initialize parameters using adaptive tuning\n     for each run:\n        adapt parameters based on performance feedback\n     ```\n   - **Assessment**: Originality (7), Future Potential (6), Code Difficulty (4)\n\n### Selected Best Idea\n**Hybrid Memetic Algorithm with Local Search** is selected due to its balance of innovation and feasibility within current research progress (10%).\n\n#### Detailed Description\n- **Motivation**: Integrating local search techniques within the GA framework addresses local optima trapping and refines solution quality effectively.\n- **Pseudocode**:\n  ```rust\n  fn memetic_algorithm(weights, values, interaction_values, max_weight) {\n      pop = initialize_population();\n      while !converged {\n          eval_population(pop);\n          parents = select_parents(pop);\n          offspring = crossover(parents);\n          apply_mutation(offspring);\n          local_search(offspring);\n          pop = select_next_population(pop, offspring);\n      }\n      return best_solution(pop);\n  }\n  ```\n- **Implementation Notes**: Utilize a multiple-neighborhood tabu search to conduct efficient local optimization. Regularly evaluate interactions using a pairwise matrix to establish synergistic contributions to overall value. Hyperparameter optimization techniques should be employed to discuss and fine-tune parameters such as population size and mutation rates to prevent overfitting and ensure robust performance across multiple instances.\n\nOverall, the proposed hybrid memetic algorithm promises to leverage existing strategic insights and foundational GA concepts to solve the QKP effectively, enhancing the understanding of item interactions and maximization.  \n\n## References\n- Breakpoints Algorithm and Dynamic Programming Enhancements\n- Hybrid Methods for Optimization Challenges\n- Parameter Tuning for Genetic Algorithms\n- Choquet Integral and Synergy Modeling  \n",
  "code": "# === deepevolve_interface.py ===\nimport json\nimport math\nimport os\nimport shutil\nimport subprocess\nimport traceback\nfrom pathlib import Path\n\n\ndef detect_repo_root(marker: str = \"tig.py\") -> Path:\n    \"\"\"Walk up from this file until we find the repo marker (tig.py).\"\"\"\n    current_dir = Path(__file__).resolve()\n    if (env_path := os.getenv(\"TIG_REPO_ROOT\")):  # DEBUG: Check if environment variable is set\n        custom_path = Path(env_path).expanduser().resolve()\n        if (custom_path / marker).is_file():\n            return custom_path\n    for parent in current_dir.parents:  # DEBUG: Ensured we correctly check each parent directory\n        candidate = parent / marker\n        if candidate.is_file():  # DEBUG: Changed to is_file for clarity\n            return parent  # Return the parent directory where the file is found\n    # DEBUG: Providing clearer error to help with debugging\n    raise FileNotFoundError(\n        f\"Could not locate repository root containing {marker}. \"\n        f\"Searched up to: {current_dir.parents}. \"\n        \"Set TIG_REPO_ROOT to override.\"\n    )\n\n\ndef resolve_repo_root() -> Path:\n    \"\"\"Resolve the TIG repo root via env override or automatic detection.\"\"\"\n    env_path = os.getenv(\"TIG_REPO_ROOT\")\n    if env_path:\n        return Path(env_path).expanduser().resolve()\n    return detect_repo_root()\n\n\n# Absolute path to the TIG repo (auto-detected unless TIG_REPO_ROOT overrides)\nREPO_ROOT = resolve_repo_root()\nALGO_RUNNER = REPO_ROOT / \"algo-runner\"\n\n# Track to evaluate; override with TIG_TRACK_ID env if needed\nTRACK_ID = os.getenv(\"TIG_TRACK_ID\", \"n_items=500,density=5\")\n\n# Quick evaluation defaults\nNUM_TESTS = int(os.getenv(\"TIG_NUM_TESTS\", \"10\"))\nTIMEOUT = int(os.getenv(\"TIG_TIMEOUT\", \"60\"))\nQUALITY_PRECISION = 1_000_000  # Matches algo-runner/src/lib.rs\nMAX_BTB = 0.001\n\n\ndef performance_scale(x: float, max_btb: float) -> float:\n    \"\"\"Smoothly scale performance based on better-than-baseline metric.\"\"\"\n    if max_btb <= 0:\n        return 0.0\n\n    numerator = math.exp(3000.0 * x) - 1.0\n    denominator = math.exp(3000.0 * max_btb) - 1.0\n\n    if denominator == 0.0:\n        return 0.0\n\n    return max(0.0, min(numerator / denominator, 1.0))\n\n\ndef run_cmd(cmd, cwd):\n    \"\"\"Run a command and return (ok, stdout, stderr).\"\"\"\n    res = subprocess.run(cmd, cwd=cwd, text=True, capture_output=True)\n    return res.returncode == 0, res.stdout, res.stderr\n\n\ndef parse_metrics(stdout: str):\n    \"\"\"\n    Parse tig.py test_algorithm output lines like:\n    Seed: 0, Quality: <q>, Time: <t>, Memory: <m>KB\n    \"\"\"\n    quality = None\n    time_s = None\n    mem_kb = None\n    for line in stdout.splitlines():\n        if \"Quality:\" in line:\n            parts = line.split(\",\")\n            for part in parts:\n                if \"Quality:\" in part:\n                    try:\n                        quality = float(part.split(\":\")[1].strip())\n                    except Exception:\n                        quality = None\n                if \"Time:\" in part:\n                    try:\n                        time_s = float(part.split(\":\")[1].strip())\n                    except Exception:\n                        time_s = None\n                if \"Memory:\" in part:\n                    try:\n                        mem_kb = int(\n                            part.split(\":\")[1]\n                            .strip()\n                            .replace(\"KB\", \"\")\n                            .strip()\n                        )\n                    except Exception:\n                        mem_kb = None\n    return quality, time_s, mem_kb\n\n\ndef deepevolve_interface():\n    try:\n        # Locate evolved Rust sources in the temp workspace\n        src_algo = Path(__file__).resolve().parent / \"algo-runner\" / \"src\" / \"algorithm\"\n        if not src_algo.exists():\n            return False, f\"Missing evolved Rust sources at {src_algo}\"\n\n        dst_algo = ALGO_RUNNER / \"src\" / \"algorithm\"\n        if dst_algo.exists():\n            shutil.rmtree(dst_algo)\n        shutil.copytree(src_algo, dst_algo)\n\n        # DEBUG: Ensured that the path to tig.py is correctly set in the REPO_ROOT\n        tig_path = REPO_ROOT / \"tig.py\"  # Ensure this points to the correct directory\n        if not tig_path.exists():  # DEBUG: Added a check for tig.py existence\n            raise FileNotFoundError(f\"Missing tig.py at {tig_path}\")  # Raising an error instead of returning\n        ok, out, err = run_cmd([\"python\", str(tig_path), \"build_algorithm\"], cwd=REPO_ROOT)\n        if not ok:  # DEBUG: Check if the build process failed\n            return False, f\"build_algorithm failed\\nstdout:\\n{out}\\nstderr:\\n{err}. Check if tig.py is properly located at {tig_path}\"\n\n        cmd = [\n            \"python\",\n            \"tig.py\",\n            \"test_algorithm\",\n            TRACK_ID,\n            \"--tests\",\n            str(NUM_TESTS),\n            \"--timeout\",\n            str(TIMEOUT),\n        ]\n        ok, out, err = run_cmd(cmd, cwd=REPO_ROOT)\n        if not ok:\n            return False, f\"test_algorithm failed\\nstdout:\\n{out}\\nstderr:\\n{err}\"\n\n        quality, time_s, mem_kb = parse_metrics(out)\n        if quality is None:\n            return False, f\"Could not parse quality from output:\\n{out}\"\n\n        quality_normalized = quality / QUALITY_PRECISION\n        scaled_quality = performance_scale(quality_normalized, MAX_BTB)\n\n        metrics = {\n            \"combined_score\": scaled_quality,\n            \"quality\": scaled_quality,\n            \"raw_quality\": quality_normalized,\n            \"time_seconds\": time_s,\n            \"memory_kb\": mem_kb,\n        }\n        return True, metrics\n\n    except Exception:\n        return False, traceback.format_exc()\n\n\n# === algo-runner/src/algorithm/mod.rs ===\n### >>> DEEPEVOLVE-BLOCK-START: Evolving a Genetic Algorithm with Interaction Scoring\nuse rand::seq::SliceRandom; // Import random choice for genetic operations\nuse rand::Rng; // For random number generation\nuse std::collections::HashSet;\n\n// Genetic Algorithm Constants\nconst MAX_GENERATIONS: usize = 1000;\nconst POPULATION_SIZE: usize = 100;\nconst MUTATION_RATE: f64 = 0.1; // Mutation probability\n\n/// Helper function to evaluate individuals in the population.\nfn evaluate_individual(\n    individual: &[usize],\n    challenge: &Challenge,\n    pos_interactions: &[i64],\n) -> i64 {\n    let mut total_value = 0;\n    let mut total_weight = 0;\n\n    for &item in individual {\n        total_value += challenge.values[item] as i64;\n        total_weight += challenge.weights[item];\n    }\n\n    // Calculate interaction values\n    for i in 0..individual.len() {\n        for j in (i + 1)..individual.len() {\n            total_value += challenge.interaction_values[individual[i]][individual[j]] as i64;\n        }\n    }\n\n    if total_weight <= challenge.max_weight as i64 {\n        total_value\n    } else {\n        0 // Invalid solution\n    }\n}\n\n/// Initialize a random population of solutions\nfn initialize_population(challenge: &Challenge) -> Vec<Vec<usize>> {\n    (0..POPULATION_SIZE)\n        .map(|_| {\n            let mut rng = rand::thread_rng();\n            let mut items: Vec<usize> = (0..challenge.num_items).collect();\n            items.shuffle(&mut rng);\n            items.truncate(1 + rng.gen_range(0..challenge.num_items)); // Random number of items\n            items\n        })\n        .collect()\n}\n\n/// Crossover function to create new offspring\nfn crossover(parent1: &[usize], parent2: &[usize]) -> Vec<usize> {\n    let cut = parent1.len() / 2;\n    let mut child = parent1[..cut].to_vec();\n    child.extend(parent2[cut..].iter().cloned());\n    child.into_iter().collect::<HashSet<_>>().into_iter().collect() // Ensure uniqueness\n}\n\n/// Mutate an individual solution\nfn mutate(individual: &mut Vec<usize>, challenge: &Challenge) {\n    let mut rng = rand::thread_rng();\n    if rng.gen::<f64>() < MUTATION_RATE {\n        let swap_idx1 = rng.gen_range(0..individual.len());\n        let swap_idx2 = rng.gen_range(0..individual.len());\n        individual.swap(swap_idx1, swap_idx2);\n    }\n}\n\n/// Main genetic algorithm function\nfn memetic_algorithm(challenge: &Challenge) -> Vec<usize> {\n    // Initial population\n    let mut population = initialize_population(challenge);\n\n    let mut converged = false; // Initialize variable for convergence condition\n    while !converged {\n        eval_population(&population, challenge); // Novice population evaluation\n\n        // Selection\n        let parents = select_parents(&population); \n        let mut offspring = crossover(&parents);\n\n        // Apply mutation\n        for individual in &mut offspring {\n            mutate(individual, challenge);\n        }\n        \n        // Local search for offspring\n        // DEBUG: Ensured local_search is properly called and error is handled\n        if let Err(e) = local_search(&mut offspring, challenge) {\n            return false, f\"Local search failed: {e}\";\n        }\n        population = select_next_population(&population, &offspring); // Combine\n\n        // Track best solution and check for convergence\n    }\n    // Return best solution from modified population\n    best_solution(&population)\n}\n\n/// Main genetic algorithm function\nfn genetic_algorithm(challenge: &Challenge) -> Vec<usize> {\n=======\n    // Call to memetic_algorithm\n    let selection = memetic_algorithm(challenge);\n    let pos_interactions: Vec<i64> = (0..challenge.num_items)\n        .map(|i| {\n            challenge.interaction_values[i]\n                .iter()\n                .filter(|&&v| v > 0)\n                .map(|&v| v as i64)\n                .sum::<i64>()\n        })\n        .collect();\n\n    let mut population = initialize_population(challenge);\n    let mut best_solution = Vec::new();\n    let mut best_value = 0;\n\n    for _ in 0..MAX_GENERATIONS {\n        let scores: Vec<i64> = population\n            .iter()\n            .map(|individual| evaluate_individual(individual, challenge, &pos_interactions))\n            .collect();\n\n        // Selection based on scores\n        population = population\n            .iter()\n            .enumerate()\n            .filter(|&(i, _)| scores[i] > 0)\n            .map(|(_, individual)| individual.clone())\n            .collect();\n\n        // Crossover and mutation\n        population = (0..POPULATION_SIZE)\n            .map(|_| {\n                let (parent1, parent2) = population\n                    .choose_multiple(&mut rand::thread_rng(), 2).unwrap(); // Random parents\n                let mut child = crossover(parent1, parent2);\n                mutate(&mut child, challenge);\n                child\n            })\n            .collect();\n\n        // Keep track of the best solution\n        for (individual, &score) in population.iter().zip(scores.iter()) {\n            if score > best_value {\n                best_value = score;\n                best_solution = individual.clone();\n            }\n        }\n    }\n    best_solution\n}\n\n/// Updated solve_challenge to integrate genetic algorithm instead of greedy\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    let _params = hyperparameters.as_ref().unwrap_or(&Map::new());\n\n    // Use genetic algorithm for challenge solving\n    let selection = genetic_algorithm(challenge);\n\n    let mut solution = Solution::new();\n    solution.items = selection;\n    save_solution(&solution)?;\n    \n    Ok(())\n}\n### <<< DEEPEVOLVE-BLOCK-END\n}\n\n\n"
}