{"id": "4cd12b02-1754-4031-8880-9925dcf424a6", "code": "// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub max_iterations: usize,\n        pub initial_temperature: f64,\n        pub cooling_rate: f64,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .map_err(|e| anyhow!(\"Failed to parse hyperparameters: {}\", e))?\n        }\n        None => Hyperparameters {\n            max_iterations: 100_000, // Increased iterations for better convergence\n            initial_temperature: 1000.0, \n            cooling_rate: 0.9999, \n        },\n    };\n    \n    let mut rng = SmallRng::from_seed(challenge.seed);\n\n    // Helper function to calculate total value of the current selection\n    fn calculate_value(\n        selected_indices: &[usize],\n        challenge: &Challenge,\n        interaction_sums: &[i64],\n    ) -> i64 {\n        let mut total_value = 0i64;\n        let mut total_interaction_sum = 0i64;\n        \n        for &i in selected_indices {\n            total_value += challenge.values[i] as i64;\n            total_interaction_sum += interaction_sums[i];\n        }\n        \n        // Total value = Sum(V_i) + 0.5 * Sum_{i in S} I_sum_i\n        total_value + total_interaction_sum / 2\n    }\n\n    // Phase 1: Iterative greedy construction heuristic.\n    // At each step, it adds the item with the highest marginal gain-to-weight ratio.\n    let num_items = challenge.values.len();\n    let mut selected = Vec::new();\n\n    if num_items > 0 {\n        let mut total_weight: u32 = 0;\n        let mut is_selected = vec![false; num_items];\n        let mut marginal_gains: Vec<f64> = challenge.values.iter().map(|&v| v as f64).collect();\n\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_ratio = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = challenge.weights[i];\n                    if total_weight + item_weight <= challenge.max_weight {\n                        let ratio = if item_weight > 0 {\n                            marginal_gains[i] / item_weight as f64\n                        } else {\n                            if marginal_gains[i] > 0.0 {\n                                f64::INFINITY\n                            } else {\n                                f64::NEG_INFINITY\n                            }\n                        };\n\n                        if ratio > best_ratio {\n                            best_ratio = ratio;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(item_to_add) = best_item {\n                selected.push(item_to_add);\n                is_selected[item_to_add] = true;\n                total_weight += challenge.weights[item_to_add];\n\n                for i in 0..num_items {\n                    if !is_selected[i] {\n                        marginal_gains[i] += challenge.interaction_values[item_to_add][i] as f64;\n                    }\n                }\n            } else {\n                break;\n            }\n        }\n\n        // Phase 2: Simulated Annealing (SA)\n        if !selected.is_empty() {\n            let mut current_interaction_sums = vec![0i64; num_items];\n            for i in 0..num_items {\n                for &k in &selected {\n                    current_interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                }\n            }\n            \n            let mut current_value = calculate_value(&selected, challenge, &current_interaction_sums);\n            let mut best_value = current_value;\n            let mut best_selected = selected.clone();\n            \n            let mut temperature = hyperparameters.initial_temperature;\n            let cooling_rate = hyperparameters.cooling_rate;\n\n            #[derive(Debug, Clone, Copy)]\n            enum Move {\n                Add(usize), \n                Drop(usize), // Index in `selected` vector\n                Swap(usize, usize), // Index in `selected` vector, item index\n            }\n\n            for _ in 0..hyperparameters.max_iterations {\n                if temperature < 1e-6 {\n                    break; \n                }\n\n                let mut moves = Vec::new();\n\n                // --- 1. Identify feasible Insertion (Add item j) ---\n                for item_j in 0..num_items {\n                    if !is_selected[item_j] {\n                        let item_weight = challenge.weights[item_j];\n                        if total_weight + item_weight <= challenge.max_weight {\n                            let delta_value = challenge.values[item_j] as i64 + current_interaction_sums[item_j];\n                            moves.push((Move::Add(item_j), delta_value));\n                        }\n                    }\n                }\n\n                // --- 2. Identify feasible Removal (Drop item i) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx];\n                    let delta_value = -(challenge.values[item_i] as i64 + current_interaction_sums[item_i]);\n                    moves.push((Move::Drop(i_vec_idx), delta_value));\n                }\n\n                // --- 3. Identify feasible Swap (Drop item i, Add item j) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx];\n                    for item_j in 0..num_items {\n                        if is_selected[item_j] { continue; }\n\n                        let delta_weight = challenge.weights[item_j] as i64 - challenge.weights[item_i] as i64;\n                        if (total_weight as i64 + delta_weight) <= challenge.max_weight as i64 {\n                            let delta_value = (challenge.values[item_j] as i64 - challenge.values[item_i] as i64)\n                                            + (current_interaction_sums[item_j] - challenge.interaction_values[item_j][item_i] as i64)\n                                            - current_interaction_sums[item_i];\n                            moves.push((Move::Swap(i_vec_idx, item_j), delta_value));\n                        }\n                    }\n                }\n\n                if moves.is_empty() {\n                    break; // No feasible moves left\n                }\n\n                // --- Select and Evaluate Move (Randomly choose one move) ---\n                let move_idx = rng.gen_range(0..moves.len());\n                let (move_to_execute, delta_value) = moves[move_idx];\n                \n                let acceptance_prob = if delta_value >= 0 {\n                    1.0 // Always accept improving or neutral moves\n                } else {\n                    // Boltzmann acceptance criterion for worsening moves\n                    if temperature > 0.0 {\n                        let exponent = (delta_value as f64) / temperature;\n                        exponent.exp()\n                    } else {\n                        0.0 // Reject if temperature is zero or negative\n                    }\n                };\n\n                if acceptance_prob > rng.gen::<f64>() {\n                    // Execute Move\n                    match move_to_execute {\n                        Move::Add(item_j_to_add) => {\n                            let item_weight = challenge.weights[item_j_to_add];\n                            total_weight += item_weight;\n                            is_selected[item_j_to_add] = true;\n                            selected.push(item_j_to_add);\n\n                            for k in 0..num_items {\n                                current_interaction_sums[k] += challenge.interaction_values[k][item_j_to_add] as i64;\n                            }\n                        }\n                        Move::Drop(i_vec_idx_to_drop) => {\n                            let item_i_to_drop = selected.swap_remove(i_vec_idx_to_drop);\n                            total_weight -= challenge.weights[item_i_to_drop];\n                            is_selected[item_i_to_drop] = false;\n\n                            for k in 0..num_items {\n                                current_interaction_sums[k] -= challenge.interaction_values[k][item_i_to_drop] as i64;\n                            }\n                        }\n                        Move::Swap(i_vec_idx_to_swap, item_j_to_add) => {\n                            let item_i_to_drop = selected[i_vec_idx_to_swap];\n\n                            let delta_weight = challenge.weights[item_j_to_add] as i64 - challenge.weights[item_i_to_drop] as i64;\n                            total_weight = (total_weight as i64 + delta_weight) as u32;\n\n                            is_selected[item_i_to_drop] = false;\n                            is_selected[item_j_to_add] = true;\n                            selected[i_vec_idx_to_swap] = item_j_to_add;\n\n                            for k in 0..num_items {\n                                current_interaction_sums[k] += (challenge.interaction_values[k][item_j_to_add] - challenge.interaction_values[k][item_i_to_drop]) as i64;\n                            }\n                        }\n                    }\n                    \n                    current_value += delta_value;\n\n                    if current_value > best_value {\n                        best_value = current_value;\n                        best_selected = selected.clone();\n                    }\n                }\n\n                // Cool down\n                temperature *= cooling_rate;\n            }\n            \n            selected = best_selected;\n        }\n    }\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}", "language": "rust", "parent_id": "964a9dcd-1d8f-457c-b093-acd779c6323f", "generation": 6, "timestamp": 1766155011.801148, "iteration_found": 104, "metrics": {"error": 0.0, "timeout": true}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 227 lines with 329 lines", "parent_metrics": {"error": 0.0, "timeout": true}, "island": 3}, "prompts": {"diff_user": {"system": "SETTING:\nYou are an expert Rust programmer specializing in combinatorial optimization algorithms with deep expertise in knapsack problems, resource allocation algorithms, and constraint satisfaction.\nYour mission is to evolve and optimize a quadratic knapsack algorithm that outputs the highest quality possible.\n\n\n=== CRITICAL OUTPUT FORMAT RULES ===\n1. Output ONLY raw Rust source code\n2. Include the complete file from first line to last line\n=== END OUTPUT FORMAT RULES ===\n\nAlgorithm Improvement Instructions:\n\nObjective\nImprove the knapsack algorithm to maximize the total value while respecting the weight constraint.\n\nCRITICAL Constraints\n- You may ONLY modify code between // EVOLVE-BLOCK-START and // EVOLVE-BLOCK-END\n- Code outside these markers (imports, function wrapper, save_solution call) must NEVER be modified\n- You MUST NOT modify the function signature\n- You MUST NOT modify lines before // EVOLVE-BLOCK-START\n- You MUST NOT modify lines after // EVOLVE-BLOCK-END\n- You MUST preserve the exact structure of code outside the evolve block\n\nInput: challenge parameter (type: &Challenge)\n\nThe challenge parameter provides access to the following fields with these EXPLICIT types:\n\n- challenge.seed: [u8; 32] - Fixed-size array of 32 bytes for seeding random number generators\n- challenge.weights: Vec<u32> - Vector of unsigned 32-bit integers representing each item's weight\n- challenge.values: Vec<u32> - Vector of unsigned 32-bit integers representing each item's base value\n- challenge.interaction_values: Vec<Vec<i32>> - 2D matrix (vector of vectors) of SIGNED 32-bit integers\n  - interaction_values[i][j] gives the bonus value when items i and j are BOTH selected\n  - This matrix is symmetric: interaction_values[i][j] == interaction_values[j][i]\n  - Diagonal is zero: interaction_values[i][i] == 0\n- challenge.max_weight: u32 - Unsigned 32-bit integer representing maximum total weight allowed\n  \nImportant notes:\n- All vectors have the same length (number of items)\n- challenge.weights.len() = challenge.values.len() = challenge.interaction_values.len()\n- Item indices are 0 to n-1 where n = challenge.values.len()\n- the structure of the algorithm i.e. the inputs and outputs are fixed, you can only modify the body of the algorithm.\n\nOutput: selected variable (type: Vec<usize>)\n\nYour code must create a variable named selected with the following specification:\n\n- Type: Vec<usize> (vector of unsigned size integers)\n- Content: Indices of items to include in the knapsack solution\n- Valid range: Each element must be in range [0, n-1] where n = challenge.values.len()\n- No duplicates: Each item index can appear at most once\n- Weight constraint: The sum of challenge.weights[i] for all i in selected must be \u2264 challenge.max_weight\n\nThe selected variable is automatically saved after the evolve block ends.\n\nContext:\n- This is a QUADRATIC knapsack problem with interaction values between items\n- Items have: weights, values, and interaction_values (2D matrix)\n- Total value = sum of item values + sum of interaction values for pairs of selected items\n- Constraint: total weight must not exceed max_weight which is half the weight of all items\n- The \"density\" of the knapsack is 25% - meaning interaction values in the symmetric interaction matrix are 0 with probability 0.75; otherwise a random number between 1 and 100.\n\nBENCHMARK:\n- Beat the state-of-the-art result of avg_btb = 0.0015.\n\nHyperparameters (Optional):\nIf your algorithm uses tunable parameters (e.g., iteration counts, thresholds, probabilities),\nyou can define them inside the EVOLVE-BLOCK. Follow these examples exactly.\n\nCRITICAL: The examples below show raw Rust code. Do NOT wrap them in markdown code fences.\n\n\nStep 1 - Define a Hyperparameters struct inside the EVOLVE-BLOCK:\n\n#[derive(Serialize, Deserialize)]\npub struct Hyperparameters {\n    pub max_iterations: usize,\n    pub temperature: f64,\n}\n\nStep 2 - Parse hyperparameters at the start of your code block:\n\nlet hyperparameters = match _hyperparameters {\n    Some(params) => {\n        serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n            .map_err(|e| anyhow!(\"Failed to parse hyperparameters: {}\", e))?\n    }\n    None => Hyperparameters {\n        max_iterations: 100,\n        temperature: 0.95,\n    },\n};\n\nStep 3 - Use the hyperparameter values in your algorithm:\n\nfor _ in 0..hyperparameters.max_iterations {\n    // your algorithm logic here\n}\n\n\nRandom numbers:\nIf you need random numbers, recommend using SmallRng with challenge.seed:\nlet mut rng = SmallRng::from_seed(challenge.seed);\n\nMake sure you use\n- Optimised sorting strategies \n- Efficient data structures for tracking selected items\n\nImportant:\n- Only modify code within the EVOLVE-BLOCK\n- Ensure the algorithm terminates within reasonable time\n- Use the provided Challenge struct fields: values, weights, interaction_values, max_weight\n- The variable selected is automatically saved after the evolve block ends\n\nPERFORMANCE METRICS:\n1. **avg_btb**: Average better than baseline; average percentage that the total value of the knapsack solution is better than a baseline value (PRIMARY OBJECTIVE - maximize)\n2. **combined_score**: progress toward beating the state-of-the-art benchmark\n3. **eval_time**: Execution time in seconds (keep reasonable, prefer accuracy over speed)\n4. **memory**: Memory usage in kilobytes (keep reasonable, prefer accuracy over speed)\n\nTECHNICAL REQUIREMENTS:\n- **Error handling**: Graceful handling of optimization failures or infeasible configurations\n- **Memory efficiency**: Avoid excessive memory allocation for matrix computations\n", "user": "# Current Program Information\n- Fitness: 0.5000\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness unchanged at 0.5000\n- Consider simplifying - code length exceeds 2000 characters\n\n## Last Execution Output\n\n### timeout\n```\nTrue\n```\n\n### timeout_duration\n```\n1200\n```\n\n### failure_stage\n```\nevaluation\n```\n\n### error_type\n```\ntimeout\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 2\n- Changes: Change 1: Replace 19 lines with 53 lines\nChange 2: Replace 121 lines with 137 lines\n- Metrics: error: 0.0000, timeout: 1.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Change 1: Replace 180 lines with 325 lines\n- Metrics: avg_btb: 0.0008, combined_score: 0.6165, eval_time: 12.4139, memory: 371200.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.6165)\n```rust\n// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub max_restarts: usize,\n        pub base_perturbation_size: usize,\n        pub stagnation_limit: usize,\n        pub perturbation_increase_factor: f64,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .unwrap_or(Hyperparameters {\n                    max_restarts: 250, \n                    base_perturbation_size: 20,\n                    stagnation_limit: 30, \n                    perturbation_increase_factor: 1.25,\n                })\n        }\n        None => Hyperparameters {\n            max_restarts: 250,\n            base_perturbation_size: 20,\n            stagnation_limit: 30,\n            perturbation_increase_factor: 1.25,\n        },\n    };\n\n    let num_items = challenge.values.len();\n    let weights = &challenge.weights;\n    let values = &challenge.values;\n    let interactions = &challenge.interaction_values;\n    let max_weight = challenge.max_weight;\n\n    let mut rng = SmallRng::from_seed(challenge.seed);\n\n    // --- State Variables (Current Solution) ---\n    let mut is_selected = vec![false; num_items];\n    let mut current_weight: u32 = 0;\n    // Marginal gains initialized with base values\n    let mut marginal_gains: Vec<i64> = values.iter().map(|&v| v as i64).collect();\n    let mut current_value: i64 = 0;\n\n    // --- Best Solution Tracking ---\n    let mut best_solution = vec![false; num_items];\n    let mut best_value = i64::MIN;\n\n    #[derive(Debug, Clone, Copy)]\n    enum LS_Move {\n        Add(usize),\n        Remove(usize),\n        Swap(usize, usize), // (item_to_remove, item_to_add)\n    }\n\n    // Helper function to run Best Improvement Local Search (BILS) until convergence\n    // Modifies state variables in place.\n    let mut run_bils = |\n        is_selected: &mut Vec<bool>,\n        current_weight: &mut u32,\n        marginal_gains: &mut Vec<i64>,\n        current_value: &mut i64\n    | {\n        loop {\n            let mut best_delta_v = 0i64;\n            let mut best_move: Option<LS_Move> = None;\n\n            // O(N^2) neighborhood search\n            for j in 0..num_items {\n                if is_selected[j] {\n                    // Item j is selected: Check Remove and Swap moves involving j\n\n                    // --- Remove Move (j out) ---\n                    // Delta V = -MG[j]\n                    let delta_v_remove_j = -marginal_gains[j];\n                    if delta_v_remove_j > best_delta_v {\n                        best_delta_v = delta_v_remove_j;\n                        best_move = Some(LS_Move::Remove(j));\n                    }\n\n                    // --- Swap Moves (j out, i in) ---\n                    let w_j = weights[j];\n                    \n                    for i in 0..num_items {\n                        if !is_selected[i] {\n                            let w_i = weights[i];\n                            \n                            // Check weight constraint for swap\n                            let delta_w = w_i as i64 - w_j as i64;\n                            if (*current_weight as i64 + delta_w) <= max_weight as i64 {\n                                \n                                // Delta V(j out, i in) = MG[i] - interactions[i][j] - MG[j]\n                                let delta_v_swap = marginal_gains[i] - interactions[i][j] as i64 - marginal_gains[j];\n\n                                if delta_v_swap > best_delta_v {\n                                    best_delta_v = delta_v_swap;\n                                    best_move = Some(LS_Move::Swap(j, i));\n                                }\n                            }\n                        }\n                    }\n                } else {\n                    // Item i is unselected: Check Add moves\n                    let i = j;\n                    let w_i = weights[i];\n\n                    // --- Add Move (i in) ---\n                    // Delta V = MG[i]\n                    if current_weight.checked_add(w_i).map_or(false, |w| w <= max_weight) {\n                        let delta_v_add_i = marginal_gains[i];\n\n                        if delta_v_add_i > best_delta_v {\n                            best_delta_v = delta_v_add_i;\n                            best_move = Some(LS_Move::Add(i));\n                        }\n                    }\n                }\n            }\n\n            if best_delta_v > 0 {\n                *current_value += best_delta_v;\n\n                match best_move.unwrap() {\n                    LS_Move::Add(i) => {\n                        is_selected[i] = true;\n                        *current_weight += weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] += interactions[i][k] as i64;\n                        }\n                    }\n                    LS_Move::Remove(j) => {\n                        is_selected[j] = false;\n                        *current_weight -= weights[j];\n                        for k in 0..num_items {\n                            marginal_gains[k] -= interactions[j][k] as i64;\n                        }\n                    }\n                    LS_Move::Swap(j, i) => {\n                        is_selected[j] = false;\n                        is_selected[i] = true;\n                        *current_weight = *current_weight - weights[j] + weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] = marginal_gains[k] - interactions[j][k] as i64 + interactions[i][k] as i64;\n                        }\n                    }\n                }\n            } else {\n                break; // Local optimum reached\n            }\n        }\n    };\n\n\n\n    // --- 1. Initial Greedy Construction Phase (O(N^2)) ---\n    loop {\n        let mut best_item: Option<usize> = None;\n        let mut best_density: f64 = f64::NEG_INFINITY;\n\n        for i in 0..num_items {\n            if !is_selected[i] {\n                let item_weight = weights[i];\n                if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                    let gain = marginal_gains[i];\n                    \n                    let density = if item_weight == 0 {\n                        if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                    } else {\n                        gain as f64 / item_weight as f64\n                    };\n\n                    if density > best_density {\n                        best_density = density;\n                        best_item = Some(i);\n                    }\n                }\n            }\n        }\n\n        if let Some(idx_to_add) = best_item {\n            // Update value incrementally\n            current_value += marginal_gains[idx_to_add]; \n            \n            is_selected[idx_to_add] = true;\n            current_weight += weights[idx_to_add];\n\n            // Update marginal gains for ALL items (O(N) step). \n            for i in 0..num_items {\n                marginal_gains[i] += interactions[idx_to_add][i] as i64;\n            }\n        } else {\n            break;\n        }\n    }\n    \n    // Initialize best solution tracking (current_value is already correct)\n    best_value = current_value;\n    best_solution = is_selected.clone();\n\n    // --- 2. Iterated Local Search (ILS) with Adaptive Perturbation ---\n    let mut iterations_since_best_update = 0;\n    let mut dynamic_perturbation_size = hyperparameters.base_perturbation_size;\n\n    for restart in 0..hyperparameters.max_restarts {\n        \n        // A. Run BILS on the current state until local optimum is reached\n        run_bils(&mut is_selected, &mut current_weight, &mut marginal_gains, &mut current_value);\n\n        // B. Update Best Solution and adapt perturbation strength\n        if current_value > best_value {\n            best_value = current_value;\n            best_solution = is_selected.clone();\n            iterations_since_best_update = 0;\n            // On improvement, reset perturbation strength to base to focus search locally\n            dynamic_perturbation_size = hyperparameters.base_perturbation_size;\n        } else {\n            iterations_since_best_update += 1;\n        }\n\n        if iterations_since_best_update >= hyperparameters.stagnation_limit {\n            // Stagnation detected: increase perturbation strength to escape\n            dynamic_perturbation_size = (dynamic_perturbation_size as f64 * hyperparameters.perturbation_increase_factor).round() as usize;\n            // Cap the size to avoid destroying the solution completely\n            let max_p_size = (num_items as f64 * 0.4) as usize; // Don't remove more than 40% of items\n            dynamic_perturbation_size = dynamic_perturbation_size.min(max_p_size);\n            iterations_since_best_update = 0; // Reset counter after strengthening\n        }\n\n        if restart == hyperparameters.max_restarts - 1 {\n            break; // No need to perturb after the last optimization run\n        }\n\n        // C. Perturbation Phase (Biased removal + Incremental Repair)\n        let mut selected_indices: Vec<usize> = (0..num_items).filter(|&i| is_selected[i]).collect();\n        let num_selected = selected_indices.len();\n        \n        let p_size = dynamic_perturbation_size.min(num_selected);\n        \n        // 1. & 2. Biasedly remove P_size items and update state incrementally (O(P*N))\n        for _ in 0..p_size {\n            if selected_indices.is_empty() { break; }\n\n            // Calculate MG_max for normalization (O(N_selected))\n            let mg_max = selected_indices.iter()\n                .map(|&i| marginal_gains[i])\n                .max()\n                .unwrap_or(1); \n\n            // Calculate weights: S_j = MG_max - MG_j + 1 (Bias towards low MG items)\n            let mut total_weight = 0i64;\n            let weights_and_indices: Vec<(i64, usize)> = selected_indices.iter().map(|&j| {\n                // Ensure weight is positive and non-zero. \n                let weight = mg_max - marginal_gains[j] + 1; \n                total_weight += weight;\n                (weight, j)\n            }).collect();\n\n            // Select item j using roulette wheel selection (O(N_selected))\n            let target = rng.gen_range(0..total_weight);\n            let mut cumulative_weight = 0i64;\n            \n            let mut removal_index_in_vec = 0; // Index in selected_indices vector\n            \n            for (idx, &(weight, _)) in weights_and_indices.iter().enumerate() {\n                cumulative_weight += weight;\n                if cumulative_weight > target {\n                    removal_index_in_vec = idx;\n                    break;\n                }\n            }\n            \n            // Retrieve item index j and remove it from selected_indices (O(1) using swap_remove)\n            let j = selected_indices.swap_remove(removal_index_in_vec);\n\n            // Update value incrementally using the current marginal gain\n            current_value -= marginal_gains[j];\n            \n            is_selected[j] = false;\n            current_weight -= weights[j];\n\n            // Update marginal gains for all other items due to j's removal (O(N))\n            for k in 0..num_items {\n                marginal_gains[k] -= interactions[j][k] as i64;\n            }\n        }\n\n        // 3. Greedy Repair (Add items back based on marginal density)\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_density: f64 = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = weights[i];\n                    if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                        let gain = marginal_gains[i];\n                        \n                        let density = if item_weight == 0 {\n                            if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                        } else {\n                            gain as f64 / item_weight as f64\n                        };\n\n                        if density > best_density {\n                            best_density = density;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(idx_to_add) = best_item {\n                is_selected[idx_to_add] = true;\n                current_weight += weights[idx_to_add];\n                current_value += marginal_gains[idx_to_add]; // Update value incrementally\n\n                // Update marginal gains for ALL items (O(N) step). \n                for i in 0..num_items {\n                    marginal_gains[i] += interactions[idx_to_add][i] as i64;\n                }\n            } else {\n                break;\n            }\n        }\n    }\n\n    // Finalize solution indices from the best solution found\n    let selected: Vec<usize> = (0..num_items).filter(|&i| best_solution[i]).collect();\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}\n```\nKey features: Performs well on avg_btb (0.0008), Performs well on combined_score (0.6165), Performs well on eval_time (12.4139), Performs well on memory (371200.0000)\n\n### Program 2 (Score: 0.5000)\n```rust\n// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub max_iterations: usize,\n        pub initial_temperature: f64,\n        pub cooling_rate: f64,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .map_err(|e| anyhow!(\"Failed to parse hyperparameters: {}\", e))?\n        }\n        None => Hyperparameters {\n            max_iterations: 100_000, // Increased iterations for better convergence\n            initial_temperature: 1000.0, \n            cooling_rate: 0.9999, \n        },\n    };\n    \n    let mut rng = SmallRng::from_seed(challenge.seed);\n\n    // Helper function to calculate total value of the current selection\n    fn calculate_value(\n        selected_indices: &[usize],\n        challenge: &Challenge,\n        interaction_sums: &[i64],\n    ) -> i64 {\n        let mut total_value = 0i64;\n        let mut total_interaction_sum = 0i64;\n        \n        for &i in selected_indices {\n            total_value += challenge.values[i] as i64;\n            total_interaction_sum += interaction_sums[i];\n        }\n        \n        // Total value = Sum(V_i) + 0.5 * Sum_{i in S} I_sum_i\n        total_value + total_interaction_sum / 2\n    }\n\n    // Phase 1: Iterative greedy construction heuristic.\n    // At each step, it adds the item with the highest marginal gain-to-weight ratio.\n    let num_items = challenge.values.len();\n    let mut selected = Vec::new();\n\n    if num_items > 0 {\n        let mut total_weight: u32 = 0;\n        let mut is_selected = vec![false; num_items];\n        let mut marginal_gains: Vec<f64> = challenge.values.iter().map(|&v| v as f64).collect();\n\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_ratio = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = challenge.weights[i];\n                    if total_weight + item_weight <= challenge.max_weight {\n                        let ratio = if item_weight > 0 {\n                            marginal_gains[i] / item_weight as f64\n                        } else {\n                            if marginal_gains[i] > 0.0 {\n                                f64::INFINITY\n                            } else {\n                                f64::NEG_INFINITY\n                            }\n                        };\n\n                        if ratio > best_ratio {\n                            best_ratio = ratio;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(item_to_add) = best_item {\n                selected.push(item_to_add);\n                is_selected[item_to_add] = true;\n                total_weight += challenge.weights[item_to_add];\n\n                for i in 0..num_items {\n                    if !is_selected[i] {\n                        marginal_gains[i] += challenge.interaction_values[item_to_add][i] as f64;\n                    }\n                }\n            } else {\n                break;\n            }\n        }\n\n        // Phase 2: Simulated Annealing (SA)\n        if !selected.is_empty() {\n            let mut current_interaction_sums = vec![0i64; num_items];\n            for i in 0..num_items {\n                for &k in &selected {\n                    current_interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                }\n            }\n            \n            let mut current_value = calculate_value(&selected, challenge, &current_interaction_sums);\n            let mut best_value = current_value;\n            let mut best_selected = selected.clone();\n            \n            let mut temperature = hyperparameters.initial_temperature;\n            let cooling_rate = hyperparameters.cooling_rate;\n\n            #[derive(Debug, Clone, Copy)]\n            enum Move {\n                Add(usize), \n                Drop(usize), // Index in `selected` vector\n                Swap(usize, usize), // Index in `selected` vector, item index\n            }\n\n            for _ in 0..hyperparameters.max_iterations {\n                if temperature < 1e-6 {\n                    break; \n                }\n\n                let mut moves = Vec::new();\n\n                // --- 1. Identify feasible Insertion (Add item j) ---\n                for item_j in 0..num_items {\n                    if !is_selected[item_j] {\n                        let item_weight = challenge.weights[item_j];\n                        if total_weight + item_weight <= challenge.max_weight {\n                            let delta_value = challenge.values[item_j] as i64 + current_interaction_sums[item_j];\n                            moves.push((Move::Add(item_j), delta_value));\n                        }\n                    }\n                }\n\n                // --- 2. Identify feasible Removal (Drop item i) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx];\n                    let delta_value = -(challenge.values[item_i] as i64 + current_interaction_sums[item_i]);\n                    moves.push((Move::Drop(i_vec_idx), delta_value));\n                }\n\n                // --- 3. Identify feasible Swap (Drop item i, Add item j) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx];\n                    for item_j in 0..num_items {\n                        if is_selected[item_j] { continue; }\n\n                        let delta_weight = challenge.weights[item_j] as i64 - challenge.weights[item_i] as i64;\n                        if (total_weight as i64 + delta_weight) <= challenge.max_weight as i64 {\n                            let delta_value = (challenge.values[item_j] as i64 - challenge.values[item_i] as i64)\n                                            + (current_interaction_sums[item_j] - challenge.interaction_values[item_j][item_i] as i64)\n                                            - current_interaction_sums[item_i];\n                            moves.push((Move::Swap(i_vec_idx, item_j), delta_value));\n                        }\n                    }\n                }\n\n                if moves.is_empty() {\n                    break; // No feasible moves left\n                }\n\n                // --- Select and Evaluate Move (Randomly choose one move) ---\n                let move_idx = rng.gen_range(0..moves.len());\n                let (move_to_execute, delta_value) = moves[move_idx];\n                \n                let acceptance_prob = if delta_value >= 0 {\n                    1.0 // Always accept improving or neutral moves\n                } else {\n                    // Boltzmann acceptance criterion for worsening moves\n                    if temperature > 0.0 {\n                        let exponent = (delta_value as f64) / temperature;\n                        exponent.exp()\n                    } else {\n                        0.0 // Reject if temperature is zero or negative\n                    }\n                };\n\n                if acceptance_prob > rng.gen::<f64>() {\n                    // Execute Move\n                    match move_to_execute {\n                        Move::Add(item_j_to_add) => {\n                            let item_weight = challenge.weights[item_j_to_add];\n                            total_weight += item_weight;\n                            is_selected[item_j_to_add] = true;\n                            selected.push(item_j_to_add);\n\n                            for k in 0..num_items {\n                                current_interaction_sums[k] += challenge.interaction_values[k][item_j_to_add] as i64;\n                            }\n                        }\n                        Move::Drop(i_vec_idx_to_drop) => {\n                            let item_i_to_drop = selected.swap_remove(i_vec_idx_to_drop);\n                            total_weight -= challenge.weights[item_i_to_drop];\n                            is_selected[item_i_to_drop] = false;\n\n                            for k in 0..num_items {\n                                current_interaction_sums[k] -= challenge.interaction_values[k][item_i_to_drop] as i64;\n                            }\n                        }\n                        Move::Swap(i_vec_idx_to_swap, item_j_to_add) => {\n                            let item_i_to_drop = selected[i_vec_idx_to_swap];\n\n                            let delta_weight = challenge.weights[item_j_to_add] as i64 - challenge.weights[item_i_to_drop] as i64;\n                            total_weight = (total_weight as i64 + delta_weight) as u32;\n\n                            is_selected[item_i_to_drop] = false;\n                            is_selected[item_j_to_add] = true;\n                            selected[i_vec_idx_to_swap] = item_j_to_add;\n\n                            for k in 0..num_items {\n                                current_interaction_sums[k] += (challenge.interaction_values[k][item_j_to_add] - challenge.interaction_values[k][item_i_to_drop]) as i64;\n                            }\n                        }\n                    }\n                    \n                    current_value += delta_value;\n\n                    if current_value > best_value {\n                        best_value = current_value;\n                        best_selected = selected.clone();\n                    }\n                }\n\n                // Cool down\n                temperature *= cooling_rate;\n            }\n            \n            selected = best_selected;\n        }\n    }\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}\n```\nKey features: Performs well on error (0.0000), Performs well on timeout (1.0000)\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.6165, Type: Alternative)\n```rust\n// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub max_restarts: usize,\n        pub base_perturbation_size: usize,\n        pub stagnation_limit: usize,\n        pub perturbation_increase_factor: f64,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .unwrap_or(Hyperparameters {\n                    max_restarts: 250, \n                    base_perturbation_size: 20,\n                    stagnation_limit: 30, \n                    perturbation_increase_factor: 1.25,\n                })\n        }\n        None => Hyperparameters {\n            max_restarts: 250,\n            base_perturbation_size: 20,\n            stagnation_limit: 30,\n            perturbation_increase_factor: 1.25,\n        },\n    };\n\n    let num_items = challenge.values.len();\n    let weights = &challenge.weights;\n    let values = &challenge.values;\n    let interactions = &challenge.interaction_values;\n    let max_weight = challenge.max_weight;\n\n    let mut rng = SmallRng::from_seed(challenge.seed);\n\n    // --- State Variables (Current Solution) ---\n    let mut is_selected = vec![false; num_items];\n    let mut current_weight: u32 = 0;\n    // Marginal gains initialized with base values\n    let mut marginal_gains: Vec<i64> = values.iter().map(|&v| v as i64).collect();\n    let mut current_value: i64 = 0;\n\n    // --- Best Solution Tracking ---\n    let mut best_solution = vec![false; num_items];\n    let mut best_value = i64::MIN;\n\n    #[derive(Debug, Clone, Copy)]\n    enum LS_Move {\n        Add(usize),\n        Remove(usize),\n        Swap(usize, usize), // (item_to_remove, item_to_add)\n    }\n\n    // Helper function to run Best Improvement Local Search (BILS) until convergence\n    // Modifies state variables in place.\n    let mut run_bils = |\n        is_selected: &mut Vec<bool>,\n        current_weight: &mut u32,\n        marginal_gains: &mut Vec<i64>,\n        current_value: &mut i64\n    | {\n        loop {\n            let mut best_delta_v = 0i64;\n            let mut best_move: Option<LS_Move> = None;\n\n            // O(N^2) neighborhood search\n            for j in 0..num_items {\n                if is_selected[j] {\n                    // Item j is selected: Check Remove and Swap moves involving j\n\n                    // --- Remove Move (j out) ---\n                    // Delta V = -MG[j]\n                    let delta_v_remove_j = -marginal_gains[j];\n                    if delta_v_remove_j > best_delta_v {\n                        best_delta_v = delta_v_remove_j;\n                        best_move = Some(LS_Move::Remove(j));\n                    }\n\n                    // --- Swap Moves (j out, i in) ---\n                    let w_j = weights[j];\n                    \n                    for i in 0..num_items {\n                        if !is_selected[i] {\n                            let w_i = weights[i];\n                            \n                            // Check weight constraint for swap\n                            let delta_w = w_i as i64 - w_j as i64;\n                            if (*current_weight as i64 + delta_w) <= max_weight as i64 {\n                                \n                                // Delta V(j out, i in) = MG[i] - interactions[i][j] - MG[j]\n                                let delta_v_swap = marginal_gains[i] - interactions[i][j] as i64 - marginal_gains[j];\n\n                                if delta_v_swap > best_delta_v {\n                                    best_delta_v = delta_v_swap;\n                                    best_move = Some(LS_Move::Swap(j, i));\n                                }\n                            }\n                        }\n                    }\n                } else {\n                    // Item i is unselected: Check Add moves\n                    let i = j;\n                    let w_i = weights[i];\n\n                    // --- Add Move (i in) ---\n                    // Delta V = MG[i]\n                    if current_weight.checked_add(w_i).map_or(false, |w| w <= max_weight) {\n                        let delta_v_add_i = marginal_gains[i];\n\n                        if delta_v_add_i > best_delta_v {\n                            best_delta_v = delta_v_add_i;\n                            best_move = Some(LS_Move::Add(i));\n                        }\n                    }\n                }\n            }\n\n            if best_delta_v > 0 {\n                *current_value += best_delta_v;\n\n                match best_move.unwrap() {\n                    LS_Move::Add(i) => {\n                        is_selected[i] = true;\n                        *current_weight += weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] += interactions[i][k] as i64;\n                        }\n                    }\n                    LS_Move::Remove(j) => {\n                        is_selected[j] = false;\n                        *current_weight -= weights[j];\n                        for k in 0..num_items {\n                            marginal_gains[k] -= interactions[j][k] as i64;\n                        }\n                    }\n                    LS_Move::Swap(j, i) => {\n                        is_selected[j] = false;\n                        is_selected[i] = true;\n                        *current_weight = *current_weight - weights[j] + weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] = marginal_gains[k] - interactions[j][k] as i64 + interactions[i][k] as i64;\n                        }\n                    }\n                }\n            } else {\n                break; // Local optimum reached\n            }\n        }\n    };\n\n\n\n    // --- 1. Initial Greedy Construction Phase (O(N^2)) ---\n    loop {\n        let mut best_item: Option<usize> = None;\n        let mut best_density: f64 = f64::NEG_INFINITY;\n\n        for i in 0..num_items {\n            if !is_selected[i] {\n                let item_weight = weights[i];\n                if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                    let gain = marginal_gains[i];\n                    \n                    let density = if item_weight == 0 {\n                        if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                    } else {\n                        gain as f64 / item_weight as f64\n                    };\n\n                    if density > best_density {\n                        best_density = density;\n                        best_item = Some(i);\n                    }\n                }\n            }\n        }\n\n        if let Some(idx_to_add) = best_item {\n            // Update value incrementally\n            current_value += marginal_gains[idx_to_add]; \n            \n            is_selected[idx_to_add] = true;\n            current_weight += weights[idx_to_add];\n\n            // Update marginal gains for ALL items (O(N) step). \n            for i in 0..num_items {\n                marginal_gains[i] += interactions[idx_to_add][i] as i64;\n            }\n        } else {\n            break;\n        }\n    }\n    \n    // Initialize best solution tracking (current_value is already correct)\n    best_value = current_value;\n    best_solution = is_selected.clone();\n\n    // --- 2. Iterated Local Search (ILS) with Adaptive Perturbation ---\n    let mut iterations_since_best_update = 0;\n    let mut dynamic_perturbation_size = hyperparameters.base_perturbation_size;\n\n    for restart in 0..hyperparameters.max_restarts {\n        \n        // A. Run BILS on the current state until local optimum is reached\n        run_bils(&mut is_selected, &mut current_weight, &mut marginal_gains, &mut current_value);\n\n        // B. Update Best Solution and adapt perturbation strength\n        if current_value > best_value {\n            best_value = current_value;\n            best_solution = is_selected.clone();\n            iterations_since_best_update = 0;\n            // On improvement, reset perturbation strength to base to focus search locally\n            dynamic_perturbation_size = hyperparameters.base_perturbation_size;\n        } else {\n            iterations_since_best_update += 1;\n        }\n\n        if iterations_since_best_update >= hyperparameters.stagnation_limit {\n            // Stagnation detected: increase perturbation strength to escape\n            dynamic_perturbation_size = (dynamic_perturbation_size as f64 * hyperparameters.perturbation_increase_factor).round() as usize;\n            // Cap the size to avoid destroying the solution completely\n            let max_p_size = (num_items as f64 * 0.4) as usize; // Don't remove more than 40% of items\n            dynamic_perturbation_size = dynamic_perturbation_size.min(max_p_size);\n            iterations_since_best_update = 0; // Reset counter after strengthening\n        }\n\n        if restart == hyperparameters.max_restarts - 1 {\n            break; // No need to perturb after the last optimization run\n        }\n\n        // C. Perturbation Phase (Biased removal + Incremental Repair)\n        let mut selected_indices: Vec<usize> = (0..num_items).filter(|&i| is_selected[i]).collect();\n        let num_selected = selected_indices.len();\n        \n        let p_size = dynamic_perturbation_size.min(num_selected);\n        \n        // 1. & 2. Biasedly remove P_size items and update state incrementally (O(P*N))\n        for _ in 0..p_size {\n            if selected_indices.is_empty() { break; }\n\n            // Calculate MG_max for normalization (O(N_selected))\n            let mg_max = selected_indices.iter()\n                .map(|&i| marginal_gains[i])\n                .max()\n                .unwrap_or(1); \n\n            // Calculate weights: S_j = MG_max - MG_j + 1 (Bias towards low MG items)\n            let mut total_weight = 0i64;\n            let weights_and_indices: Vec<(i64, usize)> = selected_indices.iter().map(|&j| {\n                // Ensure weight is positive and non-zero. \n                let weight = mg_max - marginal_gains[j] + 1; \n                total_weight += weight;\n                (weight, j)\n            }).collect();\n\n            // Select item j using roulette wheel selection (O(N_selected))\n            let target = rng.gen_range(0..total_weight);\n            let mut cumulative_weight = 0i64;\n            \n            let mut removal_index_in_vec = 0; // Index in selected_indices vector\n            \n            for (idx, &(weight, _)) in weights_and_indices.iter().enumerate() {\n                cumulative_weight += weight;\n                if cumulative_weight > target {\n                    removal_index_in_vec = idx;\n                    break;\n                }\n            }\n            \n            // Retrieve item index j and remove it from selected_indices (O(1) using swap_remove)\n            let j = selected_indices.swap_remove(removal_index_in_vec);\n\n            // Update value incrementally using the current marginal gain\n            current_value -= marginal_gains[j];\n            \n            is_selected[j] = false;\n            current_weight -= weights[j];\n\n            // Update marginal gains for all other items due to j's removal (O(N))\n            for k in 0..num_items {\n                marginal_gains[k] -= interactions[j][k] as i64;\n            }\n        }\n\n        // 3. Greedy Repair (Add items back based on marginal density)\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_density: f64 = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = weights[i];\n                    if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                        let gain = marginal_gains[i];\n                        \n                        let density = if item_weight == 0 {\n                            if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                        } else {\n                            gain as f64 / item_weight as f64\n                        };\n\n                        if density > best_density {\n                            best_density = density;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(idx_to_add) = best_item {\n                is_selected[idx_to_add] = true;\n                current_weight += weights[idx_to_add];\n                current_value += marginal_gains[idx_to_add]; // Update value incrementally\n\n                // Update marginal gains for ALL items (O(N) step). \n                for i in 0..num_items {\n                    marginal_gains[i] += interactions[idx_to_add][i] as i64;\n                }\n            } else {\n                break;\n            }\n        }\n    }\n\n    // Finalize solution indices from the best solution found\n    let selected: Vec<usize> = (0..num_items).filter(|&i| best_solution[i]).collect();\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}\n```\nUnique approach: Modification: Change 1: Replace 180 lines with 325 lines, Alternative avg_btb approach, Excellent eval_time (12.414)\n\n# Current Program\n```rust\n// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub max_iterations: usize,\n        pub initial_temperature: f64,\n        pub cooling_rate: f64,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .map_err(|e| anyhow!(\"Failed to parse hyperparameters: {}\", e))?\n        }\n        None => Hyperparameters {\n            max_iterations: 100_000, // Increased iterations for better convergence\n            initial_temperature: 1000.0, \n            cooling_rate: 0.9999, \n        },\n    };\n    \n    let mut rng = SmallRng::from_seed(challenge.seed);\n\n    // Helper function to calculate total value of the current selection\n    fn calculate_value(\n        selected_indices: &[usize],\n        challenge: &Challenge,\n        interaction_sums: &[i64],\n    ) -> i64 {\n        let mut total_value = 0i64;\n        let mut total_interaction_sum = 0i64;\n        \n        for &i in selected_indices {\n            total_value += challenge.values[i] as i64;\n            total_interaction_sum += interaction_sums[i];\n        }\n        \n        // Total value = Sum(V_i) + 0.5 * Sum_{i in S} I_sum_i\n        total_value + total_interaction_sum / 2\n    }\n\n    // Phase 1: Iterative greedy construction heuristic.\n    // At each step, it adds the item with the highest marginal gain-to-weight ratio.\n    let num_items = challenge.values.len();\n    let mut selected = Vec::new();\n\n    if num_items > 0 {\n        let mut total_weight: u32 = 0;\n        let mut is_selected = vec![false; num_items];\n        let mut marginal_gains: Vec<f64> = challenge.values.iter().map(|&v| v as f64).collect();\n\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_ratio = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = challenge.weights[i];\n                    if total_weight + item_weight <= challenge.max_weight {\n                        let ratio = if item_weight > 0 {\n                            marginal_gains[i] / item_weight as f64\n                        } else {\n                            if marginal_gains[i] > 0.0 {\n                                f64::INFINITY\n                            } else {\n                                f64::NEG_INFINITY\n                            }\n                        };\n\n                        if ratio > best_ratio {\n                            best_ratio = ratio;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(item_to_add) = best_item {\n                selected.push(item_to_add);\n                is_selected[item_to_add] = true;\n                total_weight += challenge.weights[item_to_add];\n\n                for i in 0..num_items {\n                    if !is_selected[i] {\n                        marginal_gains[i] += challenge.interaction_values[item_to_add][i] as f64;\n                    }\n                }\n            } else {\n                break;\n            }\n        }\n\n        // Phase 2: Simulated Annealing (SA)\n        if !selected.is_empty() {\n            let mut current_interaction_sums = vec![0i64; num_items];\n            for i in 0..num_items {\n                for &k in &selected {\n                    current_interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                }\n            }\n            \n            let mut current_value = calculate_value(&selected, challenge, &current_interaction_sums);\n            let mut best_value = current_value;\n            let mut best_selected = selected.clone();\n            \n            let mut temperature = hyperparameters.initial_temperature;\n            let cooling_rate = hyperparameters.cooling_rate;\n\n            #[derive(Debug, Clone, Copy)]\n            enum Move {\n                Add(usize), \n                Drop(usize), // Index in `selected` vector\n                Swap(usize, usize), // Index in `selected` vector, item index\n            }\n\n            for _ in 0..hyperparameters.max_iterations {\n                if temperature < 1e-6 {\n                    break; \n                }\n\n                let mut moves = Vec::new();\n\n                // --- 1. Identify feasible Insertion (Add item j) ---\n                for item_j in 0..num_items {\n                    if !is_selected[item_j] {\n                        let item_weight = challenge.weights[item_j];\n                        if total_weight + item_weight <= challenge.max_weight {\n                            let delta_value = challenge.values[item_j] as i64 + current_interaction_sums[item_j];\n                            moves.push((Move::Add(item_j), delta_value));\n                        }\n                    }\n                }\n\n                // --- 2. Identify feasible Removal (Drop item i) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx];\n                    let delta_value = -(challenge.values[item_i] as i64 + current_interaction_sums[item_i]);\n                    moves.push((Move::Drop(i_vec_idx), delta_value));\n                }\n\n                // --- 3. Identify feasible Swap (Drop item i, Add item j) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx];\n                    for item_j in 0..num_items {\n                        if is_selected[item_j] { continue; }\n\n                        let delta_weight = challenge.weights[item_j] as i64 - challenge.weights[item_i] as i64;\n                        if (total_weight as i64 + delta_weight) <= challenge.max_weight as i64 {\n                            let delta_value = (challenge.values[item_j] as i64 - challenge.values[item_i] as i64)\n                                            + (current_interaction_sums[item_j] - challenge.interaction_values[item_j][item_i] as i64)\n                                            - current_interaction_sums[item_i];\n                            moves.push((Move::Swap(i_vec_idx, item_j), delta_value));\n                        }\n                    }\n                }\n\n                if moves.is_empty() {\n                    break; // No feasible moves left\n                }\n\n                // --- Select and Evaluate Move (Randomly choose one move) ---\n                let move_idx = rng.gen_range(0..moves.len());\n                let (move_to_execute, delta_value) = moves[move_idx];\n                \n                let acceptance_prob = if delta_value >= 0 {\n                    1.0 // Always accept improving or neutral moves\n                } else {\n                    // Boltzmann acceptance criterion for worsening moves\n                    if temperature > 0.0 {\n                        let exponent = (delta_value as f64) / temperature;\n                        exponent.exp()\n                    } else {\n                        0.0 // Reject if temperature is zero or negative\n                    }\n                };\n\n                if acceptance_prob > rng.gen::<f64>() {\n                    // Execute Move\n                    match move_to_execute {\n                        Move::Add(item_j_to_add) => {\n                            let item_weight = challenge.weights[item_j_to_add];\n                            total_weight += item_weight;\n                            is_selected[item_j_to_add] = true;\n                            selected.push(item_j_to_add);\n\n                            for k in 0..num_items {\n                                current_interaction_sums[k] += challenge.interaction_values[k][item_j_to_add] as i64;\n                            }\n                        }\n                        Move::Drop(i_vec_idx_to_drop) => {\n                            let item_i_to_drop = selected.swap_remove(i_vec_idx_to_drop);\n                            total_weight -= challenge.weights[item_i_to_drop];\n                            is_selected[item_i_to_drop] = false;\n\n                            for k in 0..num_items {\n                                current_interaction_sums[k] -= challenge.interaction_values[k][item_i_to_drop] as i64;\n                            }\n                        }\n                        Move::Swap(i_vec_idx_to_swap, item_j_to_add) => {\n                            let item_i_to_drop = selected[i_vec_idx_to_swap];\n\n                            let delta_weight = challenge.weights[item_j_to_add] as i64 - challenge.weights[item_i_to_drop] as i64;\n                            total_weight = (total_weight as i64 + delta_weight) as u32;\n\n                            is_selected[item_i_to_drop] = false;\n                            is_selected[item_j_to_add] = true;\n                            selected[i_vec_idx_to_swap] = item_j_to_add;\n\n                            for k in 0..num_items {\n                                current_interaction_sums[k] += (challenge.interaction_values[k][item_j_to_add] - challenge.interaction_values[k][item_i_to_drop]) as i64;\n                            }\n                        }\n                    }\n                    \n                    current_value += delta_value;\n\n                    if current_value > best_value {\n                        best_value = current_value;\n                        best_selected = selected.clone();\n                    }\n                }\n\n                // Cool down\n                temperature *= cooling_rate;\n            }\n            \n            selected = best_selected;\n        }\n    }\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: score, complexity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["<<<<<<< SEARCH\n#[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub max_iterations: usize,\n        pub initial_temperature: f64,\n        pub cooling_rate: f64,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .map_err(|e| anyhow!(\"Failed to parse hyperparameters: {}\", e))?\n        }\n        None => Hyperparameters {\n            max_iterations: 100_000, // Increased iterations for better convergence\n            initial_temperature: 1000.0, \n            cooling_rate: 0.9999, \n        },\n    };\n    \n    let mut rng = SmallRng::from_seed(challenge.seed);\n\n    // Helper function to calculate total value of the current selection\n    fn calculate_value(\n        selected_indices: &[usize],\n        challenge: &Challenge,\n        interaction_sums: &[i64],\n    ) -> i64 {\n        let mut total_value = 0i64;\n        let mut total_interaction_sum = 0i64;\n        \n        for &i in selected_indices {\n            total_value += challenge.values[i] as i64;\n            total_interaction_sum += interaction_sums[i];\n        }\n        \n        // Total value = Sum(V_i) + 0.5 * Sum_{i in S} I_sum_i\n        total_value + total_interaction_sum / 2\n    }\n\n    // Phase 1: Iterative greedy construction heuristic.\n    // At each step, it adds the item with the highest marginal gain-to-weight ratio.\n    let num_items = challenge.values.len();\n    let mut selected = Vec::new();\n\n    if num_items > 0 {\n        let mut total_weight: u32 = 0;\n        let mut is_selected = vec![false; num_items];\n        let mut marginal_gains: Vec<f64> = challenge.values.iter().map(|&v| v as f64).collect();\n\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_ratio = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = challenge.weights[i];\n                    if total_weight + item_weight <= challenge.max_weight {\n                        let ratio = if item_weight > 0 {\n                            marginal_gains[i] / item_weight as f64\n                        } else {\n                            if marginal_gains[i] > 0.0 {\n                                f64::INFINITY\n                            } else {\n                                f64::NEG_INFINITY\n                            }\n                        };\n\n                        if ratio > best_ratio {\n                            best_ratio = ratio;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(item_to_add) = best_item {\n                selected.push(item_to_add);\n                is_selected[item_to_add] = true;\n                total_weight += challenge.weights[item_to_add];\n\n                for i in 0..num_items {\n                    if !is_selected[i] {\n                        marginal_gains[i] += challenge.interaction_values[item_to_add][i] as f64;\n                    }\n                }\n            } else {\n                break;\n            }\n        }\n\n        // Phase 2: Simulated Annealing (SA)\n        if !selected.is_empty() {\n            let mut current_interaction_sums = vec![0i64; num_items];\n            for i in 0..num_items {\n                for &k in &selected {\n                    current_interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                }\n            }\n            \n            let mut current_value = calculate_value(&selected, challenge, &current_interaction_sums);\n            let mut best_value = current_value;\n            let mut best_selected = selected.clone();\n            \n            let mut temperature = hyperparameters.initial_temperature;\n            let cooling_rate = hyperparameters.cooling_rate;\n\n            #[derive(Debug, Clone, Copy)]\n            enum Move {\n                Add(usize), \n                Drop(usize), // Index in `selected` vector\n                Swap(usize, usize), // Index in `selected` vector, item index\n            }\n\n            for _ in 0..hyperparameters.max_iterations {\n                if temperature < 1e-6 {\n                    break; \n                }\n\n                let mut moves = Vec::new();\n\n                // --- 1. Identify feasible Insertion (Add item j) ---\n                for item_j in 0..num_items {\n                    if !is_selected[item_j] {\n                        let item_weight = challenge.weights[item_j];\n                        if total_weight + item_weight <= challenge.max_weight {\n                            let delta_value = challenge.values[item_j] as i64 + current_interaction_sums[item_j];\n                            moves.push((Move::Add(item_j), delta_value));\n                        }\n                    }\n                }\n\n                // --- 2. Identify feasible Removal (Drop item i) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx];\n                    let delta_value = -(challenge.values[item_i] as i64 + current_interaction_sums[item_i]);\n                    moves.push((Move::Drop(i_vec_idx), delta_value));\n                }\n\n                // --- 3. Identify feasible Swap (Drop item i, Add item j) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx];\n                    for item_j in 0..num_items {\n                        if is_selected[item_j] { continue; }\n\n                        let delta_weight = challenge.weights[item_j] as i64 - challenge.weights[item_i] as i64;\n                        if (total_weight as i64 + delta_weight) <= challenge.max_weight as i64 {\n                            let delta_value = (challenge.values[item_j] as i64 - challenge.values[item_i] as i64)\n                                            + (current_interaction_sums[item_j] - challenge.interaction_values[item_j][item_i] as i64)\n                                            - current_interaction_sums[item_i];\n                            moves.push((Move::Swap(i_vec_idx, item_j), delta_value));\n                        }\n                    }\n                }\n\n                if moves.is_empty() {\n                    break; // No feasible moves left\n                }\n\n                // --- Select and Evaluate Move (Randomly choose one move) ---\n                let move_idx = rng.gen_range(0..moves.len());\n                let (move_to_execute, delta_value) = moves[move_idx];\n                \n                let acceptance_prob = if delta_value >= 0 {\n                    1.0 // Always accept improving or neutral moves\n                } else {\n                    // Boltzmann acceptance criterion for worsening moves\n                    if temperature > 0.0 {\n                        let exponent = (delta_value as f64) / temperature;\n                        exponent.exp()\n                    } else {\n                        0.0 // Reject if temperature is zero or negative\n                    }\n                };\n\n                if acceptance_prob > rng.gen::<f64>() {\n                    // Execute Move\n                    match move_to_execute {\n                        Move::Add(item_j_to_add) => {\n                            let item_weight = challenge.weights[item_j_to_add];\n                            total_weight += item_weight;\n                            is_selected[item_j_to_add] = true;\n                            selected.push(item_j_to_add);\n\n                            for k in 0..num_items {\n                                current_interaction_sums[k] += challenge.interaction_values[k][item_j_to_add] as i64;\n                            }\n                        }\n                        Move::Drop(i_vec_idx_to_drop) => {\n                            let item_i_to_drop = selected.swap_remove(i_vec_idx_to_drop);\n                            total_weight -= challenge.weights[item_i_to_drop];\n                            is_selected[item_i_to_drop] = false;\n\n                            for k in 0..num_items {\n                                current_interaction_sums[k] -= challenge.interaction_values[k][item_i_to_drop] as i64;\n                            }\n                        }\n                        Move::Swap(i_vec_idx_to_swap, item_j_to_add) => {\n                            let item_i_to_drop = selected[i_vec_idx_to_swap];\n\n                            let delta_weight = challenge.weights[item_j_to_add] as i64 - challenge.weights[item_i_to_drop] as i64;\n                            total_weight = (total_weight as i64 + delta_weight) as u32;\n\n                            is_selected[item_i_to_drop] = false;\n                            is_selected[item_j_to_add] = true;\n                            selected[i_vec_idx_to_swap] = item_j_to_add;\n\n                            for k in 0..num_items {\n                                current_interaction_sums[k] += (challenge.interaction_values[k][item_j_to_add] - challenge.interaction_values[k][item_i_to_drop]) as i64;\n                            }\n                        }\n                    }\n                    \n                    current_value += delta_value;\n\n                    if current_value > best_value {\n                        best_value = current_value;\n                        best_selected = selected.clone();\n                    }\n                }\n\n                // Cool down\n                temperature *= cooling_rate;\n            }\n            \n            selected = best_selected;\n        }\n    }\n=======\n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub max_restarts: usize,\n        pub base_perturbation_size: usize,\n        pub stagnation_limit: usize,\n        pub perturbation_increase_factor: f64,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .unwrap_or(Hyperparameters {\n                    max_restarts: 250, \n                    base_perturbation_size: 20,\n                    stagnation_limit: 30, \n                    perturbation_increase_factor: 1.25,\n                })\n        }\n        None => Hyperparameters {\n            max_restarts: 250,\n            base_perturbation_size: 20,\n            stagnation_limit: 30,\n            perturbation_increase_factor: 1.25,\n        },\n    };\n\n    let num_items = challenge.values.len();\n    let weights = &challenge.weights;\n    let values = &challenge.values;\n    let interactions = &challenge.interaction_values;\n    let max_weight = challenge.max_weight;\n\n    let mut rng = SmallRng::from_seed(challenge.seed);\n\n    // --- State Variables (Current Solution) ---\n    let mut is_selected = vec![false; num_items];\n    let mut current_weight: u32 = 0;\n    // Marginal gains initialized with base values\n    // MG[k] = V_k + Sum_{l in S} I_{k,l}. Initially S is empty, so MG[k] = V_k.\n    let mut marginal_gains: Vec<i64> = values.iter().map(|&v| v as i64).collect();\n    let mut current_value: i64 = 0;\n\n    // --- Best Solution Tracking ---\n    let mut best_solution = vec![false; num_items];\n    let mut best_value = i64::MIN;\n\n    #[derive(Debug, Clone, Copy)]\n    enum LS_Move {\n        Add(usize),\n        Remove(usize),\n        Swap(usize, usize), // (item_to_remove, item_to_add)\n    }\n\n    // Helper function to run Best Improvement Local Search (BILS) until convergence\n    // Modifies state variables in place.\n    let mut run_bils = |\n        is_selected: &mut Vec<bool>,\n        current_weight: &mut u32,\n        marginal_gains: &mut Vec<i64>,\n        current_value: &mut i64\n    | {\n        loop {\n            let mut best_delta_v = 0i64;\n            let mut best_move: Option<LS_Move> = None;\n\n            // O(N^2) neighborhood search\n            for j in 0..num_items {\n                if is_selected[j] {\n                    // Item j is selected: Check Remove and Swap moves involving j\n\n                    // --- Remove Move (j out) ---\n                    // Delta V = -MG[j]\n                    let delta_v_remove_j = -marginal_gains[j];\n                    if delta_v_remove_j > best_delta_v {\n                        best_delta_v = delta_v_remove_j;\n                        best_move = Some(LS_Move::Remove(j));\n                    }\n\n                    // --- Swap Moves (j out, i in) ---\n                    let w_j = weights[j];\n                    \n                    for i in 0..num_items {\n                        if !is_selected[i] {\n                            let w_i = weights[i];\n                            \n                            // Check weight constraint for swap\n                            let delta_w = w_i as i64 - w_j as i64;\n                            if (*current_weight as i64 + delta_w) <= max_weight as i64 {\n                                \n                                // Delta V(j out, i in) = MG[i] - interactions[i][j] - MG[j]\n                                let delta_v_swap = marginal_gains[i] - interactions[i][j] as i64 - marginal_gains[j];\n\n                                if delta_v_swap > best_delta_v {\n                                    best_delta_v = delta_v_swap;\n                                    best_move = Some(LS_Move::Swap(j, i));\n                                }\n                            }\n                        }\n                    }\n                } else {\n                    // Item i is unselected: Check Add moves\n                    let i = j;\n                    let w_i = weights[i];\n\n                    // --- Add Move (i in) ---\n                    // Delta V = MG[i]\n                    if current_weight.checked_add(w_i).map_or(false, |w| w <= max_weight) {\n                        let delta_v_add_i = marginal_gains[i];\n\n                        if delta_v_add_i > best_delta_v {\n                            best_delta_v = delta_v_add_i;\n                            best_move = Some(LS_Move::Add(i));\n                        }\n                    }\n                }\n            }\n\n            if best_delta_v > 0 {\n                *current_value += best_delta_v;\n\n                match best_move.unwrap() {\n                    LS_Move::Add(i) => {\n                        is_selected[i] = true;\n                        *current_weight += weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] += interactions[i][k] as i64;\n                        }\n                    }\n                    LS_Move::Remove(j) => {\n                        is_selected[j] = false;\n                        *current_weight -= weights[j];\n                        for k in 0..num_items {\n                            marginal_gains[k] -= interactions[j][k] as i64;\n                        }\n                    }\n                    LS_Move::Swap(j, i) => {\n                        is_selected[j] = false;\n                        is_selected[i] = true;\n                        *current_weight = *current_weight - weights[j] + weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] = marginal_gains[k] - interactions[j][k] as i64 + interactions[i][k] as i64;\n                        }\n                    }\n                }\n            } else {\n                break; // Local optimum reached\n            }\n        }\n    };\n\n\n\n    // --- 1. Initial Greedy Construction Phase (O(N^2)) ---\n    // Note: Marginal gains are calculated using f64 in the greedy phase for density calculation, \n    // but stored as i64 for the subsequent BILS/ILS phases. We must ensure consistency.\n    \n    loop {\n        let mut best_item: Option<usize> = None;\n        let mut best_density: f64 = f64::NEG_INFINITY;\n\n        for i in 0..num_items {\n            if !is_selected[i] {\n                let item_weight = weights[i];\n                if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                    let gain = marginal_gains[i];\n                    \n                    let density = if item_weight == 0 {\n                        if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                    } else {\n                        gain as f64 / item_weight as f64\n                    };\n\n                    if density > best_density {\n                        best_density = density;\n                        best_item = Some(i);\n                    }\n                }\n            }\n        }\n\n        if let Some(idx_to_add) = best_item {\n            // Update value incrementally\n            current_value += marginal_gains[idx_to_add]; \n            \n            is_selected[idx_to_add] = true;\n            current_weight += weights[idx_to_add];\n\n            // Update marginal gains for ALL items (O(N) step). \n            for i in 0..num_items {\n                marginal_gains[i] += interactions[idx_to_add][i] as i64;\n            }\n        } else {\n            break;\n        }\n    }\n    \n    // Initialize best solution tracking (current_value is already correct)\n    best_value = current_value;\n    best_solution = is_selected.clone();\n\n    // --- 2. Iterated Local Search (ILS) with Adaptive Perturbation ---\n    let mut iterations_since_best_update = 0;\n    let mut dynamic_perturbation_size = hyperparameters.base_perturbation_size;\n\n    for restart in 0..hyperparameters.max_restarts {\n        \n        // A. Run BILS on the current state until local optimum is reached\n        run_bils(&mut is_selected, &mut current_weight, &mut marginal_gains, &mut current_value);\n\n        // B. Update Best Solution and adapt perturbation strength\n        if current_value > best_value {\n            best_value = current_value;\n            best_solution = is_selected.clone();\n            iterations_since_best_update = 0;\n            // On improvement, reset perturbation strength to base to focus search locally\n            dynamic_perturbation_size = hyperparameters.base_perturbation_size;\n        } else {\n            iterations_since_best_update += 1;\n        }\n\n        if iterations_since_best_update >= hyperparameters.stagnation_limit {\n            // Stagnation detected: increase perturbation strength to escape\n            dynamic_perturbation_size = (dynamic_perturbation_size as f64 * hyperparameters.perturbation_increase_factor).round() as usize;\n            // Cap the size to avoid destroying the solution completely\n            let max_p_size = (num_items as f64 * 0.4) as usize; // Don't remove more than 40% of items\n            dynamic_perturbation_size = dynamic_perturbation_size.min(max_p_size);\n            iterations_since_best_update = 0; // Reset counter after strengthening\n        }\n\n        if restart == hyperparameters.max_restarts - 1 {\n            break; // No need to perturb after the last optimization run\n        }\n\n        // C. Perturbation Phase (Biased removal + Incremental Repair)\n        let mut selected_indices: Vec<usize> = (0..num_items).filter(|&i| is_selected[i]).collect();\n        let num_selected = selected_indices.len();\n        \n        let p_size = dynamic_perturbation_size.min(num_selected);\n        \n        // 1. & 2. Biasedly remove P_size items and update state incrementally (O(P*N))\n        for _ in 0..p_size {\n            if selected_indices.is_empty() { break; }\n\n            // Calculate MG_max for normalization (O(N_selected))\n            let mg_max = selected_indices.iter()\n                .map(|&i| marginal_gains[i])\n                .max()\n                .unwrap_or(1); \n\n            // Calculate weights: S_j = MG_max - MG_j + 1 (Bias towards low MG items)\n            let mut total_weight = 0i64;\n            let weights_and_indices: Vec<(i64, usize)> = selected_indices.iter().map(|&j| {\n                // Ensure weight is positive and non-zero. \n                let weight = mg_max - marginal_gains[j] + 1; \n                total_weight += weight;\n                (weight, j)\n            }).collect();\n\n            // Select item j using roulette wheel selection (O(N_selected))\n            let target = rng.gen_range(0..total_weight);\n            let mut cumulative_weight = 0i64;\n            \n            let mut removal_index_in_vec = 0; // Index in selected_indices vector\n            \n            for (idx, &(weight, _)) in weights_and_indices.iter().enumerate() {\n                cumulative_weight += weight;\n                if cumulative_weight > target {\n                    removal_index_in_vec = idx;\n                    break;\n                }\n            }\n            \n            // Retrieve item index j and remove it from selected_indices (O(1) using swap_remove)\n            let j = selected_indices.swap_remove(removal_index_in_vec);\n\n            // Update value incrementally using the current marginal gain\n            current_value -= marginal_gains[j];\n            \n            is_selected[j] = false;\n            current_weight -= weights[j];\n\n            // Update marginal gains for all other items due to j's removal (O(N))\n            for k in 0..num_items {\n                marginal_gains[k] -= interactions[j][k] as i64;\n            }\n        }\n\n        // 3. Greedy Repair (Add items back based on marginal density)\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_density: f64 = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = weights[i];\n                    if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                        let gain = marginal_gains[i];\n                        \n                        let density = if item_weight == 0 {\n                            if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                        } else {\n                            gain as f64 / item_weight as f64\n                        };\n\n                        if density > best_density {\n                            best_density = density;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(idx_to_add) = best_item {\n                is_selected[idx_to_add] = true;\n                current_weight += weights[idx_to_add];\n                current_value += marginal_gains[idx_to_add]; // Update value incrementally\n\n                // Update marginal gains for ALL items (O(N) step). \n                for i in 0..num_items {\n                    marginal_gains[i] += interactions[idx_to_add][i] as i64;\n                }\n            } else {\n                break;\n            }\n        }\n    }\n\n    // Finalize solution indices from the best solution found\n    let selected: Vec<usize> = (0..num_items).filter(|&i| best_solution[i]).collect();\n>>>>>>> REPLACE"]}}, "artifacts_json": "{\"timeout\": true, \"timeout_duration\": 1200, \"failure_stage\": \"evaluation\", \"error_type\": \"timeout\"}", "artifact_dir": null, "embedding": null}