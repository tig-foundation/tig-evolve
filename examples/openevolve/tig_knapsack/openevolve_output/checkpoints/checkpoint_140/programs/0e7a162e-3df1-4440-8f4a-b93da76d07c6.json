{"id": "0e7a162e-3df1-4440-8f4a-b93da76d07c6", "code": "// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    let num_items = challenge.values.len();\n\n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub tabu_iterations: usize,\n        pub tabu_tenure: usize,\n        pub non_improving_limit: usize,\n        pub tie_breaking_prob: f64,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .map_err(|e| anyhow!(\"Failed to parse hyperparameters: {}\", e))?\n        }\n        None => Hyperparameters {\n            tabu_iterations: 10000,\n            // A dynamic tenure based on problem size often works well.\n            tabu_tenure: ((num_items as f64).sqrt().round() as usize).max(5),\n            non_improving_limit: 1000,\n            tie_breaking_prob: 0.1,\n        },\n    };\n\n    // Phase 1: Iterative greedy construction heuristic.\n    // At each step, it adds the item with the highest marginal gain-to-weight ratio.\n    let mut selected = Vec::new();\n\n    if num_items > 0 {\n        let mut total_weight: u32 = 0;\n        let mut is_selected = vec![false; num_items];\n        let mut marginal_gains: Vec<f64> = challenge.values.iter().map(|&v| v as f64).collect();\n\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_ratio = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = challenge.weights[i];\n                    if total_weight + item_weight <= challenge.max_weight {\n                        let ratio = if item_weight > 0 {\n                            marginal_gains[i] / item_weight as f64\n                        } else {\n                            if marginal_gains[i] > 0.0 {\n                                f64::INFINITY\n                            } else {\n                                f64::NEG_INFINITY\n                            }\n                        };\n\n                        if ratio > best_ratio {\n                            best_ratio = ratio;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(item_to_add) = best_item {\n                selected.push(item_to_add);\n                is_selected[item_to_add] = true;\n                total_weight += challenge.weights[item_to_add];\n\n                for i in 0..num_items {\n                    if !is_selected[i] {\n                        marginal_gains[i] += challenge.interaction_values[item_to_add][i] as f64;\n                    }\n                }\n            } else {\n                break;\n            }\n        }\n\n        // Phase 2: Local search (1-opt swap) to improve the greedy solution.\n        // This phase iterates and performs the best possible swap (one item in, one item out)\n        // until no further improvements can be made.\n        if !selected.is_empty() {\n            let mut interaction_sums = vec![0i64; num_items];\n            for i in 0..num_items {\n                for &k in &selected {\n                    interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                }\n            }\n\n            // Calculate initial value\n            let mut current_value: i64 = 0;\n            for &i in &selected {\n                current_value += challenge.values[i] as i64;\n                // Summing interaction_sums[i] over i in selected counts interactions twice.\n                current_value += interaction_sums[i] / 2;\n            }\n\n            let mut best_value = current_value;\n            let mut best_selected = selected.clone();\n            let mut best_total_weight = total_weight;\n\n            let mut rng = SmallRng::from_seed(challenge.seed);\n            let mut iterations_since_best_update = 0;\n\n            // Phase 2: Tabu Search (1-opt swap)\n            // Tabu List: stores the iteration when an item's removal restriction expires.\n            let mut tabu_list = vec![0usize; num_items];\n            let tabu_tenure = hyperparameters.tabu_tenure;\n            let max_iterations = hyperparameters.tabu_iterations;\n            let non_improving_limit = hyperparameters.non_improving_limit;\n            let tie_breaking_prob = hyperparameters.tie_breaking_prob;\n\n            // Define move types for clarity\n            enum Move {\n                Swap { i_vec_idx: usize, j_idx: usize },\n                Add { j_idx: usize },\n                Remove { i_vec_idx: usize },\n            }\n\n            for iteration in 1..=max_iterations {\n                iterations_since_best_update += 1;\n                let mut best_move: Option<(Move, i64)> = None;\n                let mut best_delta = i64::MIN;\n\n                // --- 1. Search Swap neighborhood (i out, j in) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx]; // Item to remove\n\n                    for item_j in 0..num_items { // Item to add\n                        if is_selected[item_j] { continue; }\n\n                        // 1. Check weight constraint\n                        let delta_weight = challenge.weights[item_j] as i64 - challenge.weights[item_i] as i64;\n                        if (total_weight as i64 + delta_weight) > challenge.max_weight as i64 {\n                            continue;\n                        }\n\n                        // 2. Calculate Delta Value\n                        // Delta V = (v_j - v_i) + (interaction_sums[j] - c_{ji}) - interaction_sums[i]\n                        let delta_value = (challenge.values[item_j] as i64 - challenge.values[item_i] as i64)\n                                        + (interaction_sums[item_j] - challenge.interaction_values[item_j][item_i] as i64)\n                                        - interaction_sums[item_i];\n\n                        let new_value = current_value + delta_value;\n\n                        // 3. Tabu Check & Aspiration Criterion\n                        // Item i (removed) is tabu from being added back.\n                        let is_tabu = tabu_list[item_i] > iteration;\n                        let is_aspirated = is_tabu && (new_value > best_value);\n\n                        if !is_tabu || is_aspirated {\n                            if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(tie_breaking_prob)) {\n                                best_delta = delta_value;\n                                best_move = Some((Move::Swap { i_vec_idx, j_idx: item_j }, delta_value));\n                            }\n                        }\n                    }\n                }\n\n                // --- 2. Search Add neighborhood (j in) ---\n                for item_j in 0..num_items {\n                    if is_selected[item_j] { continue; }\n                    let item_weight = challenge.weights[item_j];\n\n                    if total_weight + item_weight <= challenge.max_weight {\n                        // Delta V = v_j + interaction_sums[j]\n                        let delta_value = challenge.values[item_j] as i64 + interaction_sums[item_j];\n                        \n                        if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(tie_breaking_prob)) {\n                            best_delta = delta_value;\n                            best_move = Some((Move::Add { j_idx: item_j }, delta_value));\n                        }\n                    }\n                }\n\n                // --- 3. Search Remove neighborhood (i out) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx]; // Item to remove\n\n                    // Delta V = -v_i - interaction_sums[i]\n                    let delta_value = -(challenge.values[item_i] as i64 + interaction_sums[item_i]);\n                    let new_value = current_value + delta_value;\n\n                    // Tabu Check: Item i (removed) is tabu from being added back.\n                    let is_tabu = tabu_list[item_i] > iteration;\n                    let is_aspirated = is_tabu && (new_value > best_value);\n\n                    if !is_tabu || is_aspirated {\n                        if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(tie_breaking_prob)) {\n                            best_delta = delta_value;\n                            best_move = Some((Move::Remove { i_vec_idx }, delta_value));\n                        }\n                    }\n                }\n\n                // If no feasible move (respecting weight constraint) is found, stop.\n                if best_move.is_none() {\n                    break;\n                }\n\n                // Perform the best move found\n                let (move_type, delta) = best_move.unwrap();\n                current_value += delta;\n\n                match move_type {\n                    Move::Swap { i_vec_idx, j_idx } => {\n                        let item_i = selected[i_vec_idx];\n\n                        // 1. Update weight\n                        let delta_weight = challenge.weights[j_idx] as i64 - challenge.weights[item_i] as i64;\n                        total_weight = (total_weight as i64 + delta_weight) as u32;\n\n                        // 2. Update selection status and list\n                        is_selected[item_i] = false;\n                        is_selected[j_idx] = true;\n                        selected[i_vec_idx] = j_idx;\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] += c_{k, j_new} - c_{k, i_old}\n                        for k in 0..num_items {\n                            interaction_sums[k] += (challenge.interaction_values[k][j_idx] - challenge.interaction_values[k][item_i]) as i64;\n                        }\n\n                        // 4. Update Tabu List: Tabu the item removed (i)\n                        tabu_list[item_i] = iteration + tabu_tenure;\n                    }\n                    Move::Add { j_idx } => {\n                        // 1. Update weight\n                        total_weight += challenge.weights[j_idx];\n\n                        // 2. Update selection status and list\n                        is_selected[j_idx] = true;\n                        selected.push(j_idx);\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] += c_{k, j_new}\n                        for k in 0..num_items {\n                            interaction_sums[k] += challenge.interaction_values[k][j_idx] as i64;\n                        }\n                        // No item removed, no tabu restriction applied.\n                    }\n                    Move::Remove { i_vec_idx } => {\n                        let item_i = selected[i_vec_idx];\n\n                        // 1. Update weight\n                        total_weight -= challenge.weights[item_i];\n\n                        // 2. Update selection status and list\n                        is_selected[item_i] = false;\n                        selected.swap_remove(i_vec_idx); // O(1) removal, order doesn't matter\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] -= c_{k, i_old}\n                        for k in 0..num_items {\n                            interaction_sums[k] -= challenge.interaction_values[k][item_i] as i64;\n                        }\n\n                        // 4. Update Tabu List: Tabu the item removed (i)\n                        tabu_list[item_i] = iteration + tabu_tenure;\n                    }\n                }\n\n                // 5. Update Best Solution\n                if current_value > best_value {\n                    best_value = current_value;\n                    best_selected = selected.clone();\n                    best_total_weight = total_weight;\n                    iterations_since_best_update = 0;\n                }\n\n                // 6. Intensification on Stagnation\n                if iterations_since_best_update > non_improving_limit {\n                    // Return to the best known solution to intensify the search in that area\n                    selected = best_selected.clone();\n                    current_value = best_value;\n                    total_weight = best_total_weight;\n\n                    // Recalculate state based on the restored best solution\n                    is_selected.fill(false);\n                    for &item in &selected {\n                        is_selected[item] = true;\n                    }\n\n                    interaction_sums.fill(0);\n                    for i in 0..num_items {\n                        for &k in &selected {\n                            interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                        }\n                    }\n                    \n                    // Clear the tabu list to allow free exploration from this point\n                    tabu_list.fill(0);\n                    iterations_since_best_update = 0;\n                }\n            }\n\n            // Restore the best solution found during the Tabu Search run\n            selected = best_selected;\n            total_weight = best_total_weight;\n        }\n    }\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}", "language": "rust", "parent_id": "318560a9-ad41-43e8-b388-b56da3649407", "generation": 11, "timestamp": 1766160063.8878586, "iteration_found": 133, "metrics": {"avg_btb": 0.00080894, "combined_score": 0.5408712497050424, "eval_time": 232.968133394, "memory": 371200.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 23 lines with 21 lines\nChange 2: Replace 52 lines with 25 lines", "parent_metrics": {"avg_btb": 0.00078697, "combined_score": 0.5030297886513915, "eval_time": 270.812393448, "memory": 371200.0}, "island": 2}, "prompts": {"diff_user": {"system": "SETTING:\nYou are an expert Rust programmer specializing in combinatorial optimization algorithms with deep expertise in knapsack problems, resource allocation algorithms, and constraint satisfaction.\nYour mission is to evolve and optimize a quadratic knapsack algorithm that outputs the highest quality possible.\n\n\n=== CRITICAL OUTPUT FORMAT RULES ===\n1. Output ONLY raw Rust source code\n2. Include the complete file from first line to last line\n=== END OUTPUT FORMAT RULES ===\n\nAlgorithm Improvement Instructions:\n\nObjective\nImprove the knapsack algorithm to maximize the total value while respecting the weight constraint.\n\nCRITICAL Constraints\n- You may ONLY modify code between // EVOLVE-BLOCK-START and // EVOLVE-BLOCK-END\n- Code outside these markers (imports, function wrapper, save_solution call) must NEVER be modified\n- You MUST NOT modify the function signature\n- You MUST NOT modify lines before // EVOLVE-BLOCK-START\n- You MUST NOT modify lines after // EVOLVE-BLOCK-END\n- You MUST preserve the exact structure of code outside the evolve block\n\nInput: challenge parameter (type: &Challenge)\n\nThe challenge parameter provides access to the following fields with these EXPLICIT types:\n\n- challenge.seed: [u8; 32] - Fixed-size array of 32 bytes for seeding random number generators\n- challenge.weights: Vec<u32> - Vector of unsigned 32-bit integers representing each item's weight\n- challenge.values: Vec<u32> - Vector of unsigned 32-bit integers representing each item's base value\n- challenge.interaction_values: Vec<Vec<i32>> - 2D matrix (vector of vectors) of SIGNED 32-bit integers\n  - interaction_values[i][j] gives the bonus value when items i and j are BOTH selected\n  - This matrix is symmetric: interaction_values[i][j] == interaction_values[j][i]\n  - Diagonal is zero: interaction_values[i][i] == 0\n- challenge.max_weight: u32 - Unsigned 32-bit integer representing maximum total weight allowed\n  \nImportant notes:\n- All vectors have the same length (number of items)\n- challenge.weights.len() = challenge.values.len() = challenge.interaction_values.len()\n- Item indices are 0 to n-1 where n = challenge.values.len()\n- the structure of the algorithm i.e. the inputs and outputs are fixed, you can only modify the body of the algorithm.\n\nOutput: selected variable (type: Vec<usize>)\n\nYour code must create a variable named selected with the following specification:\n\n- Type: Vec<usize> (vector of unsigned size integers)\n- Content: Indices of items to include in the knapsack solution\n- Valid range: Each element must be in range [0, n-1] where n = challenge.values.len()\n- No duplicates: Each item index can appear at most once\n- Weight constraint: The sum of challenge.weights[i] for all i in selected must be \u2264 challenge.max_weight\n\nThe selected variable is automatically saved after the evolve block ends.\n\nContext:\n- This is a QUADRATIC knapsack problem with interaction values between items\n- Items have: weights, values, and interaction_values (2D matrix)\n- Total value = sum of item values + sum of interaction values for pairs of selected items\n- Constraint: total weight must not exceed max_weight which is half the weight of all items\n- The \"density\" of the knapsack is 25% - meaning interaction values in the symmetric interaction matrix are 0 with probability 0.75; otherwise a random number between 1 and 100.\n\nBENCHMARK:\n- Beat the state-of-the-art result of avg_btb = 0.0015.\n\nHyperparameters (Optional):\nIf your algorithm uses tunable parameters (e.g., iteration counts, thresholds, probabilities),\nyou can define them inside the EVOLVE-BLOCK. Follow these examples exactly.\n\nCRITICAL: The examples below show raw Rust code. Do NOT wrap them in markdown code fences.\n\n\nStep 1 - Define a Hyperparameters struct inside the EVOLVE-BLOCK:\n\n#[derive(Serialize, Deserialize)]\npub struct Hyperparameters {\n    pub max_iterations: usize,\n    pub temperature: f64,\n}\n\nStep 2 - Parse hyperparameters at the start of your code block:\n\nlet hyperparameters = match _hyperparameters {\n    Some(params) => {\n        serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n            .map_err(|e| anyhow!(\"Failed to parse hyperparameters: {}\", e))?\n    }\n    None => Hyperparameters {\n        max_iterations: 100,\n        temperature: 0.95,\n    },\n};\n\nStep 3 - Use the hyperparameter values in your algorithm:\n\nfor _ in 0..hyperparameters.max_iterations {\n    // your algorithm logic here\n}\n\n\nRandom numbers:\nIf you need random numbers, recommend using SmallRng with challenge.seed:\nlet mut rng = SmallRng::from_seed(challenge.seed);\n\nMake sure you use\n- Optimised sorting strategies \n- Efficient data structures for tracking selected items\n\nImportant:\n- Only modify code within the EVOLVE-BLOCK\n- Ensure the algorithm terminates within reasonable time\n- Use the provided Challenge struct fields: values, weights, interaction_values, max_weight\n- The variable selected is automatically saved after the evolve block ends\n\nPERFORMANCE METRICS:\n1. **avg_btb**: Average better than baseline; average percentage that the total value of the knapsack solution is better than a baseline value (PRIMARY OBJECTIVE - maximize)\n2. **combined_score**: progress toward beating the state-of-the-art benchmark\n3. **eval_time**: Execution time in seconds (keep reasonable, prefer accuracy over speed)\n4. **memory**: Memory usage in kilobytes (keep reasonable, prefer accuracy over speed)\n\nTECHNICAL REQUIREMENTS:\n- **Error handling**: Graceful handling of optimization failures or infeasible configurations\n- **Memory efficiency**: Avoid excessive memory allocation for matrix computations\n", "user": "# Current Program Information\n- Fitness: 0.5030\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness declined: 0.5409 \u2192 0.5030. Consider revising recent changes.\n- Consider simplifying - code length exceeds 2000 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 17 lines with 19 lines\nChange 2: Replace 20 lines with 24 lines\nChange 3: Replace 6 lines with 6 lines\nChange 4: Replace 7 lines with 7 lines\nChange 5: Replace 6 lines with 6 lines\nChange 6: Replace 11 lines with 37 lines\n- Metrics: avg_btb: 0.0008, combined_score: 0.5409, eval_time: 233.1643, memory: 371200.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Change 1: Replace 8 lines with 7 lines\nChange 2: Replace 9 lines with 8 lines\nChange 3: Replace 51 lines with 25 lines\n- Metrics: avg_btb: 0.0008, combined_score: 0.5409, eval_time: 233.2104, memory: 371200.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Change 1: Replace 17 lines with 19 lines\nChange 2: Replace 5 lines with 8 lines\nChange 3: Replace 2 lines with 3 lines\nChange 4: Replace 6 lines with 6 lines\nChange 5: Replace 4 lines with 4 lines\nChange 6: Replace 6 lines with 6 lines\nChange 7: Replace 7 lines with 33 lines\n- Metrics: avg_btb: 0.0008, combined_score: 0.5409, eval_time: 233.4463, memory: 371072.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.5409)\n```rust\n// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    let num_items = challenge.values.len();\n\n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub tabu_iterations: usize,\n        pub tabu_tenure: usize,\n        pub non_improving_limit: usize,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .map_err(|e| anyhow!(\"Failed to parse hyperparameters: {}\", e))?\n        }\n        None => Hyperparameters {\n            tabu_iterations: 10000,\n            // A dynamic tenure based on problem size often works well.\n            tabu_tenure: ((num_items as f64).sqrt().round() as usize).max(5),\n            non_improving_limit: 1000,\n        },\n    };\n\n    // Phase 1: Iterative greedy construction heuristic.\n    // At each step, it adds the item with the highest marginal gain-to-weight ratio.\n    let mut selected = Vec::new();\n\n    if num_items > 0 {\n        let mut total_weight: u32 = 0;\n        let mut is_selected = vec![false; num_items];\n        let mut marginal_gains: Vec<f64> = challenge.values.iter().map(|&v| v as f64).collect();\n\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_ratio = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = challenge.weights[i];\n                    if total_weight + item_weight <= challenge.max_weight {\n                        let ratio = if item_weight > 0 {\n                            marginal_gains[i] / item_weight as f64\n                        } else {\n                            if marginal_gains[i] > 0.0 {\n                                f64::INFINITY\n                            } else {\n                                f64::NEG_INFINITY\n                            }\n                        };\n\n                        if ratio > best_ratio {\n                            best_ratio = ratio;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(item_to_add) = best_item {\n                selected.push(item_to_add);\n                is_selected[item_to_add] = true;\n                total_weight += challenge.weights[item_to_add];\n\n                for i in 0..num_items {\n                    if !is_selected[i] {\n                        marginal_gains[i] += challenge.interaction_values[item_to_add][i] as f64;\n                    }\n                }\n            } else {\n                break;\n            }\n        }\n\n        // Phase 2: Local search (1-opt swap) to improve the greedy solution.\n        // This phase iterates and performs the best possible swap (one item in, one item out)\n        // until no further improvements can be made.\n        if !selected.is_empty() {\n            let mut interaction_sums = vec![0i64; num_items];\n            for i in 0..num_items {\n                for &k in &selected {\n                    interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                }\n            }\n\n            // Calculate initial value\n            let mut current_value: i64 = 0;\n            for &i in &selected {\n                current_value += challenge.values[i] as i64;\n                // Summing interaction_sums[i] over i in selected counts interactions twice.\n                current_value += interaction_sums[i] / 2;\n            }\n\n            let mut best_value = current_value;\n            let mut best_selected = selected.clone();\n            let mut best_total_weight = total_weight;\n\n            let mut rng = SmallRng::from_seed(challenge.seed);\n\n            // Phase 2: Tabu Search (1-opt swap)\n            // Tabu List: stores the iteration when an item's removal restriction expires.\n            let mut tabu_list = vec![0usize; num_items];\n            let tabu_tenure = hyperparameters.tabu_tenure;\n            let max_iterations = hyperparameters.tabu_iterations;\n            let mut iterations_since_best_update = 0;\n\n            // Define move types for clarity\n            enum Move {\n                Swap { i_vec_idx: usize, j_idx: usize },\n                Add { j_idx: usize },\n                Remove { i_vec_idx: usize },\n            }\n\n            for iteration in 1..=max_iterations {\n                iterations_since_best_update += 1;\n                let mut best_move: Option<(Move, i64)> = None;\n                let mut best_delta = i64::MIN;\n\n                // --- 1. Search Swap neighborhood (i out, j in) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx]; // Item to remove\n\n                    for item_j in 0..num_items { // Item to add\n                        if is_selected[item_j] { continue; }\n\n                        // 1. Check weight constraint\n                        let delta_weight = challenge.weights[item_j] as i64 - challenge.weights[item_i] as i64;\n                        if (total_weight as i64 + delta_weight) > challenge.max_weight as i64 {\n                            continue;\n                        }\n\n                        // 2. Calculate Delta Value\n                        // Delta V = (v_j - v_i) + (interaction_sums[j] - c_{ji}) - interaction_sums[i]\n                        let delta_value = (challenge.values[item_j] as i64 - challenge.values[item_i] as i64)\n                                        + (interaction_sums[item_j] - challenge.interaction_values[item_j][item_i] as i64)\n                                        - interaction_sums[item_i];\n\n                        let new_value = current_value + delta_value;\n\n                        // 3. Tabu Check & Aspiration Criterion\n                        // Item i (removed) is tabu from being added back.\n                        let is_tabu = tabu_list[item_i] > iteration;\n                        let is_aspirated = is_tabu && (new_value > best_value);\n\n                        if !is_tabu || is_aspirated {\n                            if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(0.1)) {\n                                best_delta = delta_value;\n                                best_move = Some((Move::Swap { i_vec_idx, j_idx: item_j }, delta_value));\n                            }\n                        }\n                    }\n                }\n\n                // --- 2. Search Add neighborhood (j in) ---\n                for item_j in 0..num_items {\n                    if is_selected[item_j] { continue; }\n                    let item_weight = challenge.weights[item_j];\n\n                    if total_weight + item_weight <= challenge.max_weight {\n                        // Delta V = v_j + interaction_sums[j]\n                        let delta_value = challenge.values[item_j] as i64 + interaction_sums[item_j];\n                        \n                        if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(0.1)) {\n                            best_delta = delta_value;\n                            best_move = Some((Move::Add { j_idx: item_j }, delta_value));\n                        }\n                    }\n                }\n\n                // --- 3. Search Remove neighborhood (i out) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx]; // Item to remove\n\n                    // Delta V = -v_i - interaction_sums[i]\n                    let delta_value = -(challenge.values[item_i] as i64 + interaction_sums[item_i]);\n                    let new_value = current_value + delta_value;\n\n                    // Tabu Check: Item i (removed) is tabu from being added back.\n                    let is_tabu = tabu_list[item_i] > iteration;\n                    let is_aspirated = is_tabu && (new_value > best_value);\n\n                    if !is_tabu || is_aspirated {\n                        if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(0.1)) {\n                            best_delta = delta_value;\n                            best_move = Some((Move::Remove { i_vec_idx }, delta_value));\n                        }\n                    }\n                }\n\n                // If no feasible move (respecting weight constraint) is found, stop.\n                if best_move.is_none() {\n                    break;\n                }\n\n                // Perform the best move found\n                let (move_type, delta) = best_move.unwrap();\n                current_value += delta;\n\n                match move_type {\n                    Move::Swap { i_vec_idx, j_idx } => {\n                        let item_i = selected[i_vec_idx];\n\n                        // 1. Update weight\n                        let delta_weight = challenge.weights[j_idx] as i64 - challenge.weights[item_i] as i64;\n                        total_weight = (total_weight as i64 + delta_weight) as u32;\n\n                        // 2. Update selection status and list\n                        is_selected[item_i] = false;\n                        is_selected[j_idx] = true;\n                        selected[i_vec_idx] = j_idx;\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] += c_{k, j_new} - c_{k, i_old}\n                        for k in 0..num_items {\n                            interaction_sums[k] += (challenge.interaction_values[k][j_idx] - challenge.interaction_values[k][item_i]) as i64;\n                        }\n\n                        // 4. Update Tabu List: Tabu the item removed (i)\n                        tabu_list[item_i] = iteration + tabu_tenure;\n                    }\n                    Move::Add { j_idx } => {\n                        // 1. Update weight\n                        total_weight += challenge.weights[j_idx];\n\n                        // 2. Update selection status and list\n                        is_selected[j_idx] = true;\n                        selected.push(j_idx);\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] += c_{k, j_new}\n                        for k in 0..num_items {\n                            interaction_sums[k] += challenge.interaction_values[k][j_idx] as i64;\n                        }\n                        // No item removed, no tabu restriction applied.\n                    }\n                    Move::Remove { i_vec_idx } => {\n                        let item_i = selected[i_vec_idx];\n\n                        // 1. Update weight\n                        total_weight -= challenge.weights[item_i];\n\n                        // 2. Update selection status and list\n                        is_selected[item_i] = false;\n                        selected.swap_remove(i_vec_idx); // O(1) removal, order doesn't matter\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] -= c_{k, i_old}\n                        for k in 0..num_items {\n                            interaction_sums[k] -= challenge.interaction_values[k][item_i] as i64;\n                        }\n\n                        // 4. Update Tabu List: Tabu the item removed (i)\n                        tabu_list[item_i] = iteration + tabu_tenure;\n                    }\n                }\n\n                // 5. Update Best Solution\n                if current_value > best_value {\n                    best_value = current_value;\n                    best_selected = selected.clone();\n                    best_total_weight = total_weight;\n                    iterations_since_best_update = 0;\n                }\n\n                // 6. Intensification on Stagnation\n                if iterations_since_best_update > hyperparameters.non_improving_limit {\n                    // Return to the best known solution to intensify the search in that area\n                    selected = best_selected.clone();\n                    current_value = best_value;\n                    total_weight = best_total_weight;\n\n                    // Recalculate state based on the restored best solution\n                    is_selected.fill(false);\n                    for &item in &selected {\n                        is_selected[item] = true;\n                    }\n\n                    interaction_sums.fill(0);\n                    for i in 0..num_items {\n                        for &k in &selected {\n                            interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                        }\n                    }\n                    \n                    // Clear the tabu list to allow free exploration from this point\n                    tabu_list.fill(0);\n                    iterations_since_best_update = 0;\n                }\n            }\n\n            // Restore the best solution found during the Tabu Search run\n            selected = best_selected;\n            total_weight = best_total_weight;\n        }\n    }\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}\n```\nKey features: Performs well on avg_btb (0.0008), Performs well on combined_score (0.5409), Performs well on eval_time (233.4463), Performs well on memory (371072.0000)\n\n### Program 2 (Score: 0.5409)\n```rust\n// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    let num_items = challenge.values.len();\n\n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub tabu_iterations: usize,\n        pub tabu_tenure: usize,\n        pub non_improving_limit: usize,\n        pub tie_breaking_prob: f64,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .map_err(|e| anyhow!(\"Failed to parse hyperparameters: {}\", e))?\n        }\n        None => Hyperparameters {\n            tabu_iterations: 10000,\n            // A dynamic tenure based on problem size often works well.\n            tabu_tenure: ((num_items as f64).sqrt().round() as usize).max(5),\n            non_improving_limit: 1000,\n            tie_breaking_prob: 0.1,\n        },\n    };\n\n    // Phase 1: Iterative greedy construction heuristic.\n    // At each step, it adds the item with the highest marginal gain-to-weight ratio.\n    let mut selected = Vec::new();\n\n    if num_items > 0 {\n        let mut total_weight: u32 = 0;\n        let mut is_selected = vec![false; num_items];\n        let mut marginal_gains: Vec<f64> = challenge.values.iter().map(|&v| v as f64).collect();\n\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_ratio = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = challenge.weights[i];\n                    if total_weight + item_weight <= challenge.max_weight {\n                        let ratio = if item_weight > 0 {\n                            marginal_gains[i] / item_weight as f64\n                        } else {\n                            if marginal_gains[i] > 0.0 {\n                                f64::INFINITY\n                            } else {\n                                f64::NEG_INFINITY\n                            }\n                        };\n\n                        if ratio > best_ratio {\n                            best_ratio = ratio;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(item_to_add) = best_item {\n                selected.push(item_to_add);\n                is_selected[item_to_add] = true;\n                total_weight += challenge.weights[item_to_add];\n\n                for i in 0..num_items {\n                    if !is_selected[i] {\n                        marginal_gains[i] += challenge.interaction_values[item_to_add][i] as f64;\n                    }\n                }\n            } else {\n                break;\n            }\n        }\n\n        // Phase 2: Local search (1-opt swap) to improve the greedy solution.\n        // This phase iterates and performs the best possible swap (one item in, one item out)\n        // until no further improvements can be made.\n        if !selected.is_empty() {\n            let mut interaction_sums = vec![0i64; num_items];\n            for i in 0..num_items {\n                for &k in &selected {\n                    interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                }\n            }\n\n            // Calculate initial value\n            let mut current_value: i64 = 0;\n            for &i in &selected {\n                current_value += challenge.values[i] as i64;\n                // Summing interaction_sums[i] over i in selected counts interactions twice.\n                current_value += interaction_sums[i] / 2;\n            }\n\n            let mut best_value = current_value;\n            let mut best_selected = selected.clone();\n            let mut best_total_weight = total_weight;\n\n            let mut rng = SmallRng::from_seed(challenge.seed);\n            let mut iterations_since_best_update = 0;\n\n            // Phase 2: Tabu Search (1-opt swap)\n            // Tabu List: stores the iteration when an item's removal restriction expires.\n            let mut tabu_list = vec![0usize; num_items];\n            let tabu_tenure = hyperparameters.tabu_tenure;\n            let max_iterations = hyperparameters.tabu_iterations;\n            let non_improving_limit = hyperparameters.non_improving_limit;\n            let tie_breaking_prob = hyperparameters.tie_breaking_prob;\n\n            // Define move types for clarity\n            enum Move {\n                Swap { i_vec_idx: usize, j_idx: usize },\n                Add { j_idx: usize },\n                Remove { i_vec_idx: usize },\n            }\n\n            for iteration in 1..=max_iterations {\n                iterations_since_best_update += 1;\n                let mut best_move: Option<(Move, i64)> = None;\n                let mut best_delta = i64::MIN;\n\n                // --- 1. Search Swap neighborhood (i out, j in) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx]; // Item to remove\n\n                    for item_j in 0..num_items { // Item to add\n                        if is_selected[item_j] { continue; }\n\n                        // 1. Check weight constraint\n                        let delta_weight = challenge.weights[item_j] as i64 - challenge.weights[item_i] as i64;\n                        if (total_weight as i64 + delta_weight) > challenge.max_weight as i64 {\n                            continue;\n                        }\n\n                        // 2. Calculate Delta Value\n                        // Delta V = (v_j - v_i) + (interaction_sums[j] - c_{ji}) - interaction_sums[i]\n                        let delta_value = (challenge.values[item_j] as i64 - challenge.values[item_i] as i64)\n                                        + (interaction_sums[item_j] - challenge.interaction_values[item_j][item_i] as i64)\n                                        - interaction_sums[item_i];\n\n                        let new_value = current_value + delta_value;\n\n                        // 3. Tabu Check & Aspiration Criterion\n                        // Item i (removed) is tabu from being added back.\n                        let is_tabu = tabu_list[item_i] > iteration;\n                        let is_aspirated = is_tabu && (new_value > best_value);\n\n                        if !is_tabu || is_aspirated {\n                            if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(tie_breaking_prob)) {\n                                best_delta = delta_value;\n                                best_move = Some((Move::Swap { i_vec_idx, j_idx: item_j }, delta_value));\n                            }\n                        }\n                    }\n                }\n\n                // --- 2. Search Add neighborhood (j in) ---\n                for item_j in 0..num_items {\n                    if is_selected[item_j] { continue; }\n                    let item_weight = challenge.weights[item_j];\n\n                    if total_weight + item_weight <= challenge.max_weight {\n                        // Delta V = v_j + interaction_sums[j]\n                        let delta_value = challenge.values[item_j] as i64 + interaction_sums[item_j];\n                        \n                        if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(tie_breaking_prob)) {\n                            best_delta = delta_value;\n                            best_move = Some((Move::Add { j_idx: item_j }, delta_value));\n                        }\n                    }\n                }\n\n                // --- 3. Search Remove neighborhood (i out) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx]; // Item to remove\n\n                    // Delta V = -v_i - interaction_sums[i]\n                    let delta_value = -(challenge.values[item_i] as i64 + interaction_sums[item_i]);\n                    let new_value = current_value + delta_value;\n\n                    // Tabu Check: Item i (removed) is tabu from being added back.\n                    let is_tabu = tabu_list[item_i] > iteration;\n                    let is_aspirated = is_tabu && (new_value > best_value);\n\n                    if !is_tabu || is_aspirated {\n                        if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(tie_breaking_prob)) {\n                            best_delta = delta_value;\n                            best_move = Some((Move::Remove { i_vec_idx }, delta_value));\n                        }\n                    }\n                }\n\n                // If no feasible move (respecting weight constraint) is found, stop.\n                if best_move.is_none() {\n                    break;\n                }\n\n                // Perform the best move found\n                let (move_type, delta) = best_move.unwrap();\n                current_value += delta;\n\n                match move_type {\n                    Move::Swap { i_vec_idx, j_idx } => {\n                        let item_i = selected[i_vec_idx];\n\n                        // 1. Update weight\n                        let delta_weight = challenge.weights[j_idx] as i64 - challenge.weights[item_i] as i64;\n                        total_weight = (total_weight as i64 + delta_weight) as u32;\n\n                        // 2. Update selection status and list\n                        is_selected[item_i] = false;\n                        is_selected[j_idx] = true;\n                        selected[i_vec_idx] = j_idx;\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] += c_{k, j_new} - c_{k, i_old}\n                        for k in 0..num_items {\n                            interaction_sums[k] += (challenge.interaction_values[k][j_idx] - challenge.interaction_values[k][item_i]) as i64;\n                        }\n\n                        // 4. Update Tabu List: Tabu the item removed (i)\n                        tabu_list[item_i] = iteration + tabu_tenure;\n                    }\n                    Move::Add { j_idx } => {\n                        // 1. Update weight\n                        total_weight += challenge.weights[j_idx];\n\n                        // 2. Update selection status and list\n                        is_selected[j_idx] = true;\n                        selected.push(j_idx);\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] += c_{k, j_new}\n                        for k in 0..num_items {\n                            interaction_sums[k] += challenge.interaction_values[k][j_idx] as i64;\n                        }\n                        // No item removed, no tabu restriction applied.\n                    }\n                    Move::Remove { i_vec_idx } => {\n                        let item_i = selected[i_vec_idx];\n\n                        // 1. Update weight\n                        total_weight -= challenge.weights[item_i];\n\n                        // 2. Update selection status and list\n                        is_selected[item_i] = false;\n                        selected.swap_remove(i_vec_idx); // O(1) removal, order doesn't matter\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] -= c_{k, i_old}\n                        for k in 0..num_items {\n                            interaction_sums[k] -= challenge.interaction_values[k][item_i] as i64;\n                        }\n\n                        // 4. Update Tabu List: Tabu the item removed (i)\n                        tabu_list[item_i] = iteration + tabu_tenure;\n                    }\n                }\n\n                // 5. Update Best Solution\n                if current_value > best_value {\n                    best_value = current_value;\n                    best_selected = selected.clone();\n                    best_total_weight = total_weight;\n                    iterations_since_best_update = 0;\n                }\n\n                // 6. Intensification on Stagnation\n                if iterations_since_best_update > non_improving_limit {\n                    // Return to the best known solution to intensify the search in that area\n                    selected = best_selected.clone();\n                    current_value = best_value;\n                    total_weight = best_total_weight;\n\n                    // Recalculate state based on the restored best solution\n                    is_selected.fill(false);\n                    for &item in &selected {\n                        is_selected[item] = true;\n                    }\n\n                    // Recalculate interaction_sums based on the restored best solution (O(N*|S|), worst case O(N^2))\n                    interaction_sums.fill(0);\n                    for i in 0..num_items {\n                        for &k in &selected {\n                            interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                        }\n                    }\n                    \n                    // Clear the tabu list to allow free exploration from this point\n                    tabu_list.fill(0);\n                    iterations_since_best_update = 0;\n                }\n            }\n\n            // Restore the best solution found during the Tabu Search run\n            selected = best_selected;\n            total_weight = best_total_weight;\n        }\n    }\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}\n```\nKey features: Performs well on avg_btb (0.0008), Performs well on combined_score (0.5409), Performs well on eval_time (233.2104), Performs well on memory (371200.0000)\n\n### Program 3 (Score: 0.5409)\n```rust\n// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    let num_items = challenge.values.len();\n\n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub tabu_iterations: usize,\n        pub tabu_tenure: usize,\n        pub non_improving_limit: usize,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .map_err(|e| anyhow!(\"Failed to parse hyperparameters: {}\", e))?\n        }\n        None => Hyperparameters {\n            tabu_iterations: 10000,\n            // A dynamic tenure based on problem size often works well.\n            tabu_tenure: ((num_items as f64).sqrt().round() as usize).max(5),\n            non_improving_limit: 1000,\n        },\n    };\n\n    // Phase 1: Iterative greedy construction heuristic.\n    // At each step, it adds the item with the highest marginal gain-to-weight ratio.\n    let mut selected = Vec::new();\n\n    if num_items > 0 {\n        let mut total_weight: u32 = 0;\n        let mut is_selected = vec![false; num_items];\n        let mut marginal_gains: Vec<f64> = challenge.values.iter().map(|&v| v as f64).collect();\n\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_ratio = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = challenge.weights[i];\n                    if total_weight + item_weight <= challenge.max_weight {\n                        let ratio = if item_weight > 0 {\n                            marginal_gains[i] / item_weight as f64\n                        } else {\n                            if marginal_gains[i] > 0.0 {\n                                f64::INFINITY\n                            } else {\n                                f64::NEG_INFINITY\n                            }\n                        };\n\n                        if ratio > best_ratio {\n                            best_ratio = ratio;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(item_to_add) = best_item {\n                selected.push(item_to_add);\n                is_selected[item_to_add] = true;\n                total_weight += challenge.weights[item_to_add];\n\n                for i in 0..num_items {\n                    if !is_selected[i] {\n                        marginal_gains[i] += challenge.interaction_values[item_to_add][i] as f64;\n                    }\n                }\n            } else {\n                break;\n            }\n        }\n\n        // Phase 2: Local search (1-opt swap) to improve the greedy solution.\n        // This phase iterates and performs the best possible swap (one item in, one item out)\n        // until no further improvements can be made.\n        if !selected.is_empty() {\n            let mut interaction_sums = vec![0i64; num_items];\n            for i in 0..num_items {\n                for &k in &selected {\n                    interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                }\n            }\n\n            // Calculate initial value\n            let mut current_value: i64 = 0;\n            for &i in &selected {\n                current_value += challenge.values[i] as i64;\n                // Summing interaction_sums[i] over i in selected counts interactions twice.\n                current_value += interaction_sums[i] / 2;\n            }\n\n            let mut best_value = current_value;\n            let mut best_selected = selected.clone();\n            let mut best_total_weight = total_weight;\n\n            let mut rng = SmallRng::from_seed(challenge.seed);\n            let mut iterations_since_best_update = 0;\n\n            // Phase 2: Tabu Search (1-opt swap)\n            // Tabu List: stores the iteration when an item's removal restriction expires.\n            let mut tabu_list = vec![0usize; num_items];\n            let tabu_tenure = hyperparameters.tabu_tenure;\n            let max_iterations = hyperparameters.tabu_iterations;\n\n            // Define move types for clarity\n            enum Move {\n                Swap { i_vec_idx: usize, j_idx: usize },\n                Add { j_idx: usize },\n                Remove { i_vec_idx: usize },\n            }\n\n            for iteration in 1..=max_iterations {\n                iterations_since_best_update += 1;\n                let mut best_move: Option<(Move, i64)> = None;\n                let mut best_delta = i64::MIN;\n\n                // --- 1. Search Swap neighborhood (i out, j in) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx]; // Item to remove\n\n                    for item_j in 0..num_items { // Item to add\n                        if is_selected[item_j] { continue; }\n\n                        // 1. Check weight constraint\n                        let delta_weight = challenge.weights[item_j] as i64 - challenge.weights[item_i] as i64;\n                        if (total_weight as i64 + delta_weight) > challenge.max_weight as i64 {\n                            continue;\n                        }\n\n                        // 2. Calculate Delta Value\n                        // Delta V = (v_j - v_i) + (interaction_sums[j] - c_{ji}) - interaction_sums[i]\n                        let delta_value = (challenge.values[item_j] as i64 - challenge.values[item_i] as i64)\n                                        + (interaction_sums[item_j] - challenge.interaction_values[item_j][item_i] as i64)\n                                        - interaction_sums[item_i];\n\n                        let new_value = current_value + delta_value;\n\n                        // 3. Tabu Check & Aspiration Criterion\n                        // Item i (removed) is tabu from being added back.\n                        let is_tabu = tabu_list[item_i] > iteration;\n                        let is_aspirated = is_tabu && (new_value > best_value);\n\n                        if !is_tabu || is_aspirated {\n                            if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(0.1)) {\n                                best_delta = delta_value;\n                                best_move = Some((Move::Swap { i_vec_idx, j_idx: item_j }, delta_value));\n                            }\n                        }\n                    }\n                }\n\n                // --- 2. Search Add neighborhood (j in) ---\n                for item_j in 0..num_items {\n                    if is_selected[item_j] { continue; }\n                    let item_weight = challenge.weights[item_j];\n\n                    if total_weight + item_weight <= challenge.max_weight {\n                        // Delta V = v_j + interaction_sums[j]\n                        let delta_value = challenge.values[item_j] as i64 + interaction_sums[item_j];\n                        \n                        if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(0.1)) {\n                            best_delta = delta_value;\n                            best_move = Some((Move::Add { j_idx: item_j }, delta_value));\n                        }\n                    }\n                }\n\n                // --- 3. Search Remove neighborhood (i out) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx]; // Item to remove\n\n                    // Delta V = -v_i - interaction_sums[i]\n                    let delta_value = -(challenge.values[item_i] as i64 + interaction_sums[item_i]);\n                    let new_value = current_value + delta_value;\n\n                    // Tabu Check: Item i (removed) is tabu from being added back.\n                    let is_tabu = tabu_list[item_i] > iteration;\n                    let is_aspirated = is_tabu && (new_value > best_value);\n\n                    if !is_tabu || is_aspirated {\n                        if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(0.1)) {\n                            best_delta = delta_value;\n                            best_move = Some((Move::Remove { i_vec_idx }, delta_value));\n                        }\n                    }\n                }\n\n                // If no feasible move (respecting weight constraint) is found, stop.\n                if best_move.is_none() {\n                    break;\n                }\n\n                // Perform the best move found\n                let (move_type, delta) = best_move.unwrap();\n                current_value += delta;\n\n                match move_type {\n                    Move::Swap { i_vec_idx, j_idx } => {\n                        let item_i = selected[i_vec_idx];\n\n                        // 1. Update weight\n                        let delta_weight = challenge.weights[j_idx] as i64 - challenge.weights[item_i] as i64;\n                        total_weight = (total_weight as i64 + delta_weight) as u32;\n\n                        // 2. Update selection status and list\n                        is_selected[item_i] = false;\n                        is_selected[j_idx] = true;\n                        selected[i_vec_idx] = j_idx;\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] += c_{k, j_new} - c_{k, i_old}\n                        for k in 0..num_items {\n                            interaction_sums[k] += (challenge.interaction_values[k][j_idx] - challenge.interaction_values[k][item_i]) as i64;\n                        }\n\n                        // 4. Update Tabu List: Tabu the item removed (i)\n                        tabu_list[item_i] = iteration + tabu_tenure;\n                    }\n                    Move::Add { j_idx } => {\n                        // 1. Update weight\n                        total_weight += challenge.weights[j_idx];\n\n                        // 2. Update selection status and list\n                        is_selected[j_idx] = true;\n                        selected.push(j_idx);\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] += c_{k, j_new}\n                        for k in 0..num_items {\n                            interaction_sums[k] += challenge.interaction_values[k][j_idx] as i64;\n                        }\n                        // No item removed, no tabu restriction applied.\n                    }\n                    Move::Remove { i_vec_idx } => {\n                        let item_i = selected[i_vec_idx];\n\n                        // 1. Update weight\n                        total_weight -= challenge.weights[item_i];\n\n                        // 2. Update selection status and list\n                        is_selected[item_i] = false;\n                        selected.swap_remove(i_vec_idx); // O(1) removal, order doesn't matter\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] -= c_{k, i_old}\n                        for k in 0..num_items {\n                            interaction_sums[k] -= challenge.interaction_values[k][item_i] as i64;\n                        }\n\n                        // 4. Update Tabu List: Tabu the item removed (i)\n                        tabu_list[item_i] = iteration + tabu_tenure;\n                    }\n                }\n\n                // 5. Update Best Solution\n                if current_value > best_value {\n                    best_value = current_value;\n                    best_selected = selected.clone();\n                    best_total_weight = total_weight;\n                    iterations_since_best_update = 0;\n                }\n\n                // 6. Intensification on Stagnation\n                if iterations_since_best_update > hyperparameters.non_improving_limit {\n                    // Return to the best known solution to intensify the search in that area\n                    selected = best_selected.clone();\n                    current_value = best_value;\n                    total_weight = best_total_weight;\n\n                    // Recalculate state based on the restored best solution\n                    is_selected.fill(false);\n                    for &item in &selected {\n                        is_selected[item] = true;\n                    }\n\n                    interaction_sums.fill(0);\n                    for i in 0..num_items {\n                        for &k in &selected {\n                            interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                        }\n                    }\n                    \n                    // Clear the tabu list to allow free exploration from this point\n                    tabu_list.fill(0);\n                    iterations_since_best_update = 0;\n                }\n            }\n\n            // Restore the best solution found during the Tabu Search run\n            selected = best_selected;\n            total_weight = best_total_weight;\n        }\n    }\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}\n```\nKey features: Performs well on avg_btb (0.0008), Performs well on combined_score (0.5409), Performs well on eval_time (233.1643), Performs well on memory (371200.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.5030)\n```rust\n// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    let num_items = challenge.values.len();\n\n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub tabu_iterations: usize,\n        pub tabu_tenure: usize,\n        pub non_improving_limit: usize,\n        pub perturbation_size_factor: f64, // Factor of current selection size to remove (e.g., 0.1)\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .map_err(|e| anyhow!(\"Failed to parse hyperparameters: {}\", e))?\n        }\n        None => Hyperparameters {\n            tabu_iterations: 10000,\n            // A dynamic tenure based on problem size often works well.\n            tabu_tenure: ((num_items as f64).sqrt().round() as usize).max(5),\n            non_improving_limit: 1000,\n            perturbation_size_factor: 0.1, // Default: remove 10% of items\n        },\n    };\n\n    // Phase 1: Iterative greedy construction heuristic.\n    // At each step, it adds the item with the highest marginal gain-to-weight ratio.\n    let mut selected = Vec::new();\n\n    if num_items > 0 {\n        let mut total_weight: u32 = 0;\n        let mut is_selected = vec![false; num_items];\n        let mut marginal_gains: Vec<f64> = challenge.values.iter().map(|&v| v as f64).collect();\n\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_ratio = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = challenge.weights[i];\n                    if total_weight + item_weight <= challenge.max_weight {\n                        let ratio = if item_weight > 0 {\n                            marginal_gains[i] / item_weight as f64\n                        } else {\n                            if marginal_gains[i] > 0.0 {\n                                f64::INFINITY\n                            } else {\n                                f64::NEG_INFINITY\n                            }\n                        };\n\n                        if ratio > best_ratio {\n                            best_ratio = ratio;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(item_to_add) = best_item {\n                selected.push(item_to_add);\n                is_selected[item_to_add] = true;\n                total_weight += challenge.weights[item_to_add];\n\n                for i in 0..num_items {\n                    if !is_selected[i] {\n                        marginal_gains[i] += challenge.interaction_values[item_to_add][i] as f64;\n                    }\n                }\n            } else {\n                break;\n            }\n        }\n\n        // Phase 2: Local search (1-opt swap) to improve the greedy solution.\n        // This phase iterates and performs the best possible swap (one item in, one item out)\n        // until no further improvements can be made.\n        if !selected.is_empty() {\n            let mut interaction_sums = vec![0i64; num_items];\n            for i in 0..num_items {\n                for &k in &selected {\n                    interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                }\n            }\n\n            // Calculate initial value\n            let mut current_value: i64 = 0;\n            for &i in &selected {\n                current_value += challenge.values[i] as i64;\n                // Summing interaction_sums[i] over i in selected counts interactions twice.\n                current_value += interaction_sums[i] / 2;\n            }\n\n            let mut best_value = current_value;\n            let mut best_selected = selected.clone();\n            let mut best_total_weight = total_weight;\n\n            let mut rng = SmallRng::from_seed(challenge.seed);\n            let mut iterations_since_best_update = 0;\n\n            // Phase 2: Tabu Search (1-opt swap)\n            // Tabu List: stores the iteration when an item's removal restriction expires.\n            let mut tabu_list = vec![0usize; num_items];\n            let tabu_tenure = hyperparameters.tabu_tenure;\n            let max_iterations = hyperparameters.tabu_iterations;\n\n            // Define move types for clarity\n            enum Move {\n                Swap { i_vec_idx: usize, j_idx: usize },\n                Add { j_idx: usize },\n                Remove { i_vec_idx: usize },\n            }\n\n            for iteration in 1..=max_iterations {\n                iterations_since_best_update += 1;\n                let mut best_move: Option<(Move, i64)> = None;\n                let mut best_delta = i64::MIN;\n\n                // --- 1. Search Swap neighborhood (i out, j in) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx]; // Item to remove\n\n                    for item_j in 0..num_items { // Item to add\n                        if is_selected[item_j] { continue; }\n\n                        // 1. Check weight constraint\n                        let delta_weight = challenge.weights[item_j] as i64 - challenge.weights[item_i] as i64;\n                        if (total_weight as i64 + delta_weight) > challenge.max_weight as i64 {\n                            continue;\n                        }\n\n                        // 2. Calculate Delta Value\n                        // Delta V = (v_j - v_i) + (interaction_sums[j] - c_{ji}) - interaction_sums[i]\n                        let delta_value = (challenge.values[item_j] as i64 - challenge.values[item_i] as i64)\n                                        + (interaction_sums[item_j] - challenge.interaction_values[item_j][item_i] as i64)\n                                        - interaction_sums[item_i];\n\n                        let new_value = current_value + delta_value;\n\n                        // 3. Tabu Check & Aspiration Criterion\n                        // Item i (removed) is tabu from being added back.\n                        let is_tabu = tabu_list[item_i] > iteration;\n                        let is_aspirated = is_tabu && (new_value > best_value);\n\n                        if !is_tabu || is_aspirated {\n                            if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(0.1)) {\n                                best_delta = delta_value;\n                                best_move = Some((Move::Swap { i_vec_idx, j_idx: item_j }, delta_value));\n                            }\n                        }\n                    }\n                }\n\n                // --- 2. Search Add neighborhood (j in) ---\n                for item_j in 0..num_items {\n                    if is_selected[item_j] { continue; }\n                    let item_weight = challenge.weights[item_j];\n\n                    if total_weight + item_weight <= challenge.max_weight {\n                        // Delta V = v_j + interaction_sums[j]\n                        let delta_value = challenge.values[item_j] as i64 + interaction_sums[item_j];\n                        \n                        if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(0.1)) {\n                            best_delta = delta_value;\n                            best_move = Some((Move::Add { j_idx: item_j }, delta_value));\n                        }\n                    }\n                }\n\n                // --- 3. Search Remove neighborhood (i out) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx]; // Item to remove\n\n                    // Delta V = -v_i - interaction_sums[i]\n                    let delta_value = -(challenge.values[item_i] as i64 + interaction_sums[item_i]);\n                    let new_value = current_value + delta_value;\n\n                    // Tabu Check: Item i (removed) is tabu from being added back.\n                    let is_tabu = tabu_list[item_i] > iteration;\n                    let is_aspirated = is_tabu && (new_value > best_value);\n\n                    if !is_tabu || is_aspirated {\n                        if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(0.1)) {\n                            best_delta = delta_value;\n                            best_move = Some((Move::Remove { i_vec_idx }, delta_value));\n                        }\n                    }\n                }\n\n                // If no feasible move (respecting weight constraint) is found, stop.\n                if best_move.is_none() {\n                    break;\n                }\n\n                // Perform the best move found\n                let (move_type, delta) = best_move.unwrap();\n                current_value += delta;\n\n                match move_type {\n                    Move::Swap { i_vec_idx, j_idx } => {\n                        let item_i = selected[i_vec_idx];\n\n                        // 1. Update weight\n                        let delta_weight = challenge.weights[j_idx] as i64 - challenge.weights[item_i] as i64;\n                        total_weight = (total_weight as i64 + delta_weight) as u32;\n\n                        // 2. Update selection status and list\n                        is_selected[item_i] = false;\n                        is_selected[j_idx] = true;\n                        selected[i_vec_idx] = j_idx;\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] += c_{k, j_new} - c_{k, i_old}\n                        for k in 0..num_items {\n                            interaction_sums[k] += (challenge.interaction_values[k][j_idx] - challenge.interaction_values[k][item_i]) as i64;\n                        }\n\n                        // 4. Update Tabu List: Tabu the item removed (i)\n                        tabu_list[item_i] = iteration + tabu_tenure;\n                    }\n                    Move::Add { j_idx } => {\n                        // 1. Update weight\n                        total_weight += challenge.weights[j_idx];\n\n                        // 2. Update selection status and list\n                        is_selected[j_idx] = true;\n                        selected.push(j_idx);\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] += c_{k, j_new}\n                        for k in 0..num_items {\n                            interaction_sums[k] += challenge.interaction_values[k][j_idx] as i64;\n                        }\n                        // No item removed, no tabu restriction applied.\n                    }\n                    Move::Remove { i_vec_idx } => {\n                        let item_i = selected[i_vec_idx];\n\n                        // 1. Update weight\n                        total_weight -= challenge.weights[item_i];\n\n                        // 2. Update selection status and list\n                        is_selected[item_i] = false;\n                        selected.swap_remove(i_vec_idx); // O(1) removal, order doesn't matter\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] -= c_{k, i_old}\n                        for k in 0..num_items {\n                            interaction_sums[k] -= challenge.interaction_values[k][item_i] as i64;\n                        }\n\n                        // 4. Update Tabu List: Tabu the item removed (i)\n                        tabu_list[item_i] = iteration + tabu_tenure;\n                    }\n                }\n\n                // 5. Update Best Solution\n                if current_value > best_value {\n                    best_value = current_value;\n                    best_selected = selected.clone();\n                    best_total_weight = total_weight;\n                    iterations_since_best_update = 0;\n                }\n\n                // 6. Intensification/Diversification on Stagnation\n                if iterations_since_best_update > hyperparameters.non_improving_limit {\n                    // 6a. Restore to the best known solution (Intensification phase start)\n                    selected = best_selected.clone();\n                    current_value = best_value;\n                    total_weight = best_total_weight;\n\n                    // Recalculate state based on the restored best solution (O(N^2))\n                    is_selected.fill(false);\n                    for &item in &selected {\n                        is_selected[item] = true;\n                    }\n\n                    interaction_sums.fill(0);\n                    for i in 0..num_items {\n                        for &k in &selected {\n                            interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                        }\n                    }\n                    \n                    // 6b. Perturb the solution (Diversification phase)\n                    let perturbation_count = ((selected.len() as f64) * hyperparameters.perturbation_size_factor).round() as usize;\n                    \n                    // Randomly remove items using efficient O(N) updates\n                    for _ in 0..perturbation_count {\n                        if selected.is_empty() { break; }\n                        \n                        // Select a random index in the selected list\n                        let remove_idx = rng.gen_range(0..selected.len());\n                        let item_i = selected[remove_idx];\n\n                        // Delta V = -v_i - interaction_sums[i]\n                        let delta_value = -(challenge.values[item_i] as i64 + interaction_sums[item_i]);\n                        current_value += delta_value;\n\n                        total_weight -= challenge.weights[item_i];\n                        is_selected[item_i] = false;\n                        selected.swap_remove(remove_idx);\n\n                        // Update interaction_sums efficiently in O(N).\n                        for k in 0..num_items {\n                            interaction_sums[k] -= challenge.interaction_values[k][item_i] as i64;\n                        }\n                    }\n\n                    // 6c. Clear the tabu list and reset counter\n                    tabu_list.fill(0);\n                    iterations_since_best_update = 0;\n                }\n            }\n\n            // Restore the best solution found during the Tabu Search run\n            selected = best_selected;\n            total_weight = best_total_weight;\n        }\n    }\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}\n```\nKey features: Alternative approach to avg_btb, Alternative approach to combined_score\n\n### Program D2 (Score: 0.5409)\n```rust\n// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    let num_items = challenge.values.len();\n\n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub tabu_iterations: usize,\n        pub tabu_tenure: usize,\n        pub non_improving_limit: usize,\n        pub tie_breaking_prob: f64,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .map_err(|e| anyhow!(\"Failed to parse hyperparameters: {}\", e))?\n        }\n        None => Hyperparameters {\n            tabu_iterations: 10000,\n            // A dynamic tenure based on problem size often works well.\n            tabu_tenure: ((num_items as f64).sqrt().round() as usize).max(5),\n            non_improving_limit: 1000,\n            tie_breaking_prob: 0.1,\n        },\n    };\n\n    // Phase 1: Iterative greedy construction heuristic.\n    // At each step, it adds the item with the highest marginal gain-to-weight ratio.\n    let mut selected = Vec::new();\n\n    if num_items > 0 {\n        let mut total_weight: u32 = 0;\n        let mut is_selected = vec![false; num_items];\n        let mut marginal_gains: Vec<f64> = challenge.values.iter().map(|&v| v as f64).collect();\n\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_ratio = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = challenge.weights[i];\n                    if total_weight + item_weight <= challenge.max_weight {\n                        let ratio = if item_weight > 0 {\n                            marginal_gains[i] / item_weight as f64\n                        } else {\n                            if marginal_gains[i] > 0.0 {\n                                f64::INFINITY\n                            } else {\n                                f64::NEG_INFINITY\n                            }\n                        };\n\n                        if ratio > best_ratio {\n                            best_ratio = ratio;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(item_to_add) = best_item {\n                selected.push(item_to_add);\n                is_selected[item_to_add] = true;\n                total_weight += challenge.weights[item_to_add];\n\n                for i in 0..num_items {\n                    if !is_selected[i] {\n                        marginal_gains[i] += challenge.interaction_values[item_to_add][i] as f64;\n                    }\n                }\n            } else {\n                break;\n            }\n        }\n\n        // Phase 2: Local search (1-opt swap) to improve the greedy solution.\n        // This phase iterates and performs the best possible swap (one item in, one item out)\n        // until no further improvements can be made.\n        if !selected.is_empty() {\n            let mut interaction_sums = vec![0i64; num_items];\n            for i in 0..num_items {\n                for &k in &selected {\n                    interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                }\n            }\n\n            // Calculate initial value\n            let mut current_value: i64 = 0;\n            for &i in &selected {\n                current_value += challenge.values[i] as i64;\n                // Summing interaction_sums[i] over i in selected counts interactions twice.\n                current_value += interaction_sums[i] / 2;\n            }\n\n            let mut best_value = current_value;\n            let mut best_selected = selected.clone();\n            let mut best_total_weight = total_weight;\n\n            let mut rng = SmallRng::from_seed(challenge.seed);\n            let mut iterations_since_best_update = 0;\n\n            // Phase 2: Tabu Search (1-opt swap)\n            // Tabu List: stores the iteration when an item's removal restriction expires.\n            let mut tabu_list = vec![0usize; num_items];\n            let tabu_tenure = hyperparameters.tabu_tenure;\n            let max_iterations = hyperparameters.tabu_iterations;\n            let non_improving_limit = hyperparameters.non_improving_limit;\n            let tie_breaking_prob = hyperparameters.tie_breaking_prob;\n\n            // Define move types for clarity\n            enum Move {\n                Swap { i_vec_idx: usize, j_idx: usize },\n                Add { j_idx: usize },\n                Remove { i_vec_idx: usize },\n            }\n\n            for iteration in 1..=max_iterations {\n                iterations_since_best_update += 1;\n                let mut best_move: Option<(Move, i64)> = None;\n                let mut best_delta = i64::MIN;\n\n                // --- 1. Search Swap neighborhood (i out, j in) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx]; // Item to remove\n\n                    for item_j in 0..num_items { // Item to add\n                        if is_selected[item_j] { continue; }\n\n                        // 1. Check weight constraint\n                        let delta_weight = challenge.weights[item_j] as i64 - challenge.weights[item_i] as i64;\n                        if (total_weight as i64 + delta_weight) > challenge.max_weight as i64 {\n                            continue;\n                        }\n\n                        // 2. Calculate Delta Value\n                        // Delta V = (v_j - v_i) + (interaction_sums[j] - c_{ji}) - interaction_sums[i]\n                        let delta_value = (challenge.values[item_j] as i64 - challenge.values[item_i] as i64)\n                                        + (interaction_sums[item_j] - challenge.interaction_values[item_j][item_i] as i64)\n                                        - interaction_sums[item_i];\n\n                        let new_value = current_value + delta_value;\n\n                        // 3. Tabu Check & Aspiration Criterion\n                        // Item i (removed) is tabu from being added back.\n                        let is_tabu = tabu_list[item_i] > iteration;\n                        let is_aspirated = is_tabu && (new_value > best_value);\n\n                        if !is_tabu || is_aspirated {\n                            if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(tie_breaking_prob)) {\n                                best_delta = delta_value;\n                                best_move = Some((Move::Swap { i_vec_idx, j_idx: item_j }, delta_value));\n                            }\n                        }\n                    }\n                }\n\n                // --- 2. Search Add neighborhood (j in) ---\n                for item_j in 0..num_items {\n                    if is_selected[item_j] { continue; }\n                    let item_weight = challenge.weights[item_j];\n\n                    if total_weight + item_weight <= challenge.max_weight {\n                        // Delta V = v_j + interaction_sums[j]\n                        let delta_value = challenge.values[item_j] as i64 + interaction_sums[item_j];\n                        \n                        if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(tie_breaking_prob)) {\n                            best_delta = delta_value;\n                            best_move = Some((Move::Add { j_idx: item_j }, delta_value));\n                        }\n                    }\n                }\n\n                // --- 3. Search Remove neighborhood (i out) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx]; // Item to remove\n\n                    // Delta V = -v_i - interaction_sums[i]\n                    let delta_value = -(challenge.values[item_i] as i64 + interaction_sums[item_i]);\n                    let new_value = current_value + delta_value;\n\n                    // Tabu Check: Item i (removed) is tabu from being added back.\n                    let is_tabu = tabu_list[item_i] > iteration;\n                    let is_aspirated = is_tabu && (new_value > best_value);\n\n                    if !is_tabu || is_aspirated {\n                        if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(tie_breaking_prob)) {\n                            best_delta = delta_value;\n                            best_move = Some((Move::Remove { i_vec_idx }, delta_value));\n                        }\n                    }\n                }\n\n                // If no feasible move (respecting weight constraint) is found, stop.\n                if best_move.is_none() {\n                    break;\n                }\n\n                // Perform the best move found\n                let (move_type, delta) = best_move.unwrap();\n                current_value += delta;\n\n                match move_type {\n                    Move::Swap { i_vec_idx, j_idx } => {\n                        let item_i = selected[i_vec_idx];\n\n                        // 1. Update weight\n                        let delta_weight = challenge.weights[j_idx] as i64 - challenge.weights[item_i] as i64;\n                        total_weight = (total_weight as i64 + delta_weight) as u32;\n\n                        // 2. Update selection status and list\n                        is_selected[item_i] = false;\n                        is_selected[j_idx] = true;\n                        selected[i_vec_idx] = j_idx;\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] += c_{k, j_new} - c_{k, i_old}\n                        for k in 0..num_items {\n                            interaction_sums[k] += (challenge.interaction_values[k][j_idx] - challenge.interaction_values[k][item_i]) as i64;\n                        }\n\n                        // 4. Update Tabu List: Tabu the item removed (i)\n                        tabu_list[item_i] = iteration + tabu_tenure;\n                    }\n                    Move::Add { j_idx } => {\n                        // 1. Update weight\n                        total_weight += challenge.weights[j_idx];\n\n                        // 2. Update selection status and list\n                        is_selected[j_idx] = true;\n                        selected.push(j_idx);\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] += c_{k, j_new}\n                        for k in 0..num_items {\n                            interaction_sums[k] += challenge.interaction_values[k][j_idx] as i64;\n                        }\n                        // No item removed, no tabu restriction applied.\n                    }\n                    Move::Remove { i_vec_idx } => {\n                        let item_i = selected[i_vec_idx];\n\n                        // 1. Update weight\n                        total_weight -= challenge.weights[item_i];\n\n                        // 2. Update selection status and list\n                        is_selected[item_i] = false;\n                        selected.swap_remove(i_vec_idx); // O(1) removal, order doesn't matter\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] -= c_{k, i_old}\n                        for k in 0..num_items {\n                            interaction_sums[k] -= challenge.interaction_values[k][item_i] as i64;\n                        }\n\n                        // 4. Update Tabu List: Tabu the item removed (i)\n                        tabu_list[item_i] = iteration + tabu_tenure;\n                    }\n                }\n\n                // 5. Update Best Solution\n                if current_value > best_value {\n                    best_value = current_value;\n                    best_selected = selected.clone();\n                    best_total_weight = total_weight;\n                    iterations_since_best_update = 0;\n                }\n\n                // 6. Intensification on Stagnation\n                if iterations_since_best_update > non_improving_limit {\n                    // Return to the best known solution to intensify the search in that area\n                    selected = best_selected.clone();\n                    current_value = best_value;\n                    total_weight = best_total_weight;\n\n                    // Recalculate state based on the restored best solution\n                    is_selected.fill(false);\n                    for &item in &selected {\n                        is_selected[item] = true;\n                    }\n\n                    interaction_sums.fill(0);\n                    for i in 0..num_items {\n                        for &k in &selected {\n                            interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                        }\n                    }\n                    \n                    // Clear the tabu list to allow free exploration from this point\n                    tabu_list.fill(0);\n                    iterations_since_best_update = 0;\n                }\n            }\n\n            // Restore the best solution found during the Tabu Search run\n            selected = best_selected;\n            total_weight = best_total_weight;\n        }\n    }\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}\n```\nKey features: Alternative approach to avg_btb, Alternative approach to combined_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.5028, Type: Experimental)\n```rust\n// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    let num_items = challenge.values.len();\n\n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub tabu_iterations: usize,\n        pub tabu_tenure: usize,\n        pub non_improving_limit: usize,\n        pub tie_breaking_prob: f64,\n        pub perturbation_size_factor: f64,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .map_err(|e| anyhow!(\"Failed to parse hyperparameters: {}\", e))?\n        }\n        None => Hyperparameters {\n            tabu_iterations: 10000,\n            // A dynamic tenure based on problem size often works well.\n            tabu_tenure: ((num_items as f64).sqrt().round() as usize).max(5),\n            non_improving_limit: 1000,\n            tie_breaking_prob: 0.1,\n            perturbation_size_factor: 0.15, // Remove 15% of items on stagnation\n        },\n    };\n\n    // Phase 1: Iterative greedy construction heuristic.\n    // At each step, it adds the item with the highest marginal gain-to-weight ratio.\n    let mut selected = Vec::new();\n\n    if num_items > 0 {\n        let mut total_weight: u32 = 0;\n        let mut is_selected = vec![false; num_items];\n        let mut marginal_gains: Vec<f64> = challenge.values.iter().map(|&v| v as f64).collect();\n        \n        let mut rng = SmallRng::from_seed(challenge.seed);\n\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_ratio = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = challenge.weights[i];\n                    if total_weight + item_weight <= challenge.max_weight {\n                        let ratio = if item_weight > 0 {\n                            marginal_gains[i] / item_weight as f64\n                        } else {\n                            if marginal_gains[i] > 0.0 {\n                                f64::INFINITY\n                            } else {\n                                f64::NEG_INFINITY\n                            }\n                        };\n\n                        if ratio > best_ratio {\n                            best_ratio = ratio;\n                            best_item = Some(i);\n                        } else if ratio == best_ratio && rng.gen_bool(0.5) {\n                            best_ratio = ratio;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(item_to_add) = best_item {\n                selected.push(item_to_add);\n                is_selected[item_to_add] = true;\n                total_weight += challenge.weights[item_to_add];\n\n                for i in 0..num_items {\n                    if !is_selected[i] {\n                        marginal_gains[i] += challenge.interaction_values[item_to_add][i] as f64;\n                    }\n                }\n            } else {\n                break;\n            }\n        }\n\n        // Phase 2: Local search (1-opt swap) to improve the greedy solution.\n        // This phase iterates and performs the best possible swap (one item in, one item out)\n        // until no further improvements can be made.\n        if !selected.is_empty() {\n            let mut interaction_sums = vec![0i64; num_items];\n            for i in 0..num_items {\n                for &k in &selected {\n                    interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                }\n            }\n\n            // Calculate initial value\n            let mut current_value: i64 = 0;\n            for &i in &selected {\n                current_value += challenge.values[i] as i64;\n                // Summing interaction_sums[i] over i in selected counts interactions twice.\n                current_value += interaction_sums[i] / 2;\n            }\n\n            let mut best_value = current_value;\n            let mut best_selected = selected.clone();\n            let mut best_total_weight = total_weight;\n\n            let mut iterations_since_best_update = 0;\n\n            // Phase 2: Tabu Search (1-opt swap)\n            // Tabu List: stores the iteration when an item's removal restriction expires.\n            let mut tabu_list = vec![0usize; num_items];\n            let tabu_tenure = hyperparameters.tabu_tenure;\n            let max_iterations = hyperparameters.tabu_iterations;\n            let non_improving_limit = hyperparameters.non_improving_limit;\n            let tie_breaking_prob = hyperparameters.tie_breaking_prob;\n\n            // Define move types for clarity\n            enum Move {\n                Swap { i_vec_idx: usize, j_idx: usize },\n                Add { j_idx: usize },\n                Remove { i_vec_idx: usize },\n            }\n\n            for iteration in 1..=max_iterations {\n                iterations_since_best_update += 1;\n                let mut best_move: Option<(Move, i64)> = None;\n                let mut best_delta = i64::MIN;\n\n                // --- 1. Search Swap neighborhood (i out, j in) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx]; // Item to remove\n\n                    for item_j in 0..num_items { // Item to add\n                        if is_selected[item_j] { continue; }\n\n                        // 1. Check weight constraint\n                        let delta_weight = challenge.weights[item_j] as i64 - challenge.weights[item_i] as i64;\n                        if (total_weight as i64 + delta_weight) > challenge.max_weight as i64 {\n                            continue;\n                        }\n\n                        // 2. Calculate Delta Value\n                        // Delta V = (v_j - v_i) + (interaction_sums[j] - c_{ji}) - interaction_sums[i]\n                        let delta_value = (challenge.values[item_j] as i64 - challenge.values[item_i] as i64)\n                                        + (interaction_sums[item_j] - challenge.interaction_values[item_j][item_i] as i64)\n                                        - interaction_sums[item_i];\n\n                        let new_value = current_value + delta_value;\n\n                        // 3. Tabu Check & Aspiration Criterion\n                        // Item i (removed) is tabu from being added back.\n                        let is_tabu = tabu_list[item_i] > iteration;\n                        let is_aspirated = is_tabu && (new_value > best_value);\n\n                        if !is_tabu || is_aspirated {\n                            if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(tie_breaking_prob)) {\n                                best_delta = delta_value;\n                                best_move = Some((Move::Swap { i_vec_idx, j_idx: item_j }, delta_value));\n                            }\n                        }\n                    }\n                }\n\n                // --- 2. Search Add neighborhood (j in) ---\n                for item_j in 0..num_items {\n                    if is_selected[item_j] { continue; }\n                    let item_weight = challenge.weights[item_j];\n\n                    if total_weight + item_weight <= challenge.max_weight {\n                        // Delta V = v_j + interaction_sums[j]\n                        let delta_value = challenge.values[item_j] as i64 + interaction_sums[item_j];\n                        \n                        if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(tie_breaking_prob)) {\n                            best_delta = delta_value;\n                            best_move = Some((Move::Add { j_idx: item_j }, delta_value));\n                        }\n                    }\n                }\n\n                // --- 3. Search Remove neighborhood (i out) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx]; // Item to remove\n\n                    // Delta V = -v_i - interaction_sums[i]\n                    let delta_value = -(challenge.values[item_i] as i64 + interaction_sums[item_i]);\n                    let new_value = current_value + delta_value;\n\n                    // Tabu Check: Item i (removed) is tabu from being added back.\n                    let is_tabu = tabu_list[item_i] > iteration;\n                    let is_aspirated = is_tabu && (new_value > best_value);\n\n                    if !is_tabu || is_aspirated {\n                        if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(tie_breaking_prob)) {\n                            best_delta = delta_value;\n                            best_move = Some((Move::Remove { i_vec_idx }, delta_value));\n                        }\n                    }\n                }\n\n                // If no feasible move (respecting weight constraint) is found, stop.\n                if best_move.is_none() {\n                    break;\n                }\n\n                // Perform the best move found\n                let (move_type, delta) = best_move.unwrap();\n                current_value += delta;\n\n                match move_type {\n                    Move::Swap { i_vec_idx, j_idx } => {\n                        let item_i = selected[i_vec_idx];\n\n                        // 1. Update weight\n                        let delta_weight = challenge.weights[j_idx] as i64 - challenge.weights[item_i] as i64;\n                        total_weight = (total_weight as i64 + delta_weight) as u32;\n\n                        // 2. Update selection status and list\n                        is_selected[item_i] = false;\n                        is_selected[j_idx] = true;\n                        selected[i_vec_idx] = j_idx;\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] += c_{k, j_new} - c_{k, i_old}\n                        for k in 0..num_items {\n                            interaction_sums[k] += (challenge.interaction_values[k][j_idx] - challenge.interaction_values[k][item_i]) as i64;\n                        }\n\n                        // 4. Update Tabu List: Tabu the item removed (i)\n                        tabu_list[item_i] = iteration + tabu_tenure;\n                    }\n                    Move::Add { j_idx } => {\n                        // 1. Update weight\n                        total_weight += challenge.weights[j_idx];\n\n                        // 2. Update selection status and list\n                        is_selected[j_idx] = true;\n                        selected.push(j_idx);\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] += c_{k, j_new}\n                        for k in 0..num_items {\n                            interaction_sums[k] += challenge.interaction_values[k][j_idx] as i64;\n                        }\n                        // No item removed, no tabu restriction applied.\n                    }\n                    Move::Remove { i_vec_idx } => {\n                        let item_i = selected[i_vec_idx];\n\n                        // 1. Update weight\n                        total_weight -= challenge.weights[item_i];\n\n                        // 2. Update selection status and list\n                        is_selected[item_i] = false;\n                        selected.swap_remove(i_vec_idx); // O(1) removal, order doesn't matter\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] -= c_{k, i_old}\n                        for k in 0..num_items {\n                            interaction_sums[k] -= challenge.interaction_values[k][item_i] as i64;\n                        }\n\n                        // 4. Update Tabu List: Tabu the item removed (i)\n                        tabu_list[item_i] = iteration + tabu_tenure;\n                    }\n                }\n\n                // 5. Update Best Solution\n                if current_value > best_value {\n                    best_value = current_value;\n                    best_selected = selected.clone();\n                    best_total_weight = total_weight;\n                    iterations_since_best_update = 0;\n                }\n\n                // 6. Intensification/Diversification on Stagnation\n                if iterations_since_best_update > non_improving_limit {\n                    // 6a. Restore to the best known solution (Intensification)\n                    selected = best_selected.clone();\n                    current_value = best_value;\n                    total_weight = best_total_weight;\n\n                    // Recalculate state based on the restored best solution\n                    is_selected.fill(false);\n                    for &item in &selected {\n                        is_selected[item] = true;\n                    }\n                    interaction_sums.fill(0);\n                    for i in 0..num_items {\n                        for &k in &selected {\n                            interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                        }\n                    }\n                    \n                    // 6b. Perturb the solution (Diversification: Targeted Removal)\n                    let perturbation_count = ((selected.len() as f64) * hyperparameters.perturbation_size_factor).round() as usize;\n                    \n                    if perturbation_count > 0 && !selected.is_empty() {\n                        // Calculate marginal loss for all currently selected items\n                        let mut removal_candidates: Vec<(i64, usize)> = selected.iter().map(|&item_i| {\n                            // Marginal loss if item_i is removed: v_i + interaction_sums[i]\n                            let marginal_loss = challenge.values[item_i] as i64 + interaction_sums[item_i];\n                            (marginal_loss, item_i)\n                        }).collect();\n\n                        // Sort by marginal loss (ascending: worst items first, i.e., smallest marginal contribution)\n                        removal_candidates.sort_unstable_by_key(|k| k.0);\n\n                        // Select the indices of the worst items to remove\n                        let items_to_remove: std::collections::HashSet<usize> = removal_candidates\n                            .into_iter()\n                            .take(perturbation_count)\n                            .map(|(_, item_i)| item_i)\n                            .collect();\n\n                        // Perform removals and update state incrementally\n                        let mut items_to_keep: Vec<usize> = Vec::with_capacity(selected.len() - items_to_remove.len());\n                        \n                        for item_i in selected.into_iter() {\n                            if items_to_remove.contains(&item_i) {\n                                // Update value and weight\n                                // We need the marginal value based on the state *before* removal\n                                let marginal_value = challenge.values[item_i] as i64 + interaction_sums[item_i];\n                                current_value -= marginal_value;\n                                \n                                total_weight -= challenge.weights[item_i];\n                                is_selected[item_i] = false;\n                                \n                                // Update interaction_sums for all items efficiently\n                                for k in 0..num_items {\n                                    interaction_sums[k] -= challenge.interaction_values[k][item_i] as i64;\n                                }\n                            } else {\n                                items_to_keep.push(item_i);\n                            }\n                        }\n                        selected = items_to_keep;\n                    }\n\n                    // 6c. Clear the tabu list and reset counter to explore from new state\n                    tabu_list.fill(0);\n                    iterations_since_best_update = 0;\n                }\n            }\n\n            // Restore the best solution found during the Tabu Search run\n            selected = best_selected;\n            total_weight = best_total_weight;\n        }\n    }\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}\n```\nUnique approach: Modification: Change 1: Replace 71 lines with 75 lines\nChange 2: Replace 23 lines with 44 lines, Alternative avg_btb approach, Excellent eval_time (272.662)\n\n### Inspiration 2 (Score: 0.5030, Type: Experimental)\n```rust\n// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    let num_items = challenge.values.len();\n\n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub tabu_iterations: usize,\n        pub tabu_tenure: usize,\n        pub non_improving_limit: usize,\n        pub tie_breaking_prob: f64,\n        pub perturbation_size_factor: f64,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .map_err(|e| anyhow!(\"Failed to parse hyperparameters: {}\", e))?\n        }\n        None => Hyperparameters {\n            tabu_iterations: 10000,\n            // A dynamic tenure based on problem size often works well.\n            tabu_tenure: ((num_items as f64).sqrt().round() as usize).max(5),\n            non_improving_limit: 1000,\n            tie_breaking_prob: 0.1,\n            perturbation_size_factor: 0.1,\n        },\n    };\n\n    // Phase 1: Iterative greedy construction heuristic.\n    // At each step, it adds the item with the highest marginal gain-to-weight ratio.\n    let mut selected = Vec::new();\n\n    if num_items > 0 {\n        let mut total_weight: u32 = 0;\n        let mut is_selected = vec![false; num_items];\n        let mut marginal_gains: Vec<f64> = challenge.values.iter().map(|&v| v as f64).collect();\n\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_ratio = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = challenge.weights[i];\n                    if total_weight + item_weight <= challenge.max_weight {\n                        let ratio = if item_weight > 0 {\n                            marginal_gains[i] / item_weight as f64\n                        } else {\n                            if marginal_gains[i] > 0.0 {\n                                f64::INFINITY\n                            } else {\n                                f64::NEG_INFINITY\n                            }\n                        };\n\n                        if ratio > best_ratio {\n                            best_ratio = ratio;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(item_to_add) = best_item {\n                selected.push(item_to_add);\n                is_selected[item_to_add] = true;\n                total_weight += challenge.weights[item_to_add];\n\n                for i in 0..num_items {\n                    if !is_selected[i] {\n                        marginal_gains[i] += challenge.interaction_values[item_to_add][i] as f64;\n                    }\n                }\n            } else {\n                break;\n            }\n        }\n\n        // Phase 2: Local search (1-opt swap) to improve the greedy solution.\n        // This phase iterates and performs the best possible swap (one item in, one item out)\n        // until no further improvements can be made.\n        if !selected.is_empty() {\n            let mut interaction_sums = vec![0i64; num_items];\n            for i in 0..num_items {\n                for &k in &selected {\n                    interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                }\n            }\n\n            // Calculate initial value\n            let mut current_value: i64 = 0;\n            for &i in &selected {\n                current_value += challenge.values[i] as i64;\n                // Summing interaction_sums[i] over i in selected counts interactions twice.\n                current_value += interaction_sums[i] / 2;\n            }\n\n            let mut best_value = current_value;\n            let mut best_selected = selected.clone();\n            let mut best_total_weight = total_weight;\n\n            let mut rng = SmallRng::from_seed(challenge.seed);\n            let mut iterations_since_best_update = 0;\n\n            // Phase 2: Tabu Search (1-opt swap)\n            // Tabu List: stores the iteration when an item's removal restriction expires.\n            let mut tabu_list = vec![0usize; num_items];\n            let tabu_tenure = hyperparameters.tabu_tenure;\n            let max_iterations = hyperparameters.tabu_iterations;\n            let non_improving_limit = hyperparameters.non_improving_limit;\n            let tie_breaking_prob = hyperparameters.tie_breaking_prob;\n\n            // Define move types for clarity\n            enum Move {\n                Swap { i_vec_idx: usize, j_idx: usize },\n                Add { j_idx: usize },\n                Remove { i_vec_idx: usize },\n            }\n\n            for iteration in 1..=max_iterations {\n                iterations_since_best_update += 1;\n                let mut best_move: Option<(Move, i64)> = None;\n                let mut best_delta = i64::MIN;\n\n                // --- 1. Search Swap neighborhood (i out, j in) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx]; // Item to remove\n\n                    for item_j in 0..num_items { // Item to add\n                        if is_selected[item_j] { continue; }\n\n                        // 1. Check weight constraint\n                        let delta_weight = challenge.weights[item_j] as i64 - challenge.weights[item_i] as i64;\n                        if (total_weight as i64 + delta_weight) > challenge.max_weight as i64 {\n                            continue;\n                        }\n\n                        // 2. Calculate Delta Value\n                        // Delta V = (v_j - v_i) + (interaction_sums[j] - c_{ji}) - interaction_sums[i]\n                        let delta_value = (challenge.values[item_j] as i64 - challenge.values[item_i] as i64)\n                                        + (interaction_sums[item_j] - challenge.interaction_values[item_j][item_i] as i64)\n                                        - interaction_sums[item_i];\n\n                        let new_value = current_value + delta_value;\n\n                        // 3. Tabu Check & Aspiration Criterion\n                        // Item i (removed) is tabu from being added back.\n                        let is_tabu = tabu_list[item_i] > iteration;\n                        let is_aspirated = is_tabu && (new_value > best_value);\n\n                        if !is_tabu || is_aspirated {\n                            if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(tie_breaking_prob)) {\n                                best_delta = delta_value;\n                                best_move = Some((Move::Swap { i_vec_idx, j_idx: item_j }, delta_value));\n                            }\n                        }\n                    }\n                }\n\n                // --- 2. Search Add neighborhood (j in) ---\n                for item_j in 0..num_items {\n                    if is_selected[item_j] { continue; }\n                    let item_weight = challenge.weights[item_j];\n\n                    if total_weight + item_weight <= challenge.max_weight {\n                        // Delta V = v_j + interaction_sums[j]\n                        let delta_value = challenge.values[item_j] as i64 + interaction_sums[item_j];\n                        \n                        if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(tie_breaking_prob)) {\n                            best_delta = delta_value;\n                            best_move = Some((Move::Add { j_idx: item_j }, delta_value));\n                        }\n                    }\n                }\n\n                // --- 3. Search Remove neighborhood (i out) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx]; // Item to remove\n\n                    // Delta V = -v_i - interaction_sums[i]\n                    let delta_value = -(challenge.values[item_i] as i64 + interaction_sums[item_i]);\n                    let new_value = current_value + delta_value;\n\n                    // Tabu Check: Item i (removed) is tabu from being added back.\n                    let is_tabu = tabu_list[item_i] > iteration;\n                    let is_aspirated = is_tabu && (new_value > best_value);\n\n                    if !is_tabu || is_aspirated {\n                        if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(tie_breaking_prob)) {\n                            best_delta = delta_value;\n                            best_move = Some((Move::Remove { i_vec_idx }, delta_value));\n                        }\n                    }\n                }\n\n                // If no feasible move (respecting weight constraint) is found, stop.\n                if best_move.is_none() {\n                    break;\n                }\n\n                // Perform the best move found\n                let (move_type, delta) = best_move.unwrap();\n                current_value += delta;\n\n                match move_type {\n                    Move::Swap { i_vec_idx, j_idx } => {\n                        let item_i = selected[i_vec_idx];\n\n                        // 1. Update weight\n                        let delta_weight = challenge.weights[j_idx] as i64 - challenge.weights[item_i] as i64;\n                        total_weight = (total_weight as i64 + delta_weight) as u32;\n\n                        // 2. Update selection status and list\n                        is_selected[item_i] = false;\n                        is_selected[j_idx] = true;\n                        selected[i_vec_idx] = j_idx;\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] += c_{k, j_new} - c_{k, i_old}\n                        for k in 0..num_items {\n                            interaction_sums[k] += (challenge.interaction_values[k][j_idx] - challenge.interaction_values[k][item_i]) as i64;\n                        }\n\n                        // 4. Update Tabu List: Tabu the item removed (i)\n                        tabu_list[item_i] = iteration + tabu_tenure;\n                    }\n                    Move::Add { j_idx } => {\n                        // 1. Update weight\n                        total_weight += challenge.weights[j_idx];\n\n                        // 2. Update selection status and list\n                        is_selected[j_idx] = true;\n                        selected.push(j_idx);\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] += c_{k, j_new}\n                        for k in 0..num_items {\n                            interaction_sums[k] += challenge.interaction_values[k][j_idx] as i64;\n                        }\n                        // No item removed, no tabu restriction applied.\n                    }\n                    Move::Remove { i_vec_idx } => {\n                        let item_i = selected[i_vec_idx];\n\n                        // 1. Update weight\n                        total_weight -= challenge.weights[item_i];\n\n                        // 2. Update selection status and list\n                        is_selected[item_i] = false;\n                        selected.swap_remove(i_vec_idx); // O(1) removal, order doesn't matter\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] -= c_{k, i_old}\n                        for k in 0..num_items {\n                            interaction_sums[k] -= challenge.interaction_values[k][item_i] as i64;\n                        }\n\n                        // 4. Update Tabu List: Tabu the item removed (i)\n                        tabu_list[item_i] = iteration + tabu_tenure;\n                    }\n                }\n\n                // 5. Update Best Solution\n                if current_value > best_value {\n                    best_value = current_value;\n                    best_selected = selected.clone();\n                    best_total_weight = total_weight;\n                    iterations_since_best_update = 0;\n                }\n\n                // 6. Diversification on Stagnation (Iterated Local Search perturbation)\n                if iterations_since_best_update > non_improving_limit {\n                    // 6a. Restore to the best known solution (Intensification phase start)\n                    selected = best_selected.clone();\n                    current_value = best_value;\n                    total_weight = best_total_weight;\n\n                    // Recalculate state based on the restored best solution\n                    is_selected.fill(false);\n                    for &item in &selected {\n                        is_selected[item] = true;\n                    }\n\n                    // Recalculate interaction_sums based on the restored best solution (O(N*|S|), worst case O(N^2))\n                    interaction_sums.fill(0);\n                    for i in 0..num_items {\n                        for &k in &selected {\n                            interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                        }\n                    }\n                    \n                    // 6b. Perturb the solution (Diversification phase: Random Removal)\n                    let perturbation_count = ((selected.len() as f64) * hyperparameters.perturbation_size_factor).round() as usize;\n                    \n                    // Randomly remove items using efficient O(N) updates\n                    for _ in 0..perturbation_count {\n                        if selected.is_empty() { break; }\n                        \n                        // Select a random index in the selected list\n                        let remove_idx = rng.gen_range(0..selected.len());\n                        let item_i = selected[remove_idx];\n\n                        // Delta V = -v_i - interaction_sums[i]\n                        let delta_value = -(challenge.values[item_i] as i64 + interaction_sums[item_i]);\n                        current_value += delta_value;\n\n                        total_weight -= challenge.weights[item_i];\n                        is_selected[item_i] = false;\n                        selected.swap_remove(remove_idx);\n\n                        // Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] -= c_{k, i_old}\n                        for k in 0..num_items {\n                            interaction_sums[k] -= challenge.interaction_values[k][item_i] as i64;\n                        }\n                    }\n\n                    // 6c. Clear the tabu list and reset counter\n                    tabu_list.fill(0);\n                    iterations_since_best_update = 0;\n                }\n            }\n\n            // Restore the best solution found during the Tabu Search run\n            selected = best_selected;\n            total_weight = best_total_weight;\n        }\n    }\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}\n```\nUnique approach: Alternative avg_btb approach, Excellent eval_time (263.529), Excellent memory (371072.000)\n\n### Inspiration 3 (Score: 0.5030, Type: Experimental)\n```rust\n// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    let num_items = challenge.values.len();\n\n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub tabu_iterations: usize,\n        pub tabu_tenure: usize,\n        pub non_improving_limit: usize,\n        pub tie_breaking_prob: f64,\n        pub perturbation_size_factor: f64,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .map_err(|e| anyhow!(\"Failed to parse hyperparameters: {}\", e))?\n        }\n        None => Hyperparameters {\n            tabu_iterations: 10000,\n            // A dynamic tenure based on problem size often works well.\n            tabu_tenure: ((num_items as f64).sqrt().round() as usize).max(5),\n            non_improving_limit: 1000,\n            tie_breaking_prob: 0.1,\n            perturbation_size_factor: 0.08, // 8% removal for diversification\n        },\n    };\n\n    // Phase 1: Iterative greedy construction heuristic.\n    // At each step, it adds the item with the highest marginal gain-to-weight ratio.\n    let mut selected = Vec::new();\n\n    if num_items > 0 {\n        let mut total_weight: u32 = 0;\n        let mut is_selected = vec![false; num_items];\n        let mut marginal_gains: Vec<f64> = challenge.values.iter().map(|&v| v as f64).collect();\n\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_ratio = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = challenge.weights[i];\n                    if total_weight + item_weight <= challenge.max_weight {\n                        let ratio = if item_weight > 0 {\n                            marginal_gains[i] / item_weight as f64\n                        } else {\n                            if marginal_gains[i] > 0.0 {\n                                f64::INFINITY\n                            } else {\n                                f64::NEG_INFINITY\n                            }\n                        };\n\n                        if ratio > best_ratio {\n                            best_ratio = ratio;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(item_to_add) = best_item {\n                selected.push(item_to_add);\n                is_selected[item_to_add] = true;\n                total_weight += challenge.weights[item_to_add];\n\n                for i in 0..num_items {\n                    if !is_selected[i] {\n                        marginal_gains[i] += challenge.interaction_values[item_to_add][i] as f64;\n                    }\n                }\n            } else {\n                break;\n            }\n        }\n\n        // Phase 2: Local search (1-opt swap) to improve the greedy solution.\n        // This phase iterates and performs the best possible swap (one item in, one item out)\n        // until no further improvements can be made.\n        if !selected.is_empty() {\n            let mut interaction_sums = vec![0i64; num_items];\n            for i in 0..num_items {\n                for &k in &selected {\n                    interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                }\n            }\n\n            // Calculate initial value\n            let mut current_value: i64 = 0;\n            for &i in &selected {\n                current_value += challenge.values[i] as i64;\n                // Summing interaction_sums[i] over i in selected counts interactions twice.\n                current_value += interaction_sums[i] / 2;\n            }\n\n            let mut best_value = current_value;\n            let mut best_selected = selected.clone();\n            let mut best_total_weight = total_weight;\n\n            let mut rng = SmallRng::from_seed(challenge.seed);\n            let mut iterations_since_best_update = 0;\n\n            // Phase 2: Tabu Search (1-opt swap)\n            // Tabu List: stores the iteration when an item's removal restriction expires.\n            let mut tabu_list = vec![0usize; num_items];\n            let tabu_tenure = hyperparameters.tabu_tenure;\n            let max_iterations = hyperparameters.tabu_iterations;\n            let non_improving_limit = hyperparameters.non_improving_limit;\n            let tie_breaking_prob = hyperparameters.tie_breaking_prob;\n\n            // Define move types for clarity\n            enum Move {\n                Swap { i_vec_idx: usize, j_idx: usize },\n                Add { j_idx: usize },\n                Remove { i_vec_idx: usize },\n            }\n\n            for iteration in 1..=max_iterations {\n                iterations_since_best_update += 1;\n                let mut best_move: Option<(Move, i64)> = None;\n                let mut best_delta = i64::MIN;\n\n                // --- 1. Search Swap neighborhood (i out, j in) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx]; // Item to remove\n\n                    for item_j in 0..num_items { // Item to add\n                        if is_selected[item_j] { continue; }\n\n                        // 1. Check weight constraint\n                        let delta_weight = challenge.weights[item_j] as i64 - challenge.weights[item_i] as i64;\n                        if (total_weight as i64 + delta_weight) > challenge.max_weight as i64 {\n                            continue;\n                        }\n\n                        // 2. Calculate Delta Value\n                        // Delta V = (v_j - v_i) + (interaction_sums[j] - c_{ji}) - interaction_sums[i]\n                        let delta_value = (challenge.values[item_j] as i64 - challenge.values[item_i] as i64)\n                                        + (interaction_sums[item_j] - challenge.interaction_values[item_j][item_i] as i64)\n                                        - interaction_sums[item_i];\n\n                        let new_value = current_value + delta_value;\n\n                        // 3. Tabu Check & Aspiration Criterion\n                        // Item i (removed) is tabu from being added back.\n                        let is_tabu = tabu_list[item_i] > iteration;\n                        let is_aspirated = is_tabu && (new_value > best_value);\n\n                        if !is_tabu || is_aspirated {\n                            if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(tie_breaking_prob)) {\n                                best_delta = delta_value;\n                                best_move = Some((Move::Swap { i_vec_idx, j_idx: item_j }, delta_value));\n                            }\n                        }\n                    }\n                }\n\n                // --- 2. Search Add neighborhood (j in) ---\n                for item_j in 0..num_items {\n                    if is_selected[item_j] { continue; }\n                    let item_weight = challenge.weights[item_j];\n\n                    if total_weight + item_weight <= challenge.max_weight {\n                        // Delta V = v_j + interaction_sums[j]\n                        let delta_value = challenge.values[item_j] as i64 + interaction_sums[item_j];\n                        \n                        if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(tie_breaking_prob)) {\n                            best_delta = delta_value;\n                            best_move = Some((Move::Add { j_idx: item_j }, delta_value));\n                        }\n                    }\n                }\n\n                // --- 3. Search Remove neighborhood (i out) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx]; // Item to remove\n\n                    // Delta V = -v_i - interaction_sums[i]\n                    let delta_value = -(challenge.values[item_i] as i64 + interaction_sums[item_i]);\n                    let new_value = current_value + delta_value;\n\n                    // Tabu Check: Item i (removed) is tabu from being added back.\n                    let is_tabu = tabu_list[item_i] > iteration;\n                    let is_aspirated = is_tabu && (new_value > best_value);\n\n                    if !is_tabu || is_aspirated {\n                        if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(tie_breaking_prob)) {\n                            best_delta = delta_value;\n                            best_move = Some((Move::Remove { i_vec_idx }, delta_value));\n                        }\n                    }\n                }\n\n                // If no feasible move (respecting weight constraint) is found, stop.\n                if best_move.is_none() {\n                    break;\n                }\n\n                // Perform the best move found\n                let (move_type, delta) = best_move.unwrap();\n                current_value += delta;\n\n                match move_type {\n                    Move::Swap { i_vec_idx, j_idx } => {\n                        let item_i = selected[i_vec_idx];\n\n                        // 1. Update weight\n                        let delta_weight = challenge.weights[j_idx] as i64 - challenge.weights[item_i] as i64;\n                        total_weight = (total_weight as i64 + delta_weight) as u32;\n\n                        // 2. Update selection status and list\n                        is_selected[item_i] = false;\n                        is_selected[j_idx] = true;\n                        selected[i_vec_idx] = j_idx;\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] += c_{k, j_new} - c_{k, i_old}\n                        for k in 0..num_items {\n                            interaction_sums[k] += (challenge.interaction_values[k][j_idx] - challenge.interaction_values[k][item_i]) as i64;\n                        }\n\n                        // 4. Update Tabu List: Tabu the item removed (i)\n                        tabu_list[item_i] = iteration + tabu_tenure;\n                    }\n                    Move::Add { j_idx } => {\n                        // 1. Update weight\n                        total_weight += challenge.weights[j_idx];\n\n                        // 2. Update selection status and list\n                        is_selected[j_idx] = true;\n                        selected.push(j_idx);\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] += c_{k, j_new}\n                        for k in 0..num_items {\n                            interaction_sums[k] += challenge.interaction_values[k][j_idx] as i64;\n                        }\n                        // No item removed, no tabu restriction applied.\n                    }\n                    Move::Remove { i_vec_idx } => {\n                        let item_i = selected[i_vec_idx];\n\n                        // 1. Update weight\n                        total_weight -= challenge.weights[item_i];\n\n                        // 2. Update selection status and list\n                        is_selected[item_i] = false;\n                        selected.swap_remove(i_vec_idx); // O(1) removal, order doesn't matter\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] -= c_{k, i_old}\n                        for k in 0..num_items {\n                            interaction_sums[k] -= challenge.interaction_values[k][item_i] as i64;\n                        }\n\n                        // 4. Update Tabu List: Tabu the item removed (i)\n                        tabu_list[item_i] = iteration + tabu_tenure;\n                    }\n                }\n\n                // 5. Update Best Solution\n                if current_value > best_value {\n                    best_value = current_value;\n                    best_selected = selected.clone();\n                    best_total_weight = total_weight;\n                    iterations_since_best_update = 0;\n                }\n\n                // 6. Intensification/Diversification on Stagnation\n                if iterations_since_best_update > non_improving_limit {\n                    // 6a. Restore to the best known solution (Intensification phase start)\n                    selected = best_selected.clone();\n                    current_value = best_value;\n                    total_weight = best_total_weight;\n\n                    // Recalculate state based on the restored best solution\n                    is_selected.fill(false);\n                    for &item in &selected {\n                        is_selected[item] = true;\n                    }\n\n                    interaction_sums.fill(0);\n                    for i in 0..num_items {\n                        for &k in &selected {\n                            interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                        }\n                    }\n                    \n                    // 6b. Perturb the solution (Diversification phase)\n                    let perturbation_count = ((selected.len() as f64) * hyperparameters.perturbation_size_factor).round() as usize;\n                    \n                    // Randomly remove items using efficient O(N) updates\n                    for _ in 0..perturbation_count {\n                        if selected.is_empty() { break; }\n                        \n                        // Select a random index in the selected list\n                        let remove_idx = rng.gen_range(0..selected.len());\n                        let item_i = selected[remove_idx];\n\n                        // Delta V = -v_i - interaction_sums[i]\n                        let delta_value = -(challenge.values[item_i] as i64 + interaction_sums[item_i]);\n                        current_value += delta_value; // Update value for the perturbed state\n\n                        total_weight -= challenge.weights[item_i];\n                        is_selected[item_i] = false;\n                        selected.swap_remove(remove_idx);\n\n                        // Update interaction_sums efficiently in O(N).\n                        for k in 0..num_items {\n                            interaction_sums[k] -= challenge.interaction_values[k][item_i] as i64;\n                        }\n                    }\n\n                    // 6c. Clear the tabu list and reset counter\n                    tabu_list.fill(0);\n                    iterations_since_best_update = 0;\n                }\n            }\n\n            // Restore the best solution found during the Tabu Search run\n            selected = best_selected;\n            total_weight = best_total_weight;\n        }\n    }\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}\n```\nUnique approach: Modification: Change 1: Replace 21 lines with 23 lines\nChange 2: Replace 25 lines with 50 lines, Alternative avg_btb approach, Excellent eval_time (255.490)\n\n# Current Program\n```rust\n// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    let num_items = challenge.values.len();\n\n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub tabu_iterations: usize,\n        pub tabu_tenure: usize,\n        pub non_improving_limit: usize,\n        pub tie_breaking_prob: f64,\n        pub perturbation_size_factor: f64,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .map_err(|e| anyhow!(\"Failed to parse hyperparameters: {}\", e))?\n        }\n        None => Hyperparameters {\n            tabu_iterations: 10000,\n            // A dynamic tenure based on problem size often works well.\n            tabu_tenure: ((num_items as f64).sqrt().round() as usize).max(5),\n            non_improving_limit: 1000,\n            tie_breaking_prob: 0.1,\n            perturbation_size_factor: 0.15, // Default: remove 15% of items\n        },\n    };\n\n    // Phase 1: Iterative greedy construction heuristic.\n    // At each step, it adds the item with the highest marginal gain-to-weight ratio.\n    let mut selected = Vec::new();\n\n    if num_items > 0 {\n        let mut total_weight: u32 = 0;\n        let mut is_selected = vec![false; num_items];\n        let mut marginal_gains: Vec<f64> = challenge.values.iter().map(|&v| v as f64).collect();\n\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_ratio = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = challenge.weights[i];\n                    if total_weight + item_weight <= challenge.max_weight {\n                        let ratio = if item_weight > 0 {\n                            marginal_gains[i] / item_weight as f64\n                        } else {\n                            if marginal_gains[i] > 0.0 {\n                                f64::INFINITY\n                            } else {\n                                f64::NEG_INFINITY\n                            }\n                        };\n\n                        if ratio > best_ratio {\n                            best_ratio = ratio;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(item_to_add) = best_item {\n                selected.push(item_to_add);\n                is_selected[item_to_add] = true;\n                total_weight += challenge.weights[item_to_add];\n\n                for i in 0..num_items {\n                    if !is_selected[i] {\n                        marginal_gains[i] += challenge.interaction_values[item_to_add][i] as f64;\n                    }\n                }\n            } else {\n                break;\n            }\n        }\n\n        // Phase 2: Local search (1-opt swap) to improve the greedy solution.\n        // This phase iterates and performs the best possible swap (one item in, one item out)\n        // until no further improvements can be made.\n        if !selected.is_empty() {\n            let mut interaction_sums = vec![0i64; num_items];\n            for i in 0..num_items {\n                for &k in &selected {\n                    interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                }\n            }\n\n            // Calculate initial value\n            let mut current_value: i64 = 0;\n            for &i in &selected {\n                current_value += challenge.values[i] as i64;\n                // Summing interaction_sums[i] over i in selected counts interactions twice.\n                current_value += interaction_sums[i] / 2;\n            }\n\n            let mut best_value = current_value;\n            let mut best_selected = selected.clone();\n            let mut best_total_weight = total_weight;\n\n            let mut rng = SmallRng::from_seed(challenge.seed);\n            let mut iterations_since_best_update = 0;\n\n            // Phase 2: Tabu Search (1-opt swap)\n            // Tabu List: stores the iteration when an item's removal restriction expires.\n            let mut tabu_list = vec![0usize; num_items];\n            let tabu_tenure = hyperparameters.tabu_tenure;\n            let max_iterations = hyperparameters.tabu_iterations;\n            let non_improving_limit = hyperparameters.non_improving_limit;\n            let tie_breaking_prob = hyperparameters.tie_breaking_prob;\n\n            // Define move types for clarity\n            enum Move {\n                Swap { i_vec_idx: usize, j_idx: usize },\n                Add { j_idx: usize },\n                Remove { i_vec_idx: usize },\n            }\n\n            for iteration in 1..=max_iterations {\n                iterations_since_best_update += 1;\n                let mut best_move: Option<(Move, i64)> = None;\n                let mut best_delta = i64::MIN;\n\n                // --- 1. Search Swap neighborhood (i out, j in) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx]; // Item to remove\n\n                    for item_j in 0..num_items { // Item to add\n                        if is_selected[item_j] { continue; }\n\n                        // 1. Check weight constraint\n                        let delta_weight = challenge.weights[item_j] as i64 - challenge.weights[item_i] as i64;\n                        if (total_weight as i64 + delta_weight) > challenge.max_weight as i64 {\n                            continue;\n                        }\n\n                        // 2. Calculate Delta Value\n                        // Delta V = (v_j - v_i) + (interaction_sums[j] - c_{ji}) - interaction_sums[i]\n                        let delta_value = (challenge.values[item_j] as i64 - challenge.values[item_i] as i64)\n                                        + (interaction_sums[item_j] - challenge.interaction_values[item_j][item_i] as i64)\n                                        - interaction_sums[item_i];\n\n                        let new_value = current_value + delta_value;\n\n                        // 3. Tabu Check & Aspiration Criterion\n                        // Item i (removed) is tabu from being added back.\n                        let is_tabu = tabu_list[item_i] > iteration;\n                        let is_aspirated = is_tabu && (new_value > best_value);\n\n                        if !is_tabu || is_aspirated {\n                            if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(tie_breaking_prob)) {\n                                best_delta = delta_value;\n                                best_move = Some((Move::Swap { i_vec_idx, j_idx: item_j }, delta_value));\n                            }\n                        }\n                    }\n                }\n\n                // --- 2. Search Add neighborhood (j in) ---\n                for item_j in 0..num_items {\n                    if is_selected[item_j] { continue; }\n                    let item_weight = challenge.weights[item_j];\n\n                    if total_weight + item_weight <= challenge.max_weight {\n                        // Delta V = v_j + interaction_sums[j]\n                        let delta_value = challenge.values[item_j] as i64 + interaction_sums[item_j];\n                        \n                        if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(tie_breaking_prob)) {\n                            best_delta = delta_value;\n                            best_move = Some((Move::Add { j_idx: item_j }, delta_value));\n                        }\n                    }\n                }\n\n                // --- 3. Search Remove neighborhood (i out) ---\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx]; // Item to remove\n\n                    // Delta V = -v_i - interaction_sums[i]\n                    let delta_value = -(challenge.values[item_i] as i64 + interaction_sums[item_i]);\n                    let new_value = current_value + delta_value;\n\n                    // Tabu Check: Item i (removed) is tabu from being added back.\n                    let is_tabu = tabu_list[item_i] > iteration;\n                    let is_aspirated = is_tabu && (new_value > best_value);\n\n                    if !is_tabu || is_aspirated {\n                        if delta_value > best_delta || (delta_value == best_delta && rng.gen_bool(tie_breaking_prob)) {\n                            best_delta = delta_value;\n                            best_move = Some((Move::Remove { i_vec_idx }, delta_value));\n                        }\n                    }\n                }\n\n                // If no feasible move (respecting weight constraint) is found, stop.\n                if best_move.is_none() {\n                    break;\n                }\n\n                // Perform the best move found\n                let (move_type, delta) = best_move.unwrap();\n                current_value += delta;\n\n                match move_type {\n                    Move::Swap { i_vec_idx, j_idx } => {\n                        let item_i = selected[i_vec_idx];\n\n                        // 1. Update weight\n                        let delta_weight = challenge.weights[j_idx] as i64 - challenge.weights[item_i] as i64;\n                        total_weight = (total_weight as i64 + delta_weight) as u32;\n\n                        // 2. Update selection status and list\n                        is_selected[item_i] = false;\n                        is_selected[j_idx] = true;\n                        selected[i_vec_idx] = j_idx;\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] += c_{k, j_new} - c_{k, i_old}\n                        for k in 0..num_items {\n                            interaction_sums[k] += (challenge.interaction_values[k][j_idx] - challenge.interaction_values[k][item_i]) as i64;\n                        }\n\n                        // 4. Update Tabu List: Tabu the item removed (i)\n                        tabu_list[item_i] = iteration + tabu_tenure;\n                    }\n                    Move::Add { j_idx } => {\n                        // 1. Update weight\n                        total_weight += challenge.weights[j_idx];\n\n                        // 2. Update selection status and list\n                        is_selected[j_idx] = true;\n                        selected.push(j_idx);\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] += c_{k, j_new}\n                        for k in 0..num_items {\n                            interaction_sums[k] += challenge.interaction_values[k][j_idx] as i64;\n                        }\n                        // No item removed, no tabu restriction applied.\n                    }\n                    Move::Remove { i_vec_idx } => {\n                        let item_i = selected[i_vec_idx];\n\n                        // 1. Update weight\n                        total_weight -= challenge.weights[item_i];\n\n                        // 2. Update selection status and list\n                        is_selected[item_i] = false;\n                        selected.swap_remove(i_vec_idx); // O(1) removal, order doesn't matter\n\n                        // 3. Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] -= c_{k, i_old}\n                        for k in 0..num_items {\n                            interaction_sums[k] -= challenge.interaction_values[k][item_i] as i64;\n                        }\n\n                        // 4. Update Tabu List: Tabu the item removed (i)\n                        tabu_list[item_i] = iteration + tabu_tenure;\n                    }\n                }\n\n                // 5. Update Best Solution\n                if current_value > best_value {\n                    best_value = current_value;\n                    best_selected = selected.clone();\n                    best_total_weight = total_weight;\n                    iterations_since_best_update = 0;\n                }\n\n                // 6. Diversification on Stagnation (Iterated Local Search perturbation)\n                if iterations_since_best_update > non_improving_limit {\n                    // 6a. Restore to the best known solution (Intensification phase start)\n                    selected = best_selected.clone();\n                    current_value = best_value;\n                    total_weight = best_total_weight;\n\n                    // Recalculate state based on the restored best solution\n                    is_selected.fill(false);\n                    for &item in &selected {\n                        is_selected[item] = true;\n                    }\n\n                    // Recalculate interaction_sums based on the restored best solution (O(N*|S|), worst case O(N^2))\n                    interaction_sums.fill(0);\n                    for i in 0..num_items {\n                        for &k in &selected {\n                            interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                        }\n                    }\n                    \n                    // 6b. Perturb the solution (Diversification phase: Random Removal)\n                    let perturbation_count = ((selected.len() as f64) * hyperparameters.perturbation_size_factor).round() as usize;\n                    \n                    // Randomly remove items using efficient O(N) updates\n                    for _ in 0..perturbation_count {\n                        if selected.is_empty() { break; }\n                        \n                        // Select a random index in the selected list\n                        let remove_idx = rng.gen_range(0..selected.len());\n                        let item_i = selected[remove_idx];\n\n                        // Delta V = -v_i - interaction_sums[i]\n                        let delta_value = -(challenge.values[item_i] as i64 + interaction_sums[item_i]);\n                        current_value += delta_value;\n\n                        total_weight -= challenge.weights[item_i];\n                        is_selected[item_i] = false;\n                        selected.swap_remove(remove_idx);\n\n                        // Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] -= c_{k, i_old}\n                        for k in 0..num_items {\n                            interaction_sums[k] -= challenge.interaction_values[k][item_i] as i64;\n                        }\n                    }\n\n                    // 6c. Clear the tabu list and reset counter\n                    tabu_list.fill(0);\n                    iterations_since_best_update = 0;\n                }\n            }\n\n            // Restore the best solution found during the Tabu Search run\n            selected = best_selected;\n            total_weight = best_total_weight;\n        }\n    }\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: score, complexity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["This evolution aims to revert the algorithm to the structure that previously achieved the highest score (0.5409). The previous implementation incorporated an Iterated Local Search (ILS) diversification step (random removal) upon stagnation, which appears to have degraded performance (score 0.5030). By removing the explicit perturbation step and replacing it with pure intensification (restarting the Tabu Search from the best known solution), we restore the proven high-performance structure.\n\n### Change 1: Hyperparameter cleanup\n\nRemove the unused `perturbation_size_factor` from the `Hyperparameters` struct definition and default initialization.\n\n<<<<<<< SEARCH\n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub tabu_iterations: usize,\n        pub tabu_tenure: usize,\n        pub non_improving_limit: usize,\n        pub tie_breaking_prob: f64,\n        pub perturbation_size_factor: f64,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .map_err(|e| anyhow!(\"Failed to parse hyperparameters: {}\", e))?\n        }\n        None => Hyperparameters {\n            tabu_iterations: 10000,\n            // A dynamic tenure based on problem size often works well.\n            tabu_tenure: ((num_items as f64).sqrt().round() as usize).max(5),\n            non_improving_limit: 1000,\n            tie_breaking_prob: 0.1,\n            perturbation_size_factor: 0.15, // Default: remove 15% of items\n        },\n    };\n=======\n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub tabu_iterations: usize,\n        pub tabu_tenure: usize,\n        pub non_improving_limit: usize,\n        pub tie_breaking_prob: f64,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .map_err(|e| anyhow!(\"Failed to parse hyperparameters: {}\", e))?\n        }\n        None => Hyperparameters {\n            tabu_iterations: 10000,\n            // A dynamic tenure based on problem size often works well.\n            tabu_tenure: ((num_items as f64).sqrt().round() as usize).max(5),\n            non_improving_limit: 1000,\n            tie_breaking_prob: 0.1,\n        },\n    };\n>>>>>>> REPLACE\n\n### Change 2: Revert diversification to intensification\n\nReplace the ILS perturbation logic with the standard Tabu Search intensification mechanism used in the top-performing programs, which restores the best solution and clears the tabu list upon stagnation.\n\n<<<<<<< SEARCH\n                // 6. Diversification on Stagnation (Iterated Local Search perturbation)\n                if iterations_since_best_update > non_improving_limit {\n                    // 6a. Restore to the best known solution (Intensification phase start)\n                    selected = best_selected.clone();\n                    current_value = best_value;\n                    total_weight = best_total_weight;\n\n                    // Recalculate state based on the restored best solution\n                    is_selected.fill(false);\n                    for &item in &selected {\n                        is_selected[item] = true;\n                    }\n\n                    // Recalculate interaction_sums based on the restored best solution (O(N*|S|), worst case O(N^2))\n                    interaction_sums.fill(0);\n                    for i in 0..num_items {\n                        for &k in &selected {\n                            interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                        }\n                    }\n                    \n                    // 6b. Perturb the solution (Diversification phase: Random Removal)\n                    let perturbation_count = ((selected.len() as f64) * hyperparameters.perturbation_size_factor).round() as usize;\n                    \n                    // Randomly remove items using efficient O(N) updates\n                    for _ in 0..perturbation_count {\n                        if selected.is_empty() { break; }\n                        \n                        // Select a random index in the selected list\n                        let remove_idx = rng.gen_range(0..selected.len());\n                        let item_i = selected[remove_idx];\n\n                        // Delta V = -v_i - interaction_sums[i]\n                        let delta_value = -(challenge.values[item_i] as i64 + interaction_sums[item_i]);\n                        current_value += delta_value;\n\n                        total_weight -= challenge.weights[item_i];\n                        is_selected[item_i] = false;\n                        selected.swap_remove(remove_idx);\n\n                        // Update interaction_sums efficiently in O(N).\n                        // interaction_sums[k] -= c_{k, i_old}\n                        for k in 0..num_items {\n                            interaction_sums[k] -= challenge.interaction_values[k][item_i] as i64;\n                        }\n                    }\n\n                    // 6c. Clear the tabu list and reset counter\n                    tabu_list.fill(0);\n                    iterations_since_best_update = 0;\n                }\n            }\n=======\n                // 6. Intensification on Stagnation\n                if iterations_since_best_update > non_improving_limit {\n                    // Return to the best known solution to intensify the search in that area\n                    selected = best_selected.clone();\n                    current_value = best_value;\n                    total_weight = best_total_weight;\n\n                    // Recalculate state based on the restored best solution\n                    is_selected.fill(false);\n                    for &item in &selected {\n                        is_selected[item] = true;\n                    }\n\n                    interaction_sums.fill(0);\n                    for i in 0..num_items {\n                        for &k in &selected {\n                            interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                        }\n                    }\n                    \n                    // Clear the tabu list to allow free exploration from this point\n                    tabu_list.fill(0);\n                    iterations_since_best_update = 0;\n                }\n            }\n>>>>>>> REPLACE"]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}