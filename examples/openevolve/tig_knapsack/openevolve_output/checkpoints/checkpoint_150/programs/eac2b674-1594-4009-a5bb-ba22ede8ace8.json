{"id": "eac2b674-1594-4009-a5bb-ba22ede8ace8", "code": "// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub max_restarts: usize,\n        pub base_perturbation_size: usize,\n        pub stagnation_limit: usize,\n        pub perturbation_increase_factor: f64,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .unwrap_or(Hyperparameters {\n                    max_restarts: 500, // Increased restarts for deeper exploration\n                    base_perturbation_size: 25, // Slightly larger base perturbation\n                    stagnation_limit: 40, // Increased limit to allow more local searching before drastic change\n                    perturbation_increase_factor: 1.2, // Slightly reduced factor for smoother adaptation\n                })\n        }\n        None => Hyperparameters {\n            max_restarts: 500,\n            base_perturbation_size: 25,\n            stagnation_limit: 40,\n            perturbation_increase_factor: 1.2,\n        },\n    };\n\n    let num_items = challenge.values.len();\n    let weights = &challenge.weights;\n    let values = &challenge.values;\n    let interactions = &challenge.interaction_values;\n    let max_weight = challenge.max_weight;\n\n    let mut rng = SmallRng::from_seed(challenge.seed);\n\n    // --- State Variables (Current Solution) ---\n    let mut is_selected = vec![false; num_items];\n    let mut current_weight: u32 = 0;\n    // marginal_gains[i] = values[i] + sum(interactions[i][j]) for all j currently selected.\n    let mut marginal_gains: Vec<i64> = values.iter().map(|&v| v as i64).collect();\n    let mut current_value: i64 = 0;\n\n    // --- Best Solution Tracking ---\n    let mut best_solution = vec![false; num_items];\n    let mut best_value = i64::MIN;\n\n    #[derive(Debug, Clone, Copy)]\n    enum LS_Move {\n        Add(usize),\n        Remove(usize),\n        Swap(usize, usize), // (item_to_remove, item_to_add)\n    }\n    \n\n\n    // Helper function to run Best Improvement Local Search (BILS) until convergence\n    // Modifies state variables in place.\n    let mut run_bils = |\n        is_selected: &mut Vec<bool>,\n        current_weight: &mut u32,\n        marginal_gains: &mut Vec<i64>,\n        current_value: &mut i64\n    | {\n        loop {\n            let mut best_delta_v = 0i64;\n            let mut best_move: Option<LS_Move> = None;\n\n            // O(N^2) neighborhood search\n            for j in 0..num_items {\n                if is_selected[j] {\n                    // Item j is selected: Check Remove and Swap moves involving j\n\n                    // --- Remove Move (j out) ---\n                    let delta_v_remove_j = -marginal_gains[j];\n                    if delta_v_remove_j > best_delta_v {\n                        best_delta_v = delta_v_remove_j;\n                        best_move = Some(LS_Move::Remove(j));\n                    }\n\n                    // --- Swap Moves (j out, i in) ---\n                    let w_j = weights[j];\n                    \n                    for i in 0..num_items {\n                        if !is_selected[i] {\n                            let w_i = weights[i];\n                            \n                            // Check weight constraint for swap\n                            let delta_w = w_i as i64 - w_j as i64;\n                            if (*current_weight as i64 + delta_w) <= max_weight as i64 {\n                                \n                                // Delta V(j out, i in) = MG[i] - interactions[i][j] - MG[j]\n                                let delta_v_swap = marginal_gains[i] - interactions[i][j] as i64 - marginal_gains[j];\n\n                                if delta_v_swap > best_delta_v {\n                                    best_delta_v = delta_v_swap;\n                                    best_move = Some(LS_Move::Swap(j, i));\n                                }\n                            }\n                        }\n                    }\n                } else {\n                    // Item i is unselected: Check Add moves\n                    let i = j;\n                    let w_i = weights[i];\n\n                    // --- Add Move (i in) ---\n                    if current_weight.checked_add(w_i).map_or(false, |w| w <= max_weight) {\n                        let delta_v_add_i = marginal_gains[i];\n\n                        if delta_v_add_i > best_delta_v {\n                            best_delta_v = delta_v_add_i;\n                            best_move = Some(LS_Move::Add(i));\n                        }\n                    }\n                }\n            }\n\n            if best_delta_v > 0 {\n                *current_value += best_delta_v;\n\n                match best_move.unwrap() {\n                    LS_Move::Add(i) => {\n                        is_selected[i] = true;\n                        *current_weight += weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] += interactions[i][k] as i64;\n                        }\n                    }\n                    LS_Move::Remove(j) => {\n                        is_selected[j] = false;\n                        *current_weight -= weights[j];\n                        for k in 0..num_items {\n                            marginal_gains[k] -= interactions[j][k] as i64;\n                        }\n                    }\n                    LS_Move::Swap(j, i) => {\n                        is_selected[j] = false;\n                        is_selected[i] = true;\n                        *current_weight = *current_weight - weights[j] + weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] = marginal_gains[k] - interactions[j][k] as i64 + interactions[i][k] as i64;\n                        }\n                    }\n                }\n            } else {\n                break; // Local optimum reached\n            }\n        }\n    };\n\n    // --- 1. Initial Greedy Construction Phase (O(N^2)) ---\n    loop {\n        let mut best_item: Option<usize> = None;\n        let mut best_density: f64 = f64::NEG_INFINITY;\n\n        for i in 0..num_items {\n            if !is_selected[i] {\n                let item_weight = weights[i];\n                if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                    let gain = marginal_gains[i];\n                    \n                    let density = if item_weight == 0 {\n                        if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                    } else {\n                        gain as f64 / item_weight as f64\n                    };\n\n                    if density > best_density {\n                        best_density = density;\n                        best_item = Some(i);\n                    }\n                }\n            }\n        }\n\n        if let Some(idx_to_add) = best_item {\n            // Update value incrementally\n            current_value += marginal_gains[idx_to_add]; \n            \n            is_selected[idx_to_add] = true;\n            current_weight += weights[idx_to_add];\n\n            // Update marginal gains for ALL items (O(N) step). \n            for i in 0..num_items {\n                marginal_gains[i] += interactions[idx_to_add][i] as i64;\n            }\n        } else {\n            break;\n        }\n    }\n    \n    // Initialize best solution tracking (current_value is already correct)\n    best_value = current_value;\n    best_solution = is_selected.clone();\n\n    // --- 2. Iterated Local Search (ILS) with Adaptive Perturbation ---\n    let mut iterations_since_best_update = 0;\n    let mut dynamic_perturbation_size = hyperparameters.base_perturbation_size;\n\n    for restart in 0..hyperparameters.max_restarts {\n        \n        // A. Run BILS on the current state until local optimum is reached\n        run_bils(&mut is_selected, &mut current_weight, &mut marginal_gains, &mut current_value);\n\n        // B. Update Best Solution and adapt perturbation strength\n        if current_value > best_value {\n            best_value = current_value;\n            best_solution = is_selected.clone();\n            iterations_since_best_update = 0;\n            // On improvement, reset perturbation strength to base to focus search locally\n            dynamic_perturbation_size = hyperparameters.base_perturbation_size;\n        } else {\n            iterations_since_best_update += 1;\n        }\n\n        if iterations_since_best_update >= hyperparameters.stagnation_limit {\n            // Stagnation detected: increase perturbation strength to escape\n            dynamic_perturbation_size = (dynamic_perturbation_size as f64 * hyperparameters.perturbation_increase_factor).round() as usize;\n            // Cap the size to avoid destroying the solution completely\n            let max_p_size = (num_items as f64 * 0.4) as usize; // Don't remove more than 40% of items\n            dynamic_perturbation_size = dynamic_perturbation_size.min(max_p_size);\n            iterations_since_best_update = 0; // Reset counter after strengthening\n        }\n\n        if restart == hyperparameters.max_restarts - 1 {\n            break; // No need to perturb after the last optimization run\n        }\n\n        // C. Perturbation Phase (Biased removal + Incremental Repair)\n        let mut selected_indices: Vec<usize> = (0..num_items).filter(|&i| is_selected[i]).collect();\n        let num_selected = selected_indices.len();\n        \n        let p_size = dynamic_perturbation_size.min(num_selected);\n        \n        // 1. & 2. Biasedly remove P_size items and update state incrementally (O(P*N))\n        for _ in 0..p_size {\n            if selected_indices.is_empty() { break; }\n\n            // Calculate MG_max for normalization (O(N_selected))\n            let mg_max = selected_indices.iter()\n                .map(|&i| marginal_gains[i])\n                .max()\n                .unwrap_or(1); \n\n            // Calculate weights: S_j = MG_max - MG_j + 1 (Bias towards low MG items)\n            let mut total_weight = 0i64;\n            let weights_and_indices: Vec<(i64, usize)> = selected_indices.iter().map(|&j| {\n                // Ensure weight is positive and non-zero. \n                let weight = mg_max - marginal_gains[j] + 1; \n                total_weight += weight;\n                (weight, j)\n            }).collect();\n\n            // Select item j using roulette wheel selection (O(N_selected))\n            let target = rng.gen_range(0..total_weight);\n            let mut cumulative_weight = 0i64;\n            \n            let mut removal_index_in_vec = 0; // Index in selected_indices vector\n            \n            for (idx, &(weight, _)) in weights_and_indices.iter().enumerate() {\n                cumulative_weight += weight;\n                if cumulative_weight > target {\n                    removal_index_in_vec = idx;\n                    break;\n                }\n            }\n            \n            // Retrieve item index j and remove it from selected_indices (O(1) using swap_remove)\n            let j = selected_indices.swap_remove(removal_index_in_vec);\n\n            // Update value incrementally using the current marginal gain\n            current_value -= marginal_gains[j];\n            \n            is_selected[j] = false;\n            current_weight -= weights[j];\n\n            // Update marginal gains for all other items due to j's removal (O(N))\n            for k in 0..num_items {\n                marginal_gains[k] -= interactions[j][k] as i64;\n            }\n        }\n\n        // 3. Greedy Repair (Add items back based on marginal density)\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_density: f64 = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = weights[i];\n                    if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                        let gain = marginal_gains[i];\n                        \n                        let density = if item_weight == 0 {\n                            if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                        } else {\n                            gain as f64 / item_weight as f64\n                        };\n\n                        if density > best_density {\n                            best_density = density;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(idx_to_add) = best_item {\n                is_selected[idx_to_add] = true;\n                current_weight += weights[idx_to_add];\n                current_value += marginal_gains[idx_to_add]; // Update value incrementally\n\n                // Update marginal gains for ALL items (O(N) step). \n                for i in 0..num_items {\n                    marginal_gains[i] += interactions[idx_to_add][i] as i64;\n                }\n            } else {\n                break;\n            }\n        }\n    }\n\n    // Finalize solution indices from the best solution found\n    let selected: Vec<usize> = (0..num_items).filter(|&i| best_solution[i]).collect();\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}", "language": "rust", "parent_id": "c0098818-4687-48c1-a9ae-9f19c1be2bd8", "generation": 9, "timestamp": 1766160879.077242, "iteration_found": 137, "metrics": {"avg_btb": 0.0008561399999999999, "combined_score": 0.6311164724876006, "eval_time": 30.837596149, "memory": 371072.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 17 lines with 17 lines", "parent_metrics": {"avg_btb": 0.00084895, "combined_score": 0.616530984990612, "eval_time": 12.248226361, "memory": 371072.0}, "island": 1}, "prompts": {"diff_user": {"system": "SETTING:\nYou are an expert Rust programmer specializing in combinatorial optimization algorithms with deep expertise in knapsack problems, resource allocation algorithms, and constraint satisfaction.\nYour mission is to evolve and optimize a quadratic knapsack algorithm that outputs the highest quality possible.\n\n\n=== CRITICAL OUTPUT FORMAT RULES ===\n1. Output ONLY raw Rust source code\n2. Include the complete file from first line to last line\n=== END OUTPUT FORMAT RULES ===\n\nAlgorithm Improvement Instructions:\n\nObjective\nImprove the knapsack algorithm to maximize the total value while respecting the weight constraint.\n\nCRITICAL Constraints\n- You may ONLY modify code between // EVOLVE-BLOCK-START and // EVOLVE-BLOCK-END\n- Code outside these markers (imports, function wrapper, save_solution call) must NEVER be modified\n- You MUST NOT modify the function signature\n- You MUST NOT modify lines before // EVOLVE-BLOCK-START\n- You MUST NOT modify lines after // EVOLVE-BLOCK-END\n- You MUST preserve the exact structure of code outside the evolve block\n\nInput: challenge parameter (type: &Challenge)\n\nThe challenge parameter provides access to the following fields with these EXPLICIT types:\n\n- challenge.seed: [u8; 32] - Fixed-size array of 32 bytes for seeding random number generators\n- challenge.weights: Vec<u32> - Vector of unsigned 32-bit integers representing each item's weight\n- challenge.values: Vec<u32> - Vector of unsigned 32-bit integers representing each item's base value\n- challenge.interaction_values: Vec<Vec<i32>> - 2D matrix (vector of vectors) of SIGNED 32-bit integers\n  - interaction_values[i][j] gives the bonus value when items i and j are BOTH selected\n  - This matrix is symmetric: interaction_values[i][j] == interaction_values[j][i]\n  - Diagonal is zero: interaction_values[i][i] == 0\n- challenge.max_weight: u32 - Unsigned 32-bit integer representing maximum total weight allowed\n  \nImportant notes:\n- All vectors have the same length (number of items)\n- challenge.weights.len() = challenge.values.len() = challenge.interaction_values.len()\n- Item indices are 0 to n-1 where n = challenge.values.len()\n- the structure of the algorithm i.e. the inputs and outputs are fixed, you can only modify the body of the algorithm.\n\nOutput: selected variable (type: Vec<usize>)\n\nYour code must create a variable named selected with the following specification:\n\n- Type: Vec<usize> (vector of unsigned size integers)\n- Content: Indices of items to include in the knapsack solution\n- Valid range: Each element must be in range [0, n-1] where n = challenge.values.len()\n- No duplicates: Each item index can appear at most once\n- Weight constraint: The sum of challenge.weights[i] for all i in selected must be \u2264 challenge.max_weight\n\nThe selected variable is automatically saved after the evolve block ends.\n\nContext:\n- This is a QUADRATIC knapsack problem with interaction values between items\n- Items have: weights, values, and interaction_values (2D matrix)\n- Total value = sum of item values + sum of interaction values for pairs of selected items\n- Constraint: total weight must not exceed max_weight which is half the weight of all items\n- The \"density\" of the knapsack is 25% - meaning interaction values in the symmetric interaction matrix are 0 with probability 0.75; otherwise a random number between 1 and 100.\n\nBENCHMARK:\n- Beat the state-of-the-art result of avg_btb = 0.0015.\n\nHyperparameters (Optional):\nIf your algorithm uses tunable parameters (e.g., iteration counts, thresholds, probabilities),\nyou can define them inside the EVOLVE-BLOCK. Follow these examples exactly.\n\nCRITICAL: The examples below show raw Rust code. Do NOT wrap them in markdown code fences.\n\n\nStep 1 - Define a Hyperparameters struct inside the EVOLVE-BLOCK:\n\n#[derive(Serialize, Deserialize)]\npub struct Hyperparameters {\n    pub max_iterations: usize,\n    pub temperature: f64,\n}\n\nStep 2 - Parse hyperparameters at the start of your code block:\n\nlet hyperparameters = match _hyperparameters {\n    Some(params) => {\n        serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n            .map_err(|e| anyhow!(\"Failed to parse hyperparameters: {}\", e))?\n    }\n    None => Hyperparameters {\n        max_iterations: 100,\n        temperature: 0.95,\n    },\n};\n\nStep 3 - Use the hyperparameter values in your algorithm:\n\nfor _ in 0..hyperparameters.max_iterations {\n    // your algorithm logic here\n}\n\n\nRandom numbers:\nIf you need random numbers, recommend using SmallRng with challenge.seed:\nlet mut rng = SmallRng::from_seed(challenge.seed);\n\nMake sure you use\n- Optimised sorting strategies \n- Efficient data structures for tracking selected items\n\nImportant:\n- Only modify code within the EVOLVE-BLOCK\n- Ensure the algorithm terminates within reasonable time\n- Use the provided Challenge struct fields: values, weights, interaction_values, max_weight\n- The variable selected is automatically saved after the evolve block ends\n\nPERFORMANCE METRICS:\n1. **avg_btb**: Average better than baseline; average percentage that the total value of the knapsack solution is better than a baseline value (PRIMARY OBJECTIVE - maximize)\n2. **combined_score**: progress toward beating the state-of-the-art benchmark\n3. **eval_time**: Execution time in seconds (keep reasonable, prefer accuracy over speed)\n4. **memory**: Memory usage in kilobytes (keep reasonable, prefer accuracy over speed)\n\nTECHNICAL REQUIREMENTS:\n- **Error handling**: Graceful handling of optimization failures or infeasible configurations\n- **Memory efficiency**: Avoid excessive memory allocation for matrix computations\n", "user": "# Current Program Information\n- Fitness: 0.6165\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness unchanged at 0.6165\n- Consider simplifying - code length exceeds 2000 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 19 lines with 25 lines\nChange 2: Replace 24 lines with 41 lines\n- Metrics: avg_btb: 0.0008, combined_score: 0.6165, eval_time: 12.3266, memory: 370944.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Change 1: Replace 19 lines with 25 lines\nChange 2: Replace 69 lines with 86 lines\n- Metrics: avg_btb: 0.0008, combined_score: 0.6165, eval_time: 12.6633, memory: 371200.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Change 1: Replace 19 lines with 25 lines\nChange 2: Replace 79 lines with 126 lines\n- Metrics: avg_btb: 0.0008, combined_score: 0.6165, eval_time: 12.3341, memory: 371200.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.6165)\n```rust\n// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub max_restarts: usize,\n        pub base_perturbation_size: usize,\n        pub stagnation_limit: usize,\n        pub perturbation_increase_factor: f64,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .unwrap_or(Hyperparameters {\n                    max_restarts: 250, // Increased restarts for better exploration\n                    base_perturbation_size: 20,\n                    stagnation_limit: 30, // Adaptive stagnation limit\n                    perturbation_increase_factor: 1.25,\n                })\n        }\n        None => Hyperparameters {\n            max_restarts: 250,\n            base_perturbation_size: 20,\n            stagnation_limit: 30,\n            perturbation_increase_factor: 1.25,\n        },\n    };\n\n    let num_items = challenge.values.len();\n    let weights = &challenge.weights;\n    let values = &challenge.values;\n    let interactions = &challenge.interaction_values;\n    let max_weight = challenge.max_weight;\n\n    let mut rng = SmallRng::from_seed(challenge.seed);\n\n    // --- State Variables (Current Solution) ---\n    let mut is_selected = vec![false; num_items];\n    let mut current_weight: u32 = 0;\n    // Marginal gains initialized with base values\n    let mut marginal_gains: Vec<i64> = values.iter().map(|&v| v as i64).collect();\n    let mut current_value: i64 = 0;\n\n    // --- Best Solution Tracking ---\n    let mut best_solution = vec![false; num_items];\n    let mut best_value = i64::MIN;\n\n    #[derive(Debug, Clone, Copy)]\n    enum LS_Move {\n        Add(usize),\n        Remove(usize),\n        Swap(usize, usize), // (item_to_remove, item_to_add)\n    }\n\n    // Helper function to run Best Improvement Local Search (BILS) until convergence\n    // Modifies state variables in place.\n    let mut run_bils = |\n        is_selected: &mut Vec<bool>,\n        current_weight: &mut u32,\n        marginal_gains: &mut Vec<i64>,\n        current_value: &mut i64\n    | {\n        loop {\n            let mut best_delta_v = 0i64;\n            let mut best_move: Option<LS_Move> = None;\n\n            // O(N^2) neighborhood search\n            for j in 0..num_items {\n                if is_selected[j] {\n                    // Item j is selected: Check Remove and Swap moves involving j\n\n                    // --- Remove Move (j out) ---\n                    // Delta V = -MG[j]\n                    let delta_v_remove_j = -marginal_gains[j];\n                    if delta_v_remove_j > best_delta_v {\n                        best_delta_v = delta_v_remove_j;\n                        best_move = Some(LS_Move::Remove(j));\n                    }\n\n                    // --- Swap Moves (j out, i in) ---\n                    let w_j = weights[j];\n                    \n                    for i in 0..num_items {\n                        if !is_selected[i] {\n                            let w_i = weights[i];\n                            \n                            // Check weight constraint for swap\n                            let delta_w = w_i as i64 - w_j as i64;\n                            if (*current_weight as i64 + delta_w) <= max_weight as i64 {\n                                \n                                // Delta V(j out, i in) = MG[i] - interactions[i][j] - MG[j]\n                                let delta_v_swap = marginal_gains[i] - interactions[i][j] as i64 - marginal_gains[j];\n\n                                if delta_v_swap > best_delta_v {\n                                    best_delta_v = delta_v_swap;\n                                    best_move = Some(LS_Move::Swap(j, i));\n                                }\n                            }\n                        }\n                    }\n                } else {\n                    // Item i is unselected: Check Add moves\n                    let i = j;\n                    let w_i = weights[i];\n\n                    // --- Add Move (i in) ---\n                    // Delta V = MG[i]\n                    if current_weight.checked_add(w_i).map_or(false, |w| w <= max_weight) {\n                        let delta_v_add_i = marginal_gains[i];\n\n                        if delta_v_add_i > best_delta_v {\n                            best_delta_v = delta_v_add_i;\n                            best_move = Some(LS_Move::Add(i));\n                        }\n                    }\n                }\n            }\n\n            if best_delta_v > 0 {\n                *current_value += best_delta_v;\n\n                match best_move.unwrap() {\n                    LS_Move::Add(i) => {\n                        is_selected[i] = true;\n                        *current_weight += weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] += interactions[i][k] as i64;\n                        }\n                    }\n                    LS_Move::Remove(j) => {\n                        is_selected[j] = false;\n                        *current_weight -= weights[j];\n                        for k in 0..num_items {\n                            marginal_gains[k] -= interactions[j][k] as i64;\n                        }\n                    }\n                    LS_Move::Swap(j, i) => {\n                        is_selected[j] = false;\n                        is_selected[i] = true;\n                        *current_weight = *current_weight - weights[j] + weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] = marginal_gains[k] - interactions[j][k] as i64 + interactions[i][k] as i64;\n                        }\n                    }\n                }\n            } else {\n                break; // Local optimum reached\n            }\n        }\n    };\n\n    // --- 1. Initial Greedy Construction Phase (O(N^2)) ---\n    loop {\n        let mut best_item: Option<usize> = None;\n        let mut best_density: f64 = f64::NEG_INFINITY;\n\n        for i in 0..num_items {\n            if !is_selected[i] {\n                let item_weight = weights[i];\n                if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                    let gain = marginal_gains[i];\n                    \n                    let density = if item_weight == 0 {\n                        if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                    } else {\n                        gain as f64 / item_weight as f64\n                    };\n\n                    if density > best_density {\n                        best_density = density;\n                        best_item = Some(i);\n                    }\n                }\n            }\n        }\n\n        if let Some(idx_to_add) = best_item {\n            // Update value incrementally\n            current_value += marginal_gains[idx_to_add]; \n            \n            is_selected[idx_to_add] = true;\n            current_weight += weights[idx_to_add];\n\n            // Update marginal gains for ALL items (O(N) step). \n            for i in 0..num_items {\n                marginal_gains[i] += interactions[idx_to_add][i] as i64;\n            }\n        } else {\n            break;\n        }\n    }\n    \n    // Initialize best solution tracking (current_value is already correct)\n    best_value = current_value;\n    best_solution = is_selected.clone();\n\n    // --- 2. Iterated Local Search (ILS) with Adaptive Perturbation ---\n    let mut iterations_since_best_update = 0;\n    let mut dynamic_perturbation_size = hyperparameters.base_perturbation_size;\n\n    for restart in 0..hyperparameters.max_restarts {\n        \n        // A. Run BILS on the current state until local optimum is reached\n        run_bils(&mut is_selected, &mut current_weight, &mut marginal_gains, &mut current_value);\n\n        // B. Update Best Solution and adapt perturbation strength\n        if current_value > best_value {\n            best_value = current_value;\n            best_solution = is_selected.clone();\n            iterations_since_best_update = 0;\n            // On improvement, reset perturbation strength to base to focus search locally\n            dynamic_perturbation_size = hyperparameters.base_perturbation_size;\n        } else {\n            iterations_since_best_update += 1;\n        }\n\n        if iterations_since_best_update >= hyperparameters.stagnation_limit {\n            // Stagnation detected: increase perturbation strength to escape\n            dynamic_perturbation_size = (dynamic_perturbation_size as f64 * hyperparameters.perturbation_increase_factor).round() as usize;\n            // Cap the size to avoid destroying the solution completely\n            let max_p_size = (num_items as f64 * 0.4) as usize; // Don't remove more than 40% of items\n            dynamic_perturbation_size = dynamic_perturbation_size.min(max_p_size);\n            iterations_since_best_update = 0; // Reset counter after strengthening\n        }\n\n        if restart == hyperparameters.max_restarts - 1 {\n            break; // No need to perturb after the last optimization run\n        }\n\n        // C. Perturbation Phase (Biased removal + Incremental Repair)\n        let mut selected_indices: Vec<usize> = (0..num_items).filter(|&i| is_selected[i]).collect();\n        let num_selected = selected_indices.len();\n        \n        let p_size = dynamic_perturbation_size.min(num_selected);\n        \n        // 1. & 2. Biasedly remove P_size items and update state incrementally (O(P*N))\n        for _ in 0..p_size {\n            if selected_indices.is_empty() { break; }\n\n            // Calculate MG_max for normalization (O(N_selected))\n            let mg_max = selected_indices.iter()\n                .map(|&i| marginal_gains[i])\n                .max()\n                .unwrap_or(1); \n\n            // Calculate weights: S_j = MG_max - MG_j + 1 (Bias towards low MG items)\n            let mut total_weight = 0i64;\n            let weights_and_indices: Vec<(i64, usize)> = selected_indices.iter().map(|&j| {\n                // Ensure weight is positive and non-zero. \n                let weight = mg_max - marginal_gains[j] + 1; \n                total_weight += weight;\n                (weight, j)\n            }).collect();\n\n            // Select item j using roulette wheel selection (O(N_selected))\n            let target = rng.gen_range(0..total_weight);\n            let mut cumulative_weight = 0i64;\n            \n            let mut removal_index_in_vec = 0; // Index in selected_indices vector\n            \n            for (idx, &(weight, _)) in weights_and_indices.iter().enumerate() {\n                cumulative_weight += weight;\n                if cumulative_weight > target {\n                    removal_index_in_vec = idx;\n                    break;\n                }\n            }\n            \n            // Retrieve item index j and remove it from selected_indices (O(1) using swap_remove)\n            let j = selected_indices.swap_remove(removal_index_in_vec);\n\n            // Update value incrementally using the current marginal gain\n            current_value -= marginal_gains[j];\n            \n            is_selected[j] = false;\n            current_weight -= weights[j];\n\n            // Update marginal gains for all other items due to j's removal (O(N))\n            for k in 0..num_items {\n                marginal_gains[k] -= interactions[j][k] as i64;\n            }\n        }\n\n        // 3. Greedy Repair (Add items back based on marginal density)\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_density: f64 = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = weights[i];\n                    if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                        let gain = marginal_gains[i];\n                        \n                        let density = if item_weight == 0 {\n                            if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                        } else {\n                            gain as f64 / item_weight as f64\n                        };\n\n                        if density > best_density {\n                            best_density = density;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(idx_to_add) = best_item {\n                is_selected[idx_to_add] = true;\n                current_weight += weights[idx_to_add];\n                current_value += marginal_gains[idx_to_add]; // Update value incrementally\n\n                // Update marginal gains for ALL items (O(N) step). \n                for i in 0..num_items {\n                    marginal_gains[i] += interactions[idx_to_add][i] as i64;\n                }\n            } else {\n                break;\n            }\n        }\n    }\n\n    // Finalize solution indices from the best solution found\n    let selected: Vec<usize> = (0..num_items).filter(|&i| best_solution[i]).collect();\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}\n```\nKey features: Performs well on avg_btb (0.0008), Performs well on combined_score (0.6165), Performs well on eval_time (12.3341), Performs well on memory (371200.0000)\n\n### Program 2 (Score: 0.6165)\n```rust\n// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub max_restarts: usize,\n        pub base_perturbation_size: usize,\n        pub stagnation_limit: usize,\n        pub perturbation_increase_factor: f64,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .unwrap_or(Hyperparameters {\n                    max_restarts: 250, // Increased restarts for better exploration\n                    base_perturbation_size: 20,\n                    stagnation_limit: 30, // Slightly increased limit\n                    perturbation_increase_factor: 1.25,\n                })\n        }\n        None => Hyperparameters {\n            max_restarts: 250,\n            base_perturbation_size: 20,\n            stagnation_limit: 30,\n            perturbation_increase_factor: 1.25,\n        },\n    };\n\n    let num_items = challenge.values.len();\n    let weights = &challenge.weights;\n    let values = &challenge.values;\n    let interactions = &challenge.interaction_values;\n    let max_weight = challenge.max_weight;\n\n    let mut rng = SmallRng::from_seed(challenge.seed);\n\n    // --- State Variables (Current Solution) ---\n    let mut is_selected = vec![false; num_items];\n    let mut current_weight: u32 = 0;\n    // Marginal gains initialized with base values\n    let mut marginal_gains: Vec<i64> = values.iter().map(|&v| v as i64).collect();\n    let mut current_value: i64 = 0;\n\n    // --- Best Solution Tracking ---\n    let mut best_solution = vec![false; num_items];\n    let mut best_value = i64::MIN;\n\n    #[derive(Debug, Clone, Copy)]\n    enum LS_Move {\n        Add(usize),\n        Remove(usize),\n        Swap(usize, usize), // (item_to_remove, item_to_add)\n    }\n\n    // Helper function to run Best Improvement Local Search (BILS) until convergence\n    // Modifies state variables in place.\n    let mut run_bils = |\n        is_selected: &mut Vec<bool>,\n        current_weight: &mut u32,\n        marginal_gains: &mut Vec<i64>,\n        current_value: &mut i64\n    | {\n        loop {\n            let mut best_delta_v = 0i64;\n            let mut best_move: Option<LS_Move> = None;\n\n            // O(N^2) neighborhood search\n            for j in 0..num_items {\n                if is_selected[j] {\n                    // Item j is selected: Check Remove and Swap moves involving j\n\n                    // --- Remove Move (j out) ---\n                    // Delta V = -MG[j]\n                    let delta_v_remove_j = -marginal_gains[j];\n                    if delta_v_remove_j > best_delta_v {\n                        best_delta_v = delta_v_remove_j;\n                        best_move = Some(LS_Move::Remove(j));\n                    }\n\n                    // --- Swap Moves (j out, i in) ---\n                    let w_j = weights[j];\n                    \n                    for i in 0..num_items {\n                        if !is_selected[i] {\n                            let w_i = weights[i];\n                            \n                            // Check weight constraint for swap\n                            let delta_w = w_i as i64 - w_j as i64;\n                            if (*current_weight as i64 + delta_w) <= max_weight as i64 {\n                                \n                                // Delta V(j out, i in) = MG[i] - interactions[i][j] - MG[j]\n                                let delta_v_swap = marginal_gains[i] - interactions[i][j] as i64 - marginal_gains[j];\n\n                                if delta_v_swap > best_delta_v {\n                                    best_delta_v = delta_v_swap;\n                                    best_move = Some(LS_Move::Swap(j, i));\n                                }\n                            }\n                        }\n                    }\n                } else {\n                    // Item i is unselected: Check Add moves\n                    let i = j;\n                    let w_i = weights[i];\n\n                    // --- Add Move (i in) ---\n                    // Delta V = MG[i]\n                    if current_weight.checked_add(w_i).map_or(false, |w| w <= max_weight) {\n                        let delta_v_add_i = marginal_gains[i];\n\n                        if delta_v_add_i > best_delta_v {\n                            best_delta_v = delta_v_add_i;\n                            best_move = Some(LS_Move::Add(i));\n                        }\n                    }\n                }\n            }\n\n            if best_delta_v > 0 {\n                *current_value += best_delta_v;\n\n                match best_move.unwrap() {\n                    LS_Move::Add(i) => {\n                        is_selected[i] = true;\n                        *current_weight += weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] += interactions[i][k] as i64;\n                        }\n                    }\n                    LS_Move::Remove(j) => {\n                        is_selected[j] = false;\n                        *current_weight -= weights[j];\n                        for k in 0..num_items {\n                            marginal_gains[k] -= interactions[j][k] as i64;\n                        }\n                    }\n                    LS_Move::Swap(j, i) => {\n                        is_selected[j] = false;\n                        is_selected[i] = true;\n                        *current_weight = *current_weight - weights[j] + weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] = marginal_gains[k] - interactions[j][k] as i64 + interactions[i][k] as i64;\n                        }\n                    }\n                }\n            } else {\n                break; // Local optimum reached\n            }\n        }\n    };\n\n\n\n    // --- 1. Initial Greedy Construction Phase (O(N^2)) ---\n    loop {\n        let mut best_item: Option<usize> = None;\n        let mut best_density: f64 = f64::NEG_INFINITY;\n\n        for i in 0..num_items {\n            if !is_selected[i] {\n                let item_weight = weights[i];\n                if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                    let gain = marginal_gains[i];\n                    \n                    let density = if item_weight == 0 {\n                        if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                    } else {\n                        gain as f64 / item_weight as f64\n                    };\n\n                    if density > best_density {\n                        best_density = density;\n                        best_item = Some(i);\n                    }\n                }\n            }\n        }\n\n        if let Some(idx_to_add) = best_item {\n            // Update value incrementally\n            current_value += marginal_gains[idx_to_add]; \n            \n            is_selected[idx_to_add] = true;\n            current_weight += weights[idx_to_add];\n\n            // Update marginal gains for ALL items (O(N) step). \n            for i in 0..num_items {\n                marginal_gains[i] += interactions[idx_to_add][i] as i64;\n            }\n        } else {\n            break;\n        }\n    }\n    \n    // Initialize best solution tracking (current_value is already correct)\n    best_value = current_value;\n    best_solution = is_selected.clone();\n\n    // --- 2. Iterated Local Search (ILS) with Adaptive Perturbation ---\n    let mut iterations_since_best_update = 0;\n    let mut dynamic_perturbation_size = hyperparameters.base_perturbation_size;\n\n    for restart in 0..hyperparameters.max_restarts {\n        \n        // A. Run BILS on the current state until local optimum is reached\n        run_bils(&mut is_selected, &mut current_weight, &mut marginal_gains, &mut current_value);\n\n        // B. Update Best Solution and adapt perturbation strength\n        if current_value > best_value {\n            best_value = current_value;\n            best_solution = is_selected.clone();\n            iterations_since_best_update = 0;\n            // On improvement, reset perturbation strength to base to focus search locally\n            dynamic_perturbation_size = hyperparameters.base_perturbation_size;\n        } else {\n            iterations_since_best_update += 1;\n        }\n\n        if iterations_since_best_update >= hyperparameters.stagnation_limit {\n            // Stagnation detected: increase perturbation strength to escape\n            dynamic_perturbation_size = (dynamic_perturbation_size as f64 * hyperparameters.perturbation_increase_factor).round() as usize;\n            // Cap the size to avoid destroying the solution completely\n            let max_p_size = (num_items as f64 * 0.4) as usize; // Don't remove more than 40% of items\n            dynamic_perturbation_size = dynamic_perturbation_size.min(max_p_size);\n            iterations_since_best_update = 0; // Reset counter after strengthening\n        }\n\n        if restart == hyperparameters.max_restarts - 1 {\n            break; // No need to perturb after the last optimization run\n        }\n\n        // C. Perturbation Phase (Biased removal + Incremental Repair)\n        let mut selected_indices: Vec<usize> = (0..num_items).filter(|&i| is_selected[i]).collect();\n        let num_selected = selected_indices.len();\n        \n        let p_size = dynamic_perturbation_size.min(num_selected);\n        \n        // 1. & 2. Biasedly remove P_size items and update state incrementally (O(P*N))\n        for _ in 0..p_size {\n            if selected_indices.is_empty() { break; }\n\n            // Calculate MG_max for normalization (O(N_selected))\n            let mg_max = selected_indices.iter()\n                .map(|&i| marginal_gains[i])\n                .max()\n                .unwrap_or(1); \n\n            // Calculate weights: S_j = MG_max - MG_j + 1 (Bias towards low MG items)\n            let mut total_weight = 0i64;\n            let weights_and_indices: Vec<(i64, usize)> = selected_indices.iter().map(|&j| {\n                // Ensure weight is positive and non-zero. \n                let weight = mg_max - marginal_gains[j] + 1; \n                total_weight += weight;\n                (weight, j)\n            }).collect();\n\n            // Select item j using roulette wheel selection (O(N_selected))\n            let target = rng.gen_range(0..total_weight);\n            let mut cumulative_weight = 0i64;\n            \n            let mut removal_index_in_vec = 0; // Index in selected_indices vector\n            \n            for (idx, &(weight, _)) in weights_and_indices.iter().enumerate() {\n                cumulative_weight += weight;\n                if cumulative_weight > target {\n                    removal_index_in_vec = idx;\n                    break;\n                }\n            }\n            \n            // Retrieve item index j and remove it from selected_indices (O(1) using swap_remove)\n            let j = selected_indices.swap_remove(removal_index_in_vec);\n\n            // Update value incrementally using the current marginal gain\n            current_value -= marginal_gains[j];\n            \n            is_selected[j] = false;\n            current_weight -= weights[j];\n\n            // Update marginal gains for all other items due to j's removal (O(N))\n            for k in 0..num_items {\n                marginal_gains[k] -= interactions[j][k] as i64;\n            }\n        }\n\n        // 3. Greedy Repair (Add items back based on marginal density)\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_density: f64 = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = weights[i];\n                    if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                        let gain = marginal_gains[i];\n                        \n                        let density = if item_weight == 0 {\n                            if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                        } else {\n                            gain as f64 / item_weight as f64\n                        };\n\n                        if density > best_density {\n                            best_density = density;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(idx_to_add) = best_item {\n                is_selected[idx_to_add] = true;\n                current_weight += weights[idx_to_add];\n                current_value += marginal_gains[idx_to_add]; // Update value incrementally\n\n                // Update marginal gains for ALL items (O(N) step). \n                for i in 0..num_items {\n                    marginal_gains[i] += interactions[idx_to_add][i] as i64;\n                }\n            } else {\n                break;\n            }\n        }\n    }\n\n    // Finalize solution indices from the best solution found\n    let selected: Vec<usize> = (0..num_items).filter(|&i| best_solution[i]).collect();\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}\n```\nKey features: Performs well on avg_btb (0.0008), Performs well on combined_score (0.6165), Performs well on eval_time (12.6633), Performs well on memory (371200.0000)\n\n### Program 3 (Score: 0.6165)\n```rust\n// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub max_restarts: usize,\n        pub base_perturbation_size: usize,\n        pub stagnation_limit: usize,\n        pub perturbation_increase_factor: f64,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .unwrap_or(Hyperparameters {\n                    max_restarts: 250, // Increased restarts for better exploration\n                    base_perturbation_size: 20,\n                    stagnation_limit: 30, // Slightly increased limit\n                    perturbation_increase_factor: 1.25,\n                })\n        }\n        None => Hyperparameters {\n            max_restarts: 250,\n            base_perturbation_size: 20,\n            stagnation_limit: 30,\n            perturbation_increase_factor: 1.25,\n        },\n    };\n\n    let num_items = challenge.values.len();\n    let weights = &challenge.weights;\n    let values = &challenge.values;\n    let interactions = &challenge.interaction_values;\n    let max_weight = challenge.max_weight;\n\n    let mut rng = SmallRng::from_seed(challenge.seed);\n\n    // --- State Variables (Current Solution) ---\n    let mut is_selected = vec![false; num_items];\n    let mut current_weight: u32 = 0;\n    // Marginal gains initialized with base values\n    let mut marginal_gains: Vec<i64> = values.iter().map(|&v| v as i64).collect();\n    let mut current_value: i64 = 0;\n\n    // --- Best Solution Tracking ---\n    let mut best_solution = vec![false; num_items];\n    let mut best_value = i64::MIN;\n\n    #[derive(Debug, Clone, Copy)]\n    enum LS_Move {\n        Add(usize),\n        Remove(usize),\n        Swap(usize, usize), // (item_to_remove, item_to_add)\n    }\n\n    // Helper function to run Best Improvement Local Search (BILS) until convergence\n    // Modifies state variables in place.\n    let mut run_bils = |\n        is_selected: &mut Vec<bool>,\n        current_weight: &mut u32,\n        marginal_gains: &mut Vec<i64>,\n        current_value: &mut i64\n    | {\n        loop {\n            let mut best_delta_v = 0i64;\n            let mut best_move: Option<LS_Move> = None;\n\n            // O(N^2) neighborhood search\n            for j in 0..num_items {\n                if is_selected[j] {\n                    // Item j is selected: Check Remove and Swap moves involving j\n\n                    // --- Remove Move (j out) ---\n                    // Delta V = -MG[j]\n                    let delta_v_remove_j = -marginal_gains[j];\n                    if delta_v_remove_j > best_delta_v {\n                        best_delta_v = delta_v_remove_j;\n                        best_move = Some(LS_Move::Remove(j));\n                    }\n\n                    // --- Swap Moves (j out, i in) ---\n                    let w_j = weights[j];\n                    \n                    for i in 0..num_items {\n                        if !is_selected[i] {\n                            let w_i = weights[i];\n                            \n                            // Check weight constraint for swap\n                            let delta_w = w_i as i64 - w_j as i64;\n                            if (*current_weight as i64 + delta_w) <= max_weight as i64 {\n                                \n                                // Delta V(j out, i in) = MG[i] - interactions[i][j] - MG[j]\n                                let delta_v_swap = marginal_gains[i] - interactions[i][j] as i64 - marginal_gains[j];\n\n                                if delta_v_swap > best_delta_v {\n                                    best_delta_v = delta_v_swap;\n                                    best_move = Some(LS_Move::Swap(j, i));\n                                }\n                            }\n                        }\n                    }\n                } else {\n                    // Item i is unselected: Check Add moves\n                    let i = j;\n                    let w_i = weights[i];\n\n                    // --- Add Move (i in) ---\n                    // Delta V = MG[i]\n                    if current_weight.checked_add(w_i).map_or(false, |w| w <= max_weight) {\n                        let delta_v_add_i = marginal_gains[i];\n\n                        if delta_v_add_i > best_delta_v {\n                            best_delta_v = delta_v_add_i;\n                            best_move = Some(LS_Move::Add(i));\n                        }\n                    }\n                }\n            }\n\n            if best_delta_v > 0 {\n                *current_value += best_delta_v;\n\n                match best_move.unwrap() {\n                    LS_Move::Add(i) => {\n                        is_selected[i] = true;\n                        *current_weight += weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] += interactions[i][k] as i64;\n                        }\n                    }\n                    LS_Move::Remove(j) => {\n                        is_selected[j] = false;\n                        *current_weight -= weights[j];\n                        for k in 0..num_items {\n                            marginal_gains[k] -= interactions[j][k] as i64;\n                        }\n                    }\n                    LS_Move::Swap(j, i) => {\n                        is_selected[j] = false;\n                        is_selected[i] = true;\n                        *current_weight = *current_weight - weights[j] + weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] = marginal_gains[k] - interactions[j][k] as i64 + interactions[i][k] as i64;\n                        }\n                    }\n                }\n            } else {\n                break; // Local optimum reached\n            }\n        }\n    };\n\n\n\n    // --- 1. Initial Greedy Construction Phase (O(N^2)) ---\n    loop {\n        let mut best_item: Option<usize> = None;\n        let mut best_density: f64 = f64::NEG_INFINITY;\n\n        for i in 0..num_items {\n            if !is_selected[i] {\n                let item_weight = weights[i];\n                if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                    let gain = marginal_gains[i];\n                    \n                    let density = if item_weight == 0 {\n                        if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                    } else {\n                        gain as f64 / item_weight as f64\n                    };\n\n                    if density > best_density {\n                        best_density = density;\n                        best_item = Some(i);\n                    }\n                }\n            }\n        }\n\n        if let Some(idx_to_add) = best_item {\n            // Update value incrementally\n            current_value += marginal_gains[idx_to_add]; \n            \n            is_selected[idx_to_add] = true;\n            current_weight += weights[idx_to_add];\n\n            // Update marginal gains for ALL items (O(N) step). \n            for i in 0..num_items {\n                marginal_gains[i] += interactions[idx_to_add][i] as i64;\n            }\n        } else {\n            break;\n        }\n    }\n    \n    // Initialize best solution tracking (current_value is already correct)\n    best_value = current_value;\n    best_solution = is_selected.clone();\n\n    // --- 2. Iterated Local Search (ILS) with Adaptive Perturbation ---\n    let mut iterations_since_best_update = 0;\n    let mut dynamic_perturbation_size = hyperparameters.base_perturbation_size;\n\n    for restart in 0..hyperparameters.max_restarts {\n        \n        // A. Run BILS on the current state until local optimum is reached\n        run_bils(&mut is_selected, &mut current_weight, &mut marginal_gains, &mut current_value);\n\n        // B. Update Best Solution and adapt perturbation strength\n        if current_value > best_value {\n            best_value = current_value;\n            best_solution = is_selected.clone();\n            iterations_since_best_update = 0;\n            // On improvement, reset perturbation strength to base to focus search locally\n            dynamic_perturbation_size = hyperparameters.base_perturbation_size;\n        } else {\n            iterations_since_best_update += 1;\n        }\n\n        if iterations_since_best_update >= hyperparameters.stagnation_limit {\n            // Stagnation detected: increase perturbation strength to escape\n            dynamic_perturbation_size = (dynamic_perturbation_size as f64 * hyperparameters.perturbation_increase_factor).round() as usize;\n            // Cap the size to avoid destroying the solution completely\n            let max_p_size = (num_items as f64 * 0.4) as usize; // Don't remove more than 40% of items\n            dynamic_perturbation_size = dynamic_perturbation_size.min(max_p_size);\n            iterations_since_best_update = 0; // Reset counter after strengthening\n        }\n\n        if restart == hyperparameters.max_restarts - 1 {\n            break; // No need to perturb after the last optimization run\n        }\n\n        // C. Perturbation Phase (Biased removal + Incremental Repair)\n        let mut selected_indices: Vec<usize> = (0..num_items).filter(|&i| is_selected[i]).collect();\n        let num_selected = selected_indices.len();\n        \n        let p_size = dynamic_perturbation_size.min(num_selected);\n        \n        // 1. & 2. Biasedly remove P_size items and update state incrementally (O(P*N))\n        for _ in 0..p_size {\n            if selected_indices.is_empty() { break; }\n\n            // Calculate MG_max for normalization (O(N_selected))\n            let mg_max = selected_indices.iter()\n                .map(|&i| marginal_gains[i])\n                .max()\n                .unwrap_or(1); \n\n            // Calculate weights: S_j = MG_max - MG_j + 1 (Bias towards low MG items)\n            let mut total_weight = 0i64;\n            let weights_and_indices: Vec<(i64, usize)> = selected_indices.iter().map(|&j| {\n                // Ensure weight is positive and non-zero. \n                let weight = mg_max - marginal_gains[j] + 1; \n                total_weight += weight;\n                (weight, j)\n            }).collect();\n\n            // Select item j using roulette wheel selection (O(N_selected))\n            let target = rng.gen_range(0..total_weight);\n            let mut cumulative_weight = 0i64;\n            \n            let mut removal_index_in_vec = 0; // Index in selected_indices vector\n            \n            for (idx, &(weight, _)) in weights_and_indices.iter().enumerate() {\n                cumulative_weight += weight;\n                if cumulative_weight > target {\n                    removal_index_in_vec = idx;\n                    break;\n                }\n            }\n            \n            // Retrieve item index j and remove it from selected_indices (O(1) using swap_remove)\n            let j = selected_indices.swap_remove(removal_index_in_vec);\n\n            // Update value incrementally using the current marginal gain\n            current_value -= marginal_gains[j];\n            \n            is_selected[j] = false;\n            current_weight -= weights[j];\n\n            // Update marginal gains for all other items due to j's removal (O(N))\n            for k in 0..num_items {\n                marginal_gains[k] -= interactions[j][k] as i64;\n            }\n        }\n\n        // 3. Greedy Repair (Add items back based on marginal density)\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_density: f64 = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = weights[i];\n                    if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                        let gain = marginal_gains[i];\n                        \n                        let density = if item_weight == 0 {\n                            if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                        } else {\n                            gain as f64 / item_weight as f64\n                        };\n\n                        if density > best_density {\n                            best_density = density;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(idx_to_add) = best_item {\n                is_selected[idx_to_add] = true;\n                current_weight += weights[idx_to_add];\n                current_value += marginal_gains[idx_to_add]; // Update value incrementally\n\n                // Update marginal gains for ALL items (O(N) step). \n                for i in 0..num_items {\n                    marginal_gains[i] += interactions[idx_to_add][i] as i64;\n                }\n            } else {\n                break;\n            }\n        }\n    }\n\n    // Finalize solution indices from the best solution found\n    let selected: Vec<usize> = (0..num_items).filter(|&i| best_solution[i]).collect();\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}\n```\nKey features: Performs well on avg_btb (0.0008), Performs well on combined_score (0.6165), Performs well on eval_time (12.3266), Performs well on memory (370944.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.6165)\n```rust\n// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub max_restarts: usize,\n        pub base_perturbation_size: usize,\n        pub stagnation_limit: usize,\n        pub perturbation_increase_factor: f64,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .unwrap_or(Hyperparameters {\n                    max_restarts: 250, // Increased restarts for better exploration\n                    base_perturbation_size: 20,\n                    stagnation_limit: 30, // Slightly increased limit\n                    perturbation_increase_factor: 1.25,\n                })\n        }\n        None => Hyperparameters {\n            max_restarts: 250,\n            base_perturbation_size: 20,\n            stagnation_limit: 30,\n            perturbation_increase_factor: 1.25,\n        },\n    };\n\n    let num_items = challenge.values.len();\n    let weights = &challenge.weights;\n    let values = &challenge.values;\n    let interactions = &challenge.interaction_values;\n    let max_weight = challenge.max_weight;\n\n    let mut rng = SmallRng::from_seed(challenge.seed);\n\n    // --- State Variables (Current Solution) ---\n    let mut is_selected = vec![false; num_items];\n    let mut current_weight: u32 = 0;\n    // Marginal gains initialized with base values\n    let mut marginal_gains: Vec<i64> = values.iter().map(|&v| v as i64).collect();\n    let mut current_value: i64 = 0;\n\n    // --- Best Solution Tracking ---\n    let mut best_solution = vec![false; num_items];\n    let mut best_value = i64::MIN;\n\n    #[derive(Debug, Clone, Copy)]\n    enum LS_Move {\n        Add(usize),\n        Remove(usize),\n        Swap(usize, usize), // (item_to_remove, item_to_add)\n    }\n\n    // Helper function to run Best Improvement Local Search (BILS) until convergence\n    // Modifies state variables in place.\n    let mut run_bils = |\n        is_selected: &mut Vec<bool>,\n        current_weight: &mut u32,\n        marginal_gains: &mut Vec<i64>,\n        current_value: &mut i64\n    | {\n        loop {\n            let mut best_delta_v = 0i64;\n            let mut best_move: Option<LS_Move> = None;\n\n            // O(N^2) neighborhood search\n            for j in 0..num_items {\n                if is_selected[j] {\n                    // Item j is selected: Check Remove and Swap moves involving j\n\n                    // --- Remove Move (j out) ---\n                    // Delta V = -MG[j]\n                    let delta_v_remove_j = -marginal_gains[j];\n                    if delta_v_remove_j > best_delta_v {\n                        best_delta_v = delta_v_remove_j;\n                        best_move = Some(LS_Move::Remove(j));\n                    }\n\n                    // --- Swap Moves (j out, i in) ---\n                    let w_j = weights[j];\n                    \n                    for i in 0..num_items {\n                        if !is_selected[i] {\n                            let w_i = weights[i];\n                            \n                            // Check weight constraint for swap\n                            let delta_w = w_i as i64 - w_j as i64;\n                            if (*current_weight as i64 + delta_w) <= max_weight as i64 {\n                                \n                                // Delta V(j out, i in) = MG[i] - interactions[i][j] - MG[j]\n                                let delta_v_swap = marginal_gains[i] - interactions[i][j] as i64 - marginal_gains[j];\n\n                                if delta_v_swap > best_delta_v {\n                                    best_delta_v = delta_v_swap;\n                                    best_move = Some(LS_Move::Swap(j, i));\n                                }\n                            }\n                        }\n                    }\n                } else {\n                    // Item i is unselected: Check Add moves\n                    let i = j;\n                    let w_i = weights[i];\n\n                    // --- Add Move (i in) ---\n                    // Delta V = MG[i]\n                    if current_weight.checked_add(w_i).map_or(false, |w| w <= max_weight) {\n                        let delta_v_add_i = marginal_gains[i];\n\n                        if delta_v_add_i > best_delta_v {\n                            best_delta_v = delta_v_add_i;\n                            best_move = Some(LS_Move::Add(i));\n                        }\n                    }\n                }\n            }\n\n            if best_delta_v > 0 {\n                *current_value += best_delta_v;\n\n                match best_move.unwrap() {\n                    LS_Move::Add(i) => {\n                        is_selected[i] = true;\n                        *current_weight += weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] += interactions[i][k] as i64;\n                        }\n                    }\n                    LS_Move::Remove(j) => {\n                        is_selected[j] = false;\n                        *current_weight -= weights[j];\n                        for k in 0..num_items {\n                            marginal_gains[k] -= interactions[j][k] as i64;\n                        }\n                    }\n                    LS_Move::Swap(j, i) => {\n                        is_selected[j] = false;\n                        is_selected[i] = true;\n                        *current_weight = *current_weight - weights[j] + weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] = marginal_gains[k] - interactions[j][k] as i64 + interactions[i][k] as i64;\n                        }\n                    }\n                }\n            } else {\n                break; // Local optimum reached\n            }\n        }\n    };\n\n\n\n    // --- 1. Initial Greedy Construction Phase (O(N^2)) ---\n    loop {\n        let mut best_item: Option<usize> = None;\n        let mut best_density: f64 = f64::NEG_INFINITY;\n\n        for i in 0..num_items {\n            if !is_selected[i] {\n                let item_weight = weights[i];\n                if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                    let gain = marginal_gains[i];\n                    \n                    let density = if item_weight == 0 {\n                        if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                    } else {\n                        gain as f64 / item_weight as f64\n                    };\n\n                    if density > best_density {\n                        best_density = density;\n                        best_item = Some(i);\n                    }\n                }\n            }\n        }\n\n        if let Some(idx_to_add) = best_item {\n            // Update value incrementally\n            current_value += marginal_gains[idx_to_add]; \n            \n            is_selected[idx_to_add] = true;\n            current_weight += weights[idx_to_add];\n\n            // Update marginal gains for ALL items (O(N) step). \n            for i in 0..num_items {\n                marginal_gains[i] += interactions[idx_to_add][i] as i64;\n            }\n        } else {\n            break;\n        }\n    }\n    \n    // Initialize best solution tracking (current_value is already correct)\n    best_value = current_value;\n    best_solution = is_selected.clone();\n\n    // --- 2. Iterated Local Search (ILS) with Adaptive Perturbation ---\n    let mut iterations_since_best_update = 0;\n    let mut dynamic_perturbation_size = hyperparameters.base_perturbation_size;\n\n    for restart in 0..hyperparameters.max_restarts {\n        \n        // A. Run BILS on the current state until local optimum is reached\n        run_bils(&mut is_selected, &mut current_weight, &mut marginal_gains, &mut current_value);\n\n        // B. Update Best Solution and adapt perturbation strength\n        if current_value > best_value {\n            best_value = current_value;\n            best_solution = is_selected.clone();\n            iterations_since_best_update = 0;\n            // On improvement, reset perturbation strength to base to focus search locally\n            dynamic_perturbation_size = hyperparameters.base_perturbation_size;\n        } else {\n            iterations_since_best_update += 1;\n        }\n\n        if iterations_since_best_update >= hyperparameters.stagnation_limit {\n            // Stagnation detected: increase perturbation strength to escape\n            dynamic_perturbation_size = (dynamic_perturbation_size as f64 * hyperparameters.perturbation_increase_factor).round() as usize;\n            // Cap the size to avoid destroying the solution completely\n            let max_p_size = (num_items as f64 * 0.4) as usize; // Don't remove more than 40% of items\n            dynamic_perturbation_size = dynamic_perturbation_size.min(max_p_size);\n            iterations_since_best_update = 0; // Reset counter after strengthening\n        }\n\n        if restart == hyperparameters.max_restarts - 1 {\n            break; // No need to perturb after the last optimization run\n        }\n\n        // C. Perturbation Phase (Biased removal + Incremental Repair)\n        let mut selected_indices: Vec<usize> = (0..num_items).filter(|&i| is_selected[i]).collect();\n        let num_selected = selected_indices.len();\n        \n        let p_size = dynamic_perturbation_size.min(num_selected);\n        \n        // 1. & 2. Biasedly remove P_size items and update state incrementally (O(P*N))\n        for _ in 0..p_size {\n            if selected_indices.is_empty() { break; }\n\n            // Calculate MG_max for normalization (O(N_selected))\n            let mg_max = selected_indices.iter()\n                .map(|&i| marginal_gains[i])\n                .max()\n                .unwrap_or(1); \n\n            // Calculate weights: S_j = MG_max - MG_j + 1 (Bias towards low MG items)\n            let mut total_weight = 0i64;\n            let weights_and_indices: Vec<(i64, usize)> = selected_indices.iter().map(|&j| {\n                // Ensure weight is positive and non-zero. \n                let weight = mg_max - marginal_gains[j] + 1; \n                total_weight += weight;\n                (weight, j)\n            }).collect();\n\n            // Select item j using roulette wheel selection (O(N_selected))\n            let target = rng.gen_range(0..total_weight);\n            let mut cumulative_weight = 0i64;\n            \n            let mut removal_index_in_vec = 0; // Index in selected_indices vector\n            \n            for (idx, &(weight, _)) in weights_and_indices.iter().enumerate() {\n                cumulative_weight += weight;\n                if cumulative_weight > target {\n                    removal_index_in_vec = idx;\n                    break;\n                }\n            }\n            \n            // Retrieve item index j and remove it from selected_indices (O(1) using swap_remove)\n            let j = selected_indices.swap_remove(removal_index_in_vec);\n\n            // Update value incrementally using the current marginal gain\n            current_value -= marginal_gains[j];\n            \n            is_selected[j] = false;\n            current_weight -= weights[j];\n\n            // Update marginal gains for all other items due to j's removal (O(N))\n            for k in 0..num_items {\n                marginal_gains[k] -= interactions[j][k] as i64;\n            }\n        }\n\n        // 3. Greedy Repair (Add items back based on marginal density)\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_density: f64 = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = weights[i];\n                    if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                        let gain = marginal_gains[i];\n                        \n                        let density = if item_weight == 0 {\n                            if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                        } else {\n                            gain as f64 / item_weight as f64\n                        };\n\n                        if density > best_density {\n                            best_density = density;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(idx_to_add) = best_item {\n                is_selected[idx_to_add] = true;\n                current_weight += weights[idx_to_add];\n                current_value += marginal_gains[idx_to_add]; // Update value incrementally\n\n                // Update marginal gains for ALL items (O(N) step). \n                for i in 0..num_items {\n                    marginal_gains[i] += interactions[idx_to_add][i] as i64;\n                }\n            } else {\n                break;\n            }\n        }\n    }\n\n    // Finalize solution indices from the best solution found\n    let selected: Vec<usize> = (0..num_items).filter(|&i| best_solution[i]).collect();\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}\n```\nKey features: Alternative approach to avg_btb, Alternative approach to combined_score\n\n### Program D2 (Score: 0.6165)\n```rust\n// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub max_restarts: usize,\n        pub base_perturbation_size: usize,\n        pub stagnation_limit: usize,\n        pub perturbation_increase_factor: f64,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .unwrap_or(Hyperparameters {\n                    max_restarts: 250, \n                    base_perturbation_size: 20,\n                    stagnation_limit: 30, \n                    perturbation_increase_factor: 1.25,\n                })\n        }\n        None => Hyperparameters {\n            max_restarts: 250,\n            base_perturbation_size: 20,\n            stagnation_limit: 30,\n            perturbation_increase_factor: 1.25,\n        },\n    };\n\n    let num_items = challenge.values.len();\n    let weights = &challenge.weights;\n    let values = &challenge.values;\n    let interactions = &challenge.interaction_values;\n    let max_weight = challenge.max_weight;\n\n    let mut rng = SmallRng::from_seed(challenge.seed);\n\n    // --- State Variables (Current Solution) ---\n    let mut is_selected = vec![false; num_items];\n    let mut current_weight: u32 = 0;\n    // marginal_gains[i] = values[i] + sum(interactions[i][j]) for all j currently selected.\n    let mut marginal_gains: Vec<i64> = values.iter().map(|&v| v as i64).collect();\n    let mut current_value: i64 = 0;\n\n    // --- Best Solution Tracking ---\n    let mut best_solution = vec![false; num_items];\n    let mut best_value = i64::MIN;\n\n    #[derive(Debug, Clone, Copy)]\n    enum LS_Move {\n        Add(usize),\n        Remove(usize),\n        Swap(usize, usize), // (item_to_remove, item_to_add)\n    }\n    \n\n\n    // Helper function to run Best Improvement Local Search (BILS) until convergence\n    // Modifies state variables in place.\n    let mut run_bils = |\n        is_selected: &mut Vec<bool>,\n        current_weight: &mut u32,\n        marginal_gains: &mut Vec<i64>,\n        current_value: &mut i64\n    | {\n        loop {\n            let mut best_delta_v = 0i64;\n            let mut best_move: Option<LS_Move> = None;\n\n            // O(N^2) neighborhood search\n            for j in 0..num_items {\n                if is_selected[j] {\n                    // Item j is selected: Check Remove and Swap moves involving j\n\n                    // --- Remove Move (j out) ---\n                    let delta_v_remove_j = -marginal_gains[j];\n                    if delta_v_remove_j > best_delta_v {\n                        best_delta_v = delta_v_remove_j;\n                        best_move = Some(LS_Move::Remove(j));\n                    }\n\n                    // --- Swap Moves (j out, i in) ---\n                    let w_j = weights[j];\n                    \n                    for i in 0..num_items {\n                        if !is_selected[i] {\n                            let w_i = weights[i];\n                            \n                            // Check weight constraint for swap\n                            let delta_w = w_i as i64 - w_j as i64;\n                            if (*current_weight as i64 + delta_w) <= max_weight as i64 {\n                                \n                                // Delta V(j out, i in) = MG[i] - interactions[i][j] - MG[j]\n                                let delta_v_swap = marginal_gains[i] - interactions[i][j] as i64 - marginal_gains[j];\n\n                                if delta_v_swap > best_delta_v {\n                                    best_delta_v = delta_v_swap;\n                                    best_move = Some(LS_Move::Swap(j, i));\n                                }\n                            }\n                        }\n                    }\n                } else {\n                    // Item i is unselected: Check Add moves\n                    let i = j;\n                    let w_i = weights[i];\n\n                    // --- Add Move (i in) ---\n                    if current_weight.checked_add(w_i).map_or(false, |w| w <= max_weight) {\n                        let delta_v_add_i = marginal_gains[i];\n\n                        if delta_v_add_i > best_delta_v {\n                            best_delta_v = delta_v_add_i;\n                            best_move = Some(LS_Move::Add(i));\n                        }\n                    }\n                }\n            }\n\n            if best_delta_v > 0 {\n                *current_value += best_delta_v;\n\n                match best_move.unwrap() {\n                    LS_Move::Add(i) => {\n                        is_selected[i] = true;\n                        *current_weight += weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] += interactions[i][k] as i64;\n                        }\n                    }\n                    LS_Move::Remove(j) => {\n                        is_selected[j] = false;\n                        *current_weight -= weights[j];\n                        for k in 0..num_items {\n                            marginal_gains[k] -= interactions[j][k] as i64;\n                        }\n                    }\n                    LS_Move::Swap(j, i) => {\n                        is_selected[j] = false;\n                        is_selected[i] = true;\n                        *current_weight = *current_weight - weights[j] + weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] = marginal_gains[k] - interactions[j][k] as i64 + interactions[i][k] as i64;\n                        }\n                    }\n                }\n            } else {\n                break; // Local optimum reached\n            }\n        }\n    };\n\n    // --- 1. Initial Greedy Construction Phase (O(N^2)) ---\n    loop {\n        let mut best_item: Option<usize> = None;\n        let mut best_density: f64 = f64::NEG_INFINITY;\n\n        for i in 0..num_items {\n            if !is_selected[i] {\n                let item_weight = weights[i];\n                if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                    let gain = marginal_gains[i];\n                    \n                    let density = if item_weight == 0 {\n                        if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                    } else {\n                        gain as f64 / item_weight as f64\n                    };\n\n                    if density > best_density {\n                        best_density = density;\n                        best_item = Some(i);\n                    }\n                }\n            }\n        }\n\n        if let Some(idx_to_add) = best_item {\n            // Update value incrementally\n            current_value += marginal_gains[idx_to_add]; \n            \n            is_selected[idx_to_add] = true;\n            current_weight += weights[idx_to_add];\n\n            // Update marginal gains for ALL items (O(N) step). \n            for i in 0..num_items {\n                marginal_gains[i] += interactions[idx_to_add][i] as i64;\n            }\n        } else {\n            break;\n        }\n    }\n    \n    // Initialize best solution tracking (current_value is already correct)\n    best_value = current_value;\n    best_solution = is_selected.clone();\n\n    // --- 2. Iterated Local Search (ILS) with Adaptive Perturbation ---\n    let mut iterations_since_best_update = 0;\n    let mut dynamic_perturbation_size = hyperparameters.base_perturbation_size;\n\n    for restart in 0..hyperparameters.max_restarts {\n        \n        // A. Run BILS on the current state until local optimum is reached\n        run_bils(&mut is_selected, &mut current_weight, &mut marginal_gains, &mut current_value);\n\n        // B. Update Best Solution and adapt perturbation strength\n        if current_value > best_value {\n            best_value = current_value;\n            best_solution = is_selected.clone();\n            iterations_since_best_update = 0;\n            // On improvement, reset perturbation strength to base to focus search locally\n            dynamic_perturbation_size = hyperparameters.base_perturbation_size;\n        } else {\n            iterations_since_best_update += 1;\n        }\n\n        if iterations_since_best_update >= hyperparameters.stagnation_limit {\n            // Stagnation detected: increase perturbation strength to escape\n            dynamic_perturbation_size = (dynamic_perturbation_size as f64 * hyperparameters.perturbation_increase_factor).round() as usize;\n            // Cap the size to avoid destroying the solution completely\n            let max_p_size = (num_items as f64 * 0.4) as usize; // Don't remove more than 40% of items\n            dynamic_perturbation_size = dynamic_perturbation_size.min(max_p_size);\n            iterations_since_best_update = 0; // Reset counter after strengthening\n        }\n\n        if restart == hyperparameters.max_restarts - 1 {\n            break; // No need to perturb after the last optimization run\n        }\n\n        // C. Perturbation Phase (Biased removal + Incremental Repair)\n        let mut selected_indices: Vec<usize> = (0..num_items).filter(|&i| is_selected[i]).collect();\n        let num_selected = selected_indices.len();\n        \n        let p_size = dynamic_perturbation_size.min(num_selected);\n        \n        // 1. & 2. Biasedly remove P_size items and update state incrementally (O(P*N))\n        for _ in 0..p_size {\n            if selected_indices.is_empty() { break; }\n\n            // Calculate MG_max for normalization (O(N_selected))\n            let mg_max = selected_indices.iter()\n                .map(|&i| marginal_gains[i])\n                .max()\n                .unwrap_or(1); \n\n            // Calculate weights: S_j = MG_max - MG_j + 1 (Bias towards low MG items)\n            let mut total_weight = 0i64;\n            let weights_and_indices: Vec<(i64, usize)> = selected_indices.iter().map(|&j| {\n                // Ensure weight is positive and non-zero. \n                let weight = mg_max - marginal_gains[j] + 1; \n                total_weight += weight;\n                (weight, j)\n            }).collect();\n\n            // Select item j using roulette wheel selection (O(N_selected))\n            let target = rng.gen_range(0..total_weight);\n            let mut cumulative_weight = 0i64;\n            \n            let mut removal_index_in_vec = 0; // Index in selected_indices vector\n            \n            for (idx, &(weight, _)) in weights_and_indices.iter().enumerate() {\n                cumulative_weight += weight;\n                if cumulative_weight > target {\n                    removal_index_in_vec = idx;\n                    break;\n                }\n            }\n            \n            // Retrieve item index j and remove it from selected_indices (O(1) using swap_remove)\n            let j = selected_indices.swap_remove(removal_index_in_vec);\n\n            // Update value incrementally using the current marginal gain\n            current_value -= marginal_gains[j];\n            \n            is_selected[j] = false;\n            current_weight -= weights[j];\n\n            // Update marginal gains for all other items due to j's removal (O(N))\n            for k in 0..num_items {\n                marginal_gains[k] -= interactions[j][k] as i64;\n            }\n        }\n\n        // 3. Greedy Repair (Add items back based on marginal density)\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_density: f64 = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = weights[i];\n                    if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                        let gain = marginal_gains[i];\n                        \n                        let density = if item_weight == 0 {\n                            if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                        } else {\n                            gain as f64 / item_weight as f64\n                        };\n\n                        if density > best_density {\n                            best_density = density;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(idx_to_add) = best_item {\n                is_selected[idx_to_add] = true;\n                current_weight += weights[idx_to_add];\n                current_value += marginal_gains[idx_to_add]; // Update value incrementally\n\n                // Update marginal gains for ALL items (O(N) step). \n                for i in 0..num_items {\n                    marginal_gains[i] += interactions[idx_to_add][i] as i64;\n                }\n            } else {\n                break;\n            }\n        }\n    }\n\n    // Finalize solution indices from the best solution found\n    let selected: Vec<usize> = (0..num_items).filter(|&i| best_solution[i]).collect();\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}\n```\nKey features: Alternative approach to avg_btb, Alternative approach to combined_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.5129, Type: Experimental)\n```rust\n// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub max_restarts: usize,\n        pub perturbation_size: usize,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .unwrap_or(Hyperparameters {\n                    max_restarts: 50,\n                    perturbation_size: 15, \n                })\n        }\n        None => Hyperparameters {\n            max_restarts: 50,\n            perturbation_size: 15,\n        },\n    };\n\n    let num_items = challenge.values.len();\n    let weights = &challenge.weights;\n    let values = &challenge.values;\n    let interactions = &challenge.interaction_values;\n    let max_weight = challenge.max_weight;\n\n    let mut rng = SmallRng::from_seed(challenge.seed);\n\n    // --- State Variables (Current Solution) ---\n    let mut is_selected = vec![false; num_items];\n    let mut current_weight: u32 = 0;\n    // Marginal gains initialized with base values\n    let mut marginal_gains: Vec<i64> = values.iter().map(|&v| v as i64).collect();\n    let mut current_value: i64 = 0;\n\n    // --- Best Solution Tracking ---\n    let mut best_solution = vec![false; num_items];\n    let mut best_value = i64::MIN;\n\n    #[derive(Debug, Clone, Copy)]\n    enum LS_Move {\n        Add(usize),\n        Remove(usize),\n        Swap(usize, usize), // (item_to_remove, item_to_add)\n    }\n\n    // Helper function to run Best Improvement Local Search (BILS) until convergence\n    // Modifies state variables in place.\n    let mut run_bils = |\n        is_selected: &mut Vec<bool>,\n        current_weight: &mut u32,\n        marginal_gains: &mut Vec<i64>,\n        current_value: &mut i64\n    | {\n        loop {\n            let mut best_delta_v = 0i64;\n            let mut best_move: Option<LS_Move> = None;\n\n            // O(N^2) neighborhood search\n            for j in 0..num_items {\n                if is_selected[j] {\n                    // Item j is selected: Check Remove and Swap moves involving j\n\n                    // --- Remove Move (j out) ---\n                    // Delta V = -MG[j]\n                    let delta_v_remove_j = -marginal_gains[j];\n                    if delta_v_remove_j > best_delta_v {\n                        best_delta_v = delta_v_remove_j;\n                        best_move = Some(LS_Move::Remove(j));\n                    }\n\n                    // --- Swap Moves (j out, i in) ---\n                    let w_j = weights[j];\n                    \n                    for i in 0..num_items {\n                        if !is_selected[i] {\n                            let w_i = weights[i];\n                            \n                            // Check weight constraint for swap\n                            let delta_w = w_i as i64 - w_j as i64;\n                            if (*current_weight as i64 + delta_w) <= max_weight as i64 {\n                                \n                                // Delta V(j out, i in) = MG[i] - interactions[i][j] - MG[j]\n                                let delta_v_swap = marginal_gains[i] - interactions[i][j] as i64 - marginal_gains[j];\n\n                                if delta_v_swap > best_delta_v {\n                                    best_delta_v = delta_v_swap;\n                                    best_move = Some(LS_Move::Swap(j, i));\n                                }\n                            }\n                        }\n                    }\n                } else {\n                    // Item i is unselected: Check Add moves\n                    let i = j;\n                    let w_i = weights[i];\n\n                    // --- Add Move (i in) ---\n                    // Delta V = MG[i]\n                    if current_weight.checked_add(w_i).map_or(false, |w| w <= max_weight) {\n                        let delta_v_add_i = marginal_gains[i];\n\n                        if delta_v_add_i > best_delta_v {\n                            best_delta_v = delta_v_add_i;\n                            best_move = Some(LS_Move::Add(i));\n                        }\n                    }\n                }\n            }\n\n            if best_delta_v > 0 {\n                *current_value += best_delta_v;\n\n                match best_move.unwrap() {\n                    LS_Move::Add(i) => {\n                        is_selected[i] = true;\n                        *current_weight += weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] += interactions[i][k] as i64;\n                        }\n                    }\n                    LS_Move::Remove(j) => {\n                        is_selected[j] = false;\n                        *current_weight -= weights[j];\n                        for k in 0..num_items {\n                            marginal_gains[k] -= interactions[j][k] as i64;\n                        }\n                    }\n                    LS_Move::Swap(j, i) => {\n                        is_selected[j] = false;\n                        is_selected[i] = true;\n                        *current_weight = *current_weight - weights[j] + weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] = marginal_gains[k] - interactions[j][k] as i64 + interactions[i][k] as i64;\n                        }\n                    }\n                }\n            } else {\n                break; // Local optimum reached\n            }\n        }\n    };\n\n    // --- 1. Initial Greedy Construction Phase (O(N^2)) ---\n    loop {\n        let mut best_item: Option<usize> = None;\n        let mut best_density: f64 = f64::NEG_INFINITY;\n\n        for i in 0..num_items {\n            if !is_selected[i] {\n                let item_weight = weights[i];\n                if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                    let gain = marginal_gains[i];\n                    \n                    let density = if item_weight == 0 {\n                        if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                    } else {\n                        gain as f64 / item_weight as f64\n                    };\n\n                    if density > best_density {\n                        best_density = density;\n                        best_item = Some(i);\n                    }\n                }\n            }\n        }\n\n        if let Some(idx_to_add) = best_item {\n            // Update value incrementally\n            current_value += marginal_gains[idx_to_add]; \n            \n            is_selected[idx_to_add] = true;\n            current_weight += weights[idx_to_add];\n\n            // Update marginal gains for ALL items (O(N) step). \n            for i in 0..num_items {\n                marginal_gains[i] += interactions[idx_to_add][i] as i64;\n            }\n        } else {\n            break;\n        }\n    }\n    \n    // Initialize best solution tracking (current_value is already correct)\n    best_value = current_value;\n    best_solution = is_selected.clone();\n\n    // --- 2. Iterated Local Search (ILS) ---\n    for restart in 0..hyperparameters.max_restarts {\n        \n        // A. Run BILS on the current state until local optimum is reached\n        run_bils(&mut is_selected, &mut current_weight, &mut marginal_gains, &mut current_value);\n\n        // B. Update Best Solution\n        if current_value > best_value {\n            best_value = current_value;\n            best_solution = is_selected.clone();\n        }\n\n        if restart == hyperparameters.max_restarts - 1 {\n            break; // No need to perturb after the last optimization run\n        }\n\n        // C. Perturbation Phase (Randomly remove items + Greedy Repair)\n        let mut selected_indices: Vec<usize> = (0..num_items).filter(|&i| is_selected[i]).collect();\n        let num_selected = selected_indices.len();\n        \n        let p_size = hyperparameters.perturbation_size.min(num_selected);\n        \n        // 1. & 2. Randomly remove P_size items and update state incrementally (O(P*N))\n        for _ in 0..p_size {\n            if selected_indices.is_empty() { break; }\n            let idx_in_vec = rng.gen_range(0..selected_indices.len());\n            let j = selected_indices.swap_remove(idx_in_vec);\n\n            // Update value incrementally using the current marginal gain\n            current_value -= marginal_gains[j];\n            \n            is_selected[j] = false;\n            current_weight -= weights[j];\n\n            // Update marginal gains for all other items due to j's removal (O(N))\n            for k in 0..num_items {\n                marginal_gains[k] -= interactions[j][k] as i64;\n            }\n        }\n\n        // 3. Greedy Repair (Add items back based on marginal density)\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_density: f64 = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = weights[i];\n                    if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                        let gain = marginal_gains[i];\n                        \n                        let density = if item_weight == 0 {\n                            if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                        } else {\n                            gain as f64 / item_weight as f64\n                        };\n\n                        if density > best_density {\n                            best_density = density;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(idx_to_add) = best_item {\n                is_selected[idx_to_add] = true;\n                current_weight += weights[idx_to_add];\n                current_value += marginal_gains[idx_to_add]; // Update value incrementally\n\n                // Update marginal gains for ALL items (O(N) step). \n                for i in 0..num_items {\n                    marginal_gains[i] += interactions[idx_to_add][i] as i64;\n                }\n            } else {\n                break;\n            }\n        }\n    }\n\n    // Finalize solution indices from the best solution found\n    let selected: Vec<usize> = (0..num_items).filter(|&i| best_solution[i]).collect();\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}\n```\nUnique approach: Alternative avg_btb approach, Excellent eval_time (1.907), Excellent memory (371200.000)\n\n### Inspiration 2 (Score: 0.6165, Type: Alternative)\n```rust\n// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub max_restarts: usize,\n        pub base_perturbation_size: usize,\n        pub stagnation_limit: usize,\n        pub perturbation_increase_factor: f64,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .unwrap_or(Hyperparameters {\n                    max_restarts: 250, // Increased restarts for better exploration\n                    base_perturbation_size: 20,\n                    stagnation_limit: 30, // Adaptive stagnation limit\n                    perturbation_increase_factor: 1.25,\n                })\n        }\n        None => Hyperparameters {\n            max_restarts: 250,\n            base_perturbation_size: 20,\n            stagnation_limit: 30,\n            perturbation_increase_factor: 1.25,\n        },\n    };\n\n    let num_items = challenge.values.len();\n    let weights = &challenge.weights;\n    let values = &challenge.values;\n    let interactions = &challenge.interaction_values;\n    let max_weight = challenge.max_weight;\n\n    let mut rng = SmallRng::from_seed(challenge.seed);\n\n    // --- State Variables (Current Solution) ---\n    let mut is_selected = vec![false; num_items];\n    let mut current_weight: u32 = 0;\n    // Marginal gains initialized with base values\n    let mut marginal_gains: Vec<i64> = values.iter().map(|&v| v as i64).collect();\n    let mut current_value: i64 = 0;\n\n    // --- Best Solution Tracking ---\n    let mut best_solution = vec![false; num_items];\n    let mut best_value = i64::MIN;\n\n    #[derive(Debug, Clone, Copy)]\n    enum LS_Move {\n        Add(usize),\n        Remove(usize),\n        Swap(usize, usize), // (item_to_remove, item_to_add)\n    }\n\n    // Helper function to run Best Improvement Local Search (BILS) until convergence\n    // Modifies state variables in place.\n    let mut run_bils = |\n        is_selected: &mut Vec<bool>,\n        current_weight: &mut u32,\n        marginal_gains: &mut Vec<i64>,\n        current_value: &mut i64\n    | {\n        loop {\n            let mut best_delta_v = 0i64;\n            let mut best_move: Option<LS_Move> = None;\n\n            // O(N^2) neighborhood search\n            for j in 0..num_items {\n                if is_selected[j] {\n                    // Item j is selected: Check Remove and Swap moves involving j\n\n                    // --- Remove Move (j out) ---\n                    // Delta V = -MG[j]\n                    let delta_v_remove_j = -marginal_gains[j];\n                    if delta_v_remove_j > best_delta_v {\n                        best_delta_v = delta_v_remove_j;\n                        best_move = Some(LS_Move::Remove(j));\n                    }\n\n                    // --- Swap Moves (j out, i in) ---\n                    let w_j = weights[j];\n                    \n                    for i in 0..num_items {\n                        if !is_selected[i] {\n                            let w_i = weights[i];\n                            \n                            // Check weight constraint for swap\n                            let delta_w = w_i as i64 - w_j as i64;\n                            if (*current_weight as i64 + delta_w) <= max_weight as i64 {\n                                \n                                // Delta V(j out, i in) = MG[i] - interactions[i][j] - MG[j]\n                                let delta_v_swap = marginal_gains[i] - interactions[i][j] as i64 - marginal_gains[j];\n\n                                if delta_v_swap > best_delta_v {\n                                    best_delta_v = delta_v_swap;\n                                    best_move = Some(LS_Move::Swap(j, i));\n                                }\n                            }\n                        }\n                    }\n                } else {\n                    // Item i is unselected: Check Add moves\n                    let i = j;\n                    let w_i = weights[i];\n\n                    // --- Add Move (i in) ---\n                    // Delta V = MG[i]\n                    if current_weight.checked_add(w_i).map_or(false, |w| w <= max_weight) {\n                        let delta_v_add_i = marginal_gains[i];\n\n                        if delta_v_add_i > best_delta_v {\n                            best_delta_v = delta_v_add_i;\n                            best_move = Some(LS_Move::Add(i));\n                        }\n                    }\n                }\n            }\n\n            if best_delta_v > 0 {\n                *current_value += best_delta_v;\n\n                match best_move.unwrap() {\n                    LS_Move::Add(i) => {\n                        is_selected[i] = true;\n                        *current_weight += weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] += interactions[i][k] as i64;\n                        }\n                    }\n                    LS_Move::Remove(j) => {\n                        is_selected[j] = false;\n                        *current_weight -= weights[j];\n                        for k in 0..num_items {\n                            marginal_gains[k] -= interactions[j][k] as i64;\n                        }\n                    }\n                    LS_Move::Swap(j, i) => {\n                        is_selected[j] = false;\n                        is_selected[i] = true;\n                        *current_weight = *current_weight - weights[j] + weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] = marginal_gains[k] - interactions[j][k] as i64 + interactions[i][k] as i64;\n                        }\n                    }\n                }\n            } else {\n                break; // Local optimum reached\n            }\n        }\n    };\n\n    // --- 1. Initial Greedy Construction Phase (O(N^2)) ---\n    loop {\n        let mut best_item: Option<usize> = None;\n        let mut best_density: f64 = f64::NEG_INFINITY;\n\n        for i in 0..num_items {\n            if !is_selected[i] {\n                let item_weight = weights[i];\n                if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                    let gain = marginal_gains[i];\n                    \n                    let density = if item_weight == 0 {\n                        if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                    } else {\n                        gain as f64 / item_weight as f64\n                    };\n\n                    if density > best_density {\n                        best_density = density;\n                        best_item = Some(i);\n                    }\n                }\n            }\n        }\n\n        if let Some(idx_to_add) = best_item {\n            // Update value incrementally\n            current_value += marginal_gains[idx_to_add]; \n            \n            is_selected[idx_to_add] = true;\n            current_weight += weights[idx_to_add];\n\n            // Update marginal gains for ALL items (O(N) step). \n            for i in 0..num_items {\n                marginal_gains[i] += interactions[idx_to_add][i] as i64;\n            }\n        } else {\n            break;\n        }\n    }\n    \n    // Initialize best solution tracking (current_value is already correct)\n    best_value = current_value;\n    best_solution = is_selected.clone();\n\n    // --- 2. Iterated Local Search (ILS) with Adaptive Perturbation ---\n    let mut iterations_since_best_update = 0;\n    let mut dynamic_perturbation_size = hyperparameters.base_perturbation_size;\n\n    for restart in 0..hyperparameters.max_restarts {\n        \n        // A. Run BILS on the current state until local optimum is reached\n        run_bils(&mut is_selected, &mut current_weight, &mut marginal_gains, &mut current_value);\n\n        // B. Update Best Solution and adapt perturbation strength\n        if current_value > best_value {\n            best_value = current_value;\n            best_solution = is_selected.clone();\n            iterations_since_best_update = 0;\n            // On improvement, reset perturbation strength to base to focus search locally\n            dynamic_perturbation_size = hyperparameters.base_perturbation_size;\n        } else {\n            iterations_since_best_update += 1;\n        }\n\n        if iterations_since_best_update >= hyperparameters.stagnation_limit {\n            // Stagnation detected: increase perturbation strength to escape\n            dynamic_perturbation_size = (dynamic_perturbation_size as f64 * hyperparameters.perturbation_increase_factor).round() as usize;\n            // Cap the size to avoid destroying the solution completely\n            let max_p_size = (num_items as f64 * 0.4) as usize; // Don't remove more than 40% of items\n            dynamic_perturbation_size = dynamic_perturbation_size.min(max_p_size);\n            iterations_since_best_update = 0; // Reset counter after strengthening\n        }\n\n        if restart == hyperparameters.max_restarts - 1 {\n            break; // No need to perturb after the last optimization run\n        }\n\n        // C. Perturbation Phase (Biased removal + Incremental Repair)\n        let mut selected_indices: Vec<usize> = (0..num_items).filter(|&i| is_selected[i]).collect();\n        let num_selected = selected_indices.len();\n        \n        let p_size = dynamic_perturbation_size.min(num_selected);\n        \n        // 1. & 2. Biasedly remove P_size items and update state incrementally (O(P*N))\n        for _ in 0..p_size {\n            if selected_indices.is_empty() { break; }\n\n            // Calculate MG_max for normalization (O(N_selected))\n            let mg_max = selected_indices.iter()\n                .map(|&i| marginal_gains[i])\n                .max()\n                .unwrap_or(1); \n\n            // Calculate weights: S_j = MG_max - MG_j + 1 (Bias towards low MG items)\n            let mut total_weight = 0i64;\n            let weights_and_indices: Vec<(i64, usize)> = selected_indices.iter().map(|&j| {\n                // Ensure weight is positive and non-zero. \n                let weight = mg_max - marginal_gains[j] + 1; \n                total_weight += weight;\n                (weight, j)\n            }).collect();\n\n            // Select item j using roulette wheel selection (O(N_selected))\n            let target = rng.gen_range(0..total_weight);\n            let mut cumulative_weight = 0i64;\n            \n            let mut removal_index_in_vec = 0; // Index in selected_indices vector\n            \n            for (idx, &(weight, _)) in weights_and_indices.iter().enumerate() {\n                cumulative_weight += weight;\n                if cumulative_weight > target {\n                    removal_index_in_vec = idx;\n                    break;\n                }\n            }\n            \n            // Retrieve item index j and remove it from selected_indices (O(1) using swap_remove)\n            let j = selected_indices.swap_remove(removal_index_in_vec);\n\n            // Update value incrementally using the current marginal gain\n            current_value -= marginal_gains[j];\n            \n            is_selected[j] = false;\n            current_weight -= weights[j];\n\n            // Update marginal gains for all other items due to j's removal (O(N))\n            for k in 0..num_items {\n                marginal_gains[k] -= interactions[j][k] as i64;\n            }\n        }\n\n        // 3. Greedy Repair (Add items back based on marginal density)\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_density: f64 = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = weights[i];\n                    if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                        let gain = marginal_gains[i];\n                        \n                        let density = if item_weight == 0 {\n                            if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                        } else {\n                            gain as f64 / item_weight as f64\n                        };\n\n                        if density > best_density {\n                            best_density = density;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(idx_to_add) = best_item {\n                is_selected[idx_to_add] = true;\n                current_weight += weights[idx_to_add];\n                current_value += marginal_gains[idx_to_add]; // Update value incrementally\n\n                // Update marginal gains for ALL items (O(N) step). \n                for i in 0..num_items {\n                    marginal_gains[i] += interactions[idx_to_add][i] as i64;\n                }\n            } else {\n                break;\n            }\n        }\n    }\n\n    // Finalize solution indices from the best solution found\n    let selected: Vec<usize> = (0..num_items).filter(|&i| best_solution[i]).collect();\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}\n```\nUnique approach: Modification: Change 1: Replace 19 lines with 25 lines\nChange 2: Replace 79 lines with 126 lines, Alternative avg_btb approach, Excellent eval_time (12.334)\n\n### Inspiration 3 (Score: 0.5401, Type: Experimental)\n```rust\n// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub max_restarts: usize,\n        pub perturbation_size: usize,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .unwrap_or(Hyperparameters {\n                    max_restarts: 100, // Increased restarts for deeper search\n                    perturbation_size: 20, // Slightly larger perturbation\n                })\n        }\n        None => Hyperparameters {\n            max_restarts: 100,\n            perturbation_size: 20,\n        },\n    };\n\n    let num_items = challenge.values.len();\n    let weights = &challenge.weights;\n    let values = &challenge.values;\n    let interactions = &challenge.interaction_values;\n    let max_weight = challenge.max_weight;\n\n    let mut rng = SmallRng::from_seed(challenge.seed);\n\n    // --- State Variables (Current Solution) ---\n    let mut is_selected = vec![false; num_items];\n    let mut current_weight: u32 = 0;\n    // Marginal gains initialized with base values\n    let mut marginal_gains: Vec<i64> = values.iter().map(|&v| v as i64).collect();\n    let mut current_value: i64 = 0;\n\n    // --- Best Solution Tracking ---\n    let mut best_solution = vec![false; num_items];\n    let mut best_value = i64::MIN;\n\n    #[derive(Debug, Clone, Copy)]\n    enum LS_Move {\n        Add(usize),\n        Remove(usize),\n        Swap(usize, usize), // (item_to_remove, item_to_add)\n    }\n\n    // Helper function to run Best Improvement Local Search (BILS) until convergence\n    // Modifies state variables in place.\n    let mut run_bils = |\n        is_selected: &mut Vec<bool>,\n        current_weight: &mut u32,\n        marginal_gains: &mut Vec<i64>,\n        current_value: &mut i64\n    | {\n        loop {\n            let mut best_delta_v = 0i64;\n            let mut best_move: Option<LS_Move> = None;\n\n            // O(N^2) neighborhood search\n            for j in 0..num_items {\n                if is_selected[j] {\n                    // Item j is selected: Check Remove and Swap moves involving j\n\n                    // --- Remove Move (j out) ---\n                    // Delta V = -MG[j]\n                    let delta_v_remove_j = -marginal_gains[j];\n                    if delta_v_remove_j > best_delta_v {\n                        best_delta_v = delta_v_remove_j;\n                        best_move = Some(LS_Move::Remove(j));\n                    }\n\n                    // --- Swap Moves (j out, i in) ---\n                    let w_j = weights[j];\n                    \n                    for i in 0..num_items {\n                        if !is_selected[i] {\n                            let w_i = weights[i];\n                            \n                            // Check weight constraint for swap\n                            let delta_w = w_i as i64 - w_j as i64;\n                            if (*current_weight as i64 + delta_w) <= max_weight as i64 {\n                                \n                                // Delta V(j out, i in) = MG[i] - interactions[i][j] - MG[j]\n                                let delta_v_swap = marginal_gains[i] - interactions[i][j] as i64 - marginal_gains[j];\n\n                                if delta_v_swap > best_delta_v {\n                                    best_delta_v = delta_v_swap;\n                                    best_move = Some(LS_Move::Swap(j, i));\n                                }\n                            }\n                        }\n                    }\n                } else {\n                    // Item i is unselected: Check Add moves\n                    let i = j;\n                    let w_i = weights[i];\n\n                    // --- Add Move (i in) ---\n                    // Delta V = MG[i]\n                    if current_weight.checked_add(w_i).map_or(false, |w| w <= max_weight) {\n                        let delta_v_add_i = marginal_gains[i];\n\n                        if delta_v_add_i > best_delta_v {\n                            best_delta_v = delta_v_add_i;\n                            best_move = Some(LS_Move::Add(i));\n                        }\n                    }\n                }\n            }\n\n            if best_delta_v > 0 {\n                *current_value += best_delta_v;\n\n                match best_move.unwrap() {\n                    LS_Move::Add(i) => {\n                        is_selected[i] = true;\n                        *current_weight += weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] += interactions[i][k] as i64;\n                        }\n                    }\n                    LS_Move::Remove(j) => {\n                        is_selected[j] = false;\n                        *current_weight -= weights[j];\n                        for k in 0..num_items {\n                            marginal_gains[k] -= interactions[j][k] as i64;\n                        }\n                    }\n                    LS_Move::Swap(j, i) => {\n                        is_selected[j] = false;\n                        is_selected[i] = true;\n                        *current_weight = *current_weight - weights[j] + weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] = marginal_gains[k] - interactions[j][k] as i64 + interactions[i][k] as i64;\n                        }\n                    }\n                }\n            } else {\n                break; // Local optimum reached\n            }\n        }\n    };\n\n\n\n    // --- 1. Initial Greedy Construction Phase (O(N^2)) ---\n    loop {\n        let mut best_item: Option<usize> = None;\n        let mut best_density: f64 = f64::NEG_INFINITY;\n\n        for i in 0..num_items {\n            if !is_selected[i] {\n                let item_weight = weights[i];\n                if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                    let gain = marginal_gains[i];\n                    \n                    let density = if item_weight == 0 {\n                        if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                    } else {\n                        gain as f64 / item_weight as f64\n                    };\n\n                    if density > best_density {\n                        best_density = density;\n                        best_item = Some(i);\n                    }\n                }\n            }\n        }\n\n        if let Some(idx_to_add) = best_item {\n            // Update value incrementally\n            current_value += marginal_gains[idx_to_add]; \n            \n            is_selected[idx_to_add] = true;\n            current_weight += weights[idx_to_add];\n\n            // Update marginal gains for ALL items (O(N) step). \n            for i in 0..num_items {\n                marginal_gains[i] += interactions[idx_to_add][i] as i64;\n            }\n        } else {\n            break;\n        }\n    }\n    \n    // Initialize best solution tracking (current_value is already correct)\n    best_value = current_value;\n    best_solution = is_selected.clone();\n\n    // --- 2. Iterated Local Search (ILS) ---\n    for restart in 0..hyperparameters.max_restarts {\n        \n        // A. Run BILS on the current state until local optimum is reached\n        run_bils(&mut is_selected, &mut current_weight, &mut marginal_gains, &mut current_value);\n\n        // B. Update Best Solution\n        if current_value > best_value {\n            best_value = current_value;\n            best_solution = is_selected.clone();\n        }\n\n        if restart == hyperparameters.max_restarts - 1 {\n            break; // No need to perturb after the last optimization run\n        }\n\n        // C. Perturbation Phase (Biased removal + Incremental Repair)\n        let mut selected_indices: Vec<usize> = (0..num_items).filter(|&i| is_selected[i]).collect();\n        let num_selected = selected_indices.len();\n        \n        let p_size = hyperparameters.perturbation_size.min(num_selected);\n        \n        // 1. & 2. Biasedly remove P_size items and update state incrementally (O(P*N))\n        for _ in 0..p_size {\n            if selected_indices.is_empty() { break; }\n\n            // Calculate MG_max for normalization (O(N_selected))\n            let mg_max = selected_indices.iter()\n                .map(|&i| marginal_gains[i])\n                .max()\n                .unwrap_or(1); \n\n            // Calculate weights: S_j = MG_max - MG_j + 1 (Bias towards low MG items)\n            let mut total_weight = 0i64;\n            let weights_and_indices: Vec<(i64, usize)> = selected_indices.iter().map(|&j| {\n                // Ensure weight is positive and non-zero. \n                let weight = mg_max - marginal_gains[j] + 1; \n                total_weight += weight;\n                (weight, j)\n            }).collect();\n\n            // Select item j using roulette wheel selection (O(N_selected))\n            let target = rng.gen_range(0..total_weight);\n            let mut cumulative_weight = 0i64;\n            \n            let mut removal_index_in_vec = 0; // Index in selected_indices vector\n            \n            for (idx, &(weight, _)) in weights_and_indices.iter().enumerate() {\n                cumulative_weight += weight;\n                if cumulative_weight > target {\n                    removal_index_in_vec = idx;\n                    break;\n                }\n            }\n            \n            // Retrieve item index j and remove it from selected_indices (O(1) using swap_remove)\n            let j = selected_indices.swap_remove(removal_index_in_vec);\n\n            // Update value incrementally using the current marginal gain\n            current_value -= marginal_gains[j];\n            \n            is_selected[j] = false;\n            current_weight -= weights[j];\n\n            // Update marginal gains for all other items due to j's removal (O(N))\n            for k in 0..num_items {\n                marginal_gains[k] -= interactions[j][k] as i64;\n            }\n        }\n\n        // 3. Greedy Repair (Add items back based on marginal density)\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_density: f64 = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = weights[i];\n                    if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                        let gain = marginal_gains[i];\n                        \n                        let density = if item_weight == 0 {\n                            if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                        } else {\n                            gain as f64 / item_weight as f64\n                        };\n\n                        if density > best_density {\n                            best_density = density;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(idx_to_add) = best_item {\n                is_selected[idx_to_add] = true;\n                current_weight += weights[idx_to_add];\n                current_value += marginal_gains[idx_to_add]; // Update value incrementally\n\n                // Update marginal gains for ALL items (O(N) step). \n                for i in 0..num_items {\n                    marginal_gains[i] += interactions[idx_to_add][i] as i64;\n                }\n            } else {\n                break;\n            }\n        }\n    }\n\n    // Finalize solution indices from the best solution found\n    let selected: Vec<usize> = (0..num_items).filter(|&i| best_solution[i]).collect();\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}\n```\nUnique approach: Alternative avg_btb approach, Excellent eval_time (4.030), Excellent memory (371200.000)\n\n# Current Program\n```rust\n// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub max_restarts: usize,\n        pub base_perturbation_size: usize,\n        pub stagnation_limit: usize,\n        pub perturbation_increase_factor: f64,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .unwrap_or(Hyperparameters {\n                    max_restarts: 250, // Reverting to proven value\n                    base_perturbation_size: 20,\n                    stagnation_limit: 30, // Reverting to proven value\n                    perturbation_increase_factor: 1.25,\n                })\n        }\n        None => Hyperparameters {\n            max_restarts: 250,\n            base_perturbation_size: 20,\n            stagnation_limit: 30,\n            perturbation_increase_factor: 1.25,\n        },\n    };\n\n    let num_items = challenge.values.len();\n    let weights = &challenge.weights;\n    let values = &challenge.values;\n    let interactions = &challenge.interaction_values;\n    let max_weight = challenge.max_weight;\n\n    let mut rng = SmallRng::from_seed(challenge.seed);\n\n    // --- State Variables (Current Solution) ---\n    let mut is_selected = vec![false; num_items];\n    let mut current_weight: u32 = 0;\n    // marginal_gains[i] = values[i] + sum(interactions[i][j]) for all j currently selected.\n    let mut marginal_gains: Vec<i64> = values.iter().map(|&v| v as i64).collect();\n    let mut current_value: i64 = 0;\n\n    // --- Best Solution Tracking ---\n    let mut best_solution = vec![false; num_items];\n    let mut best_value = i64::MIN;\n\n    #[derive(Debug, Clone, Copy)]\n    enum LS_Move {\n        Add(usize),\n        Remove(usize),\n        Swap(usize, usize), // (item_to_remove, item_to_add)\n    }\n    \n\n\n    // Helper function to run Best Improvement Local Search (BILS) until convergence\n    // Modifies state variables in place.\n    let mut run_bils = |\n        is_selected: &mut Vec<bool>,\n        current_weight: &mut u32,\n        marginal_gains: &mut Vec<i64>,\n        current_value: &mut i64\n    | {\n        loop {\n            let mut best_delta_v = 0i64;\n            let mut best_move: Option<LS_Move> = None;\n\n            // O(N^2) neighborhood search\n            for j in 0..num_items {\n                if is_selected[j] {\n                    // Item j is selected: Check Remove and Swap moves involving j\n\n                    // --- Remove Move (j out) ---\n                    let delta_v_remove_j = -marginal_gains[j];\n                    if delta_v_remove_j > best_delta_v {\n                        best_delta_v = delta_v_remove_j;\n                        best_move = Some(LS_Move::Remove(j));\n                    }\n\n                    // --- Swap Moves (j out, i in) ---\n                    let w_j = weights[j];\n                    \n                    for i in 0..num_items {\n                        if !is_selected[i] {\n                            let w_i = weights[i];\n                            \n                            // Check weight constraint for swap\n                            let delta_w = w_i as i64 - w_j as i64;\n                            if (*current_weight as i64 + delta_w) <= max_weight as i64 {\n                                \n                                // Delta V(j out, i in) = MG[i] - interactions[i][j] - MG[j]\n                                let delta_v_swap = marginal_gains[i] - interactions[i][j] as i64 - marginal_gains[j];\n\n                                if delta_v_swap > best_delta_v {\n                                    best_delta_v = delta_v_swap;\n                                    best_move = Some(LS_Move::Swap(j, i));\n                                }\n                            }\n                        }\n                    }\n                } else {\n                    // Item i is unselected: Check Add moves\n                    let i = j;\n                    let w_i = weights[i];\n\n                    // --- Add Move (i in) ---\n                    if current_weight.checked_add(w_i).map_or(false, |w| w <= max_weight) {\n                        let delta_v_add_i = marginal_gains[i];\n\n                        if delta_v_add_i > best_delta_v {\n                            best_delta_v = delta_v_add_i;\n                            best_move = Some(LS_Move::Add(i));\n                        }\n                    }\n                }\n            }\n\n            if best_delta_v > 0 {\n                *current_value += best_delta_v;\n\n                match best_move.unwrap() {\n                    LS_Move::Add(i) => {\n                        is_selected[i] = true;\n                        *current_weight += weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] += interactions[i][k] as i64;\n                        }\n                    }\n                    LS_Move::Remove(j) => {\n                        is_selected[j] = false;\n                        *current_weight -= weights[j];\n                        for k in 0..num_items {\n                            marginal_gains[k] -= interactions[j][k] as i64;\n                        }\n                    }\n                    LS_Move::Swap(j, i) => {\n                        is_selected[j] = false;\n                        is_selected[i] = true;\n                        *current_weight = *current_weight - weights[j] + weights[i];\n                        for k in 0..num_items {\n                            marginal_gains[k] = marginal_gains[k] - interactions[j][k] as i64 + interactions[i][k] as i64;\n                        }\n                    }\n                }\n            } else {\n                break; // Local optimum reached\n            }\n        }\n    };\n\n    // --- 1. Initial Greedy Construction Phase (O(N^2)) ---\n    loop {\n        let mut best_item: Option<usize> = None;\n        let mut best_density: f64 = f64::NEG_INFINITY;\n\n        for i in 0..num_items {\n            if !is_selected[i] {\n                let item_weight = weights[i];\n                if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                    let gain = marginal_gains[i];\n                    \n                    let density = if item_weight == 0 {\n                        if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                    } else {\n                        gain as f64 / item_weight as f64\n                    };\n\n                    if density > best_density {\n                        best_density = density;\n                        best_item = Some(i);\n                    }\n                }\n            }\n        }\n\n        if let Some(idx_to_add) = best_item {\n            // Update value incrementally\n            current_value += marginal_gains[idx_to_add]; \n            \n            is_selected[idx_to_add] = true;\n            current_weight += weights[idx_to_add];\n\n            // Update marginal gains for ALL items (O(N) step). \n            for i in 0..num_items {\n                marginal_gains[i] += interactions[idx_to_add][i] as i64;\n            }\n        } else {\n            break;\n        }\n    }\n    \n    // Initialize best solution tracking (current_value is already correct)\n    best_value = current_value;\n    best_solution = is_selected.clone();\n\n    // --- 2. Iterated Local Search (ILS) with Adaptive Perturbation ---\n    let mut iterations_since_best_update = 0;\n    let mut dynamic_perturbation_size = hyperparameters.base_perturbation_size;\n\n    for restart in 0..hyperparameters.max_restarts {\n        \n        // A. Run BILS on the current state until local optimum is reached\n        run_bils(&mut is_selected, &mut current_weight, &mut marginal_gains, &mut current_value);\n\n        // B. Update Best Solution and adapt perturbation strength\n        if current_value > best_value {\n            best_value = current_value;\n            best_solution = is_selected.clone();\n            iterations_since_best_update = 0;\n            // On improvement, reset perturbation strength to base to focus search locally\n            dynamic_perturbation_size = hyperparameters.base_perturbation_size;\n        } else {\n            iterations_since_best_update += 1;\n        }\n\n        if iterations_since_best_update >= hyperparameters.stagnation_limit {\n            // Stagnation detected: increase perturbation strength to escape\n            dynamic_perturbation_size = (dynamic_perturbation_size as f64 * hyperparameters.perturbation_increase_factor).round() as usize;\n            // Cap the size to avoid destroying the solution completely\n            let max_p_size = (num_items as f64 * 0.4) as usize; // Don't remove more than 40% of items\n            dynamic_perturbation_size = dynamic_perturbation_size.min(max_p_size);\n            iterations_since_best_update = 0; // Reset counter after strengthening\n        }\n\n        if restart == hyperparameters.max_restarts - 1 {\n            break; // No need to perturb after the last optimization run\n        }\n\n        // C. Perturbation Phase (Biased removal + Incremental Repair)\n        let mut selected_indices: Vec<usize> = (0..num_items).filter(|&i| is_selected[i]).collect();\n        let num_selected = selected_indices.len();\n        \n        let p_size = dynamic_perturbation_size.min(num_selected);\n        \n        // 1. & 2. Biasedly remove P_size items and update state incrementally (O(P*N))\n        for _ in 0..p_size {\n            if selected_indices.is_empty() { break; }\n\n            // Calculate MG_max for normalization (O(N_selected))\n            let mg_max = selected_indices.iter()\n                .map(|&i| marginal_gains[i])\n                .max()\n                .unwrap_or(1); \n\n            // Calculate weights: S_j = MG_max - MG_j + 1 (Bias towards low MG items)\n            let mut total_weight = 0i64;\n            let weights_and_indices: Vec<(i64, usize)> = selected_indices.iter().map(|&j| {\n                // Ensure weight is positive and non-zero. \n                let weight = mg_max - marginal_gains[j] + 1; \n                total_weight += weight;\n                (weight, j)\n            }).collect();\n\n            // Select item j using roulette wheel selection (O(N_selected))\n            let target = rng.gen_range(0..total_weight);\n            let mut cumulative_weight = 0i64;\n            \n            let mut removal_index_in_vec = 0; // Index in selected_indices vector\n            \n            for (idx, &(weight, _)) in weights_and_indices.iter().enumerate() {\n                cumulative_weight += weight;\n                if cumulative_weight > target {\n                    removal_index_in_vec = idx;\n                    break;\n                }\n            }\n            \n            // Retrieve item index j and remove it from selected_indices (O(1) using swap_remove)\n            let j = selected_indices.swap_remove(removal_index_in_vec);\n\n            // Update value incrementally using the current marginal gain\n            current_value -= marginal_gains[j];\n            \n            is_selected[j] = false;\n            current_weight -= weights[j];\n\n            // Update marginal gains for all other items due to j's removal (O(N))\n            for k in 0..num_items {\n                marginal_gains[k] -= interactions[j][k] as i64;\n            }\n        }\n\n        // 3. Greedy Repair (Add items back based on marginal density)\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_density: f64 = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = weights[i];\n                    if current_weight.checked_add(item_weight).map_or(false, |w| w <= max_weight) {\n                        let gain = marginal_gains[i];\n                        \n                        let density = if item_weight == 0 {\n                            if gain > 0 { f64::INFINITY } else { f64::NEG_INFINITY }\n                        } else {\n                            gain as f64 / item_weight as f64\n                        };\n\n                        if density > best_density {\n                            best_density = density;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(idx_to_add) = best_item {\n                is_selected[idx_to_add] = true;\n                current_weight += weights[idx_to_add];\n                current_value += marginal_gains[idx_to_add]; // Update value incrementally\n\n                // Update marginal gains for ALL items (O(N) step). \n                for i in 0..num_items {\n                    marginal_gains[i] += interactions[idx_to_add][i] as i64;\n                }\n            } else {\n                break;\n            }\n        }\n    }\n\n    // Finalize solution indices from the best solution found\n    let selected: Vec<usize> = (0..num_items).filter(|&i| best_solution[i]).collect();\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: score, complexity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["<<<<<<< SEARCH\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .unwrap_or(Hyperparameters {\n                    max_restarts: 250, // Reverting to proven value\n                    base_perturbation_size: 20,\n                    stagnation_limit: 30, // Reverting to proven value\n                    perturbation_increase_factor: 1.25,\n                })\n        }\n        None => Hyperparameters {\n            max_restarts: 250,\n            base_perturbation_size: 20,\n            stagnation_limit: 30,\n            perturbation_increase_factor: 1.25,\n        },\n    };\n=======\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .unwrap_or(Hyperparameters {\n                    max_restarts: 500, // Increased restarts for deeper exploration\n                    base_perturbation_size: 25, // Slightly larger base perturbation\n                    stagnation_limit: 40, // Increased limit to allow more local searching before drastic change\n                    perturbation_increase_factor: 1.2, // Slightly reduced factor for smoother adaptation\n                })\n        }\n        None => Hyperparameters {\n            max_restarts: 500,\n            base_perturbation_size: 25,\n            stagnation_limit: 40,\n            perturbation_increase_factor: 1.2,\n        },\n    };\n>>>>>>> REPLACE"]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}