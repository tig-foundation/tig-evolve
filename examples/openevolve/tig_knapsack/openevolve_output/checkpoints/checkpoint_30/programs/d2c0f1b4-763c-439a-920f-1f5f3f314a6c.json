{"id": "d2c0f1b4-763c-439a-920f-1f5f3f314a6c", "code": "// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    let num_items = challenge.values.len();\n\n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub tabu_iterations: usize,\n        pub tabu_tenure: usize,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .map_err(|e| anyhow!(\"Failed to parse hyperparameters: {}\", e))?\n        }\n        None => Hyperparameters {\n            tabu_iterations: 2500,\n            // A dynamic tenure based on problem size often works well.\n            tabu_tenure: ((num_items as f64).sqrt().round() as usize).max(5),\n        },\n    };\n\n    // Phase 1: Iterative greedy construction heuristic.\n    // At each step, it adds the item with the highest marginal gain-to-weight ratio.\n    let mut selected = Vec::new();\n\n    if num_items > 0 {\n        let mut total_weight: u32 = 0;\n        let mut is_selected = vec![false; num_items];\n        let mut marginal_gains: Vec<f64> = challenge.values.iter().map(|&v| v as f64).collect();\n\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_ratio = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = challenge.weights[i];\n                    if total_weight + item_weight <= challenge.max_weight {\n                        let ratio = if item_weight > 0 {\n                            marginal_gains[i] / item_weight as f64\n                        } else {\n                            if marginal_gains[i] > 0.0 {\n                                f64::INFINITY\n                            } else {\n                                f64::NEG_INFINITY\n                            }\n                        };\n\n                        if ratio > best_ratio {\n                            best_ratio = ratio;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(item_to_add) = best_item {\n                selected.push(item_to_add);\n                is_selected[item_to_add] = true;\n                total_weight += challenge.weights[item_to_add];\n\n                for i in 0..num_items {\n                    if !is_selected[i] {\n                        marginal_gains[i] += challenge.interaction_values[item_to_add][i] as f64;\n                    }\n                }\n            } else {\n                break;\n            }\n        }\n\n        // Phase 2: Local search (1-opt swap) to improve the greedy solution.\n        // This phase iterates and performs the best possible swap (one item in, one item out)\n        // until no further improvements can be made.\n        if !selected.is_empty() {\n            let mut interaction_sums = vec![0i64; num_items];\n            for i in 0..num_items {\n                for &k in &selected {\n                    interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                }\n            }\n\n            loop {\n                let mut improvement_found = false;\n                let mut best_swap: Option<(usize, usize, i64)> = None; // (selected_vec_idx, item_j_idx, delta_value)\n\n                // Best-improvement strategy: find the best possible swap in the entire 1-opt neighborhood.\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx];\n                    for item_j in 0..num_items {\n                        if is_selected[item_j] { continue; }\n\n                        let delta_weight = challenge.weights[item_j] as i64 - challenge.weights[item_i] as i64;\n                        if (total_weight as i64 + delta_weight) > challenge.max_weight as i64 {\n                            continue;\n                        }\n\n                        let delta_value = (challenge.values[item_j] as i64 - challenge.values[item_i] as i64)\n                                        + (interaction_sums[item_j] - challenge.interaction_values[item_j][item_i] as i64)\n                                        - interaction_sums[item_i];\n\n                        if delta_value > 0 {\n                            if best_swap.is_none() || delta_value > best_swap.unwrap().2 {\n                                best_swap = Some((i_vec_idx, item_j, delta_value));\n                            }\n                        }\n                    }\n                }\n\n                if let Some((i_vec_idx_to_swap, item_j_to_swap, _)) = best_swap {\n                    let item_i_to_swap = selected[i_vec_idx_to_swap];\n\n                    let delta_weight = challenge.weights[item_j_to_swap] as i64 - challenge.weights[item_i_to_swap] as i64;\n                    total_weight = (total_weight as i64 + delta_weight) as u32;\n                    is_selected[item_i_to_swap] = false;\n                    is_selected[item_j_to_swap] = true;\n                    selected[i_vec_idx_to_swap] = item_j_to_swap;\n\n                    // Update interaction_sums efficiently in O(N).\n                    for k in 0..num_items {\n                        interaction_sums[k] += (challenge.interaction_values[k][item_j_to_swap] - challenge.interaction_values[k][item_i_to_swap]) as i64;\n                    }\n                    improvement_found = true;\n                }\n\n                if !improvement_found {\n                    break; // Local optimum reached.\n                }\n            }\n        }\n    }\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}", "language": "rust", "parent_id": "c8ffa6ef-4ae8-48d4-90b9-b6c734d9f707", "generation": 3, "timestamp": 1766142981.6378255, "iteration_found": 17, "metrics": {"avg_btb": 0.00065841, "combined_score": 0.3252870166533226, "eval_time": 0.323225979, "memory": 371200.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 8 lines with 22 lines\nChange 2: Replace 59 lines with 86 lines", "parent_metrics": {"avg_btb": 0.00065841, "combined_score": 0.3252870166533226, "eval_time": 0.30749331, "memory": 371200.0}, "island": 2}, "prompts": {"diff_user": {"system": "SETTING:\nYou are an expert Rust programmer specializing in combinatorial optimization algorithms with deep expertise in knapsack problems, resource allocation algorithms, and constraint satisfaction.\nYour mission is to evolve and optimize a quadratic knapsack algorithm that outputs the highest quality possible.\n\n\n=== CRITICAL OUTPUT FORMAT RULES ===\n1. Output ONLY raw Rust source code\n2. Include the complete file from first line to last line\n=== END OUTPUT FORMAT RULES ===\n\nAlgorithm Improvement Instructions:\n\nObjective\nImprove the knapsack algorithm to maximize the total value while respecting the weight constraint.\n\nCRITICAL Constraints\n- You may ONLY modify code between // EVOLVE-BLOCK-START and // EVOLVE-BLOCK-END\n- Code outside these markers (imports, function wrapper, save_solution call) must NEVER be modified\n- You MUST NOT modify the function signature\n- You MUST NOT modify lines before // EVOLVE-BLOCK-START\n- You MUST NOT modify lines after // EVOLVE-BLOCK-END\n- You MUST preserve the exact structure of code outside the evolve block\n\nInput: challenge parameter (type: &Challenge)\n\nThe challenge parameter provides access to the following fields with these EXPLICIT types:\n\n- challenge.seed: [u8; 32] - Fixed-size array of 32 bytes for seeding random number generators\n- challenge.weights: Vec<u32> - Vector of unsigned 32-bit integers representing each item's weight\n- challenge.values: Vec<u32> - Vector of unsigned 32-bit integers representing each item's base value\n- challenge.interaction_values: Vec<Vec<i32>> - 2D matrix (vector of vectors) of SIGNED 32-bit integers\n  - interaction_values[i][j] gives the bonus value when items i and j are BOTH selected\n  - This matrix is symmetric: interaction_values[i][j] == interaction_values[j][i]\n  - Diagonal is zero: interaction_values[i][i] == 0\n- challenge.max_weight: u32 - Unsigned 32-bit integer representing maximum total weight allowed\n  \nImportant notes:\n- All vectors have the same length (number of items)\n- challenge.weights.len() = challenge.values.len() = challenge.interaction_values.len()\n- Item indices are 0 to n-1 where n = challenge.values.len()\n- the structure of the algorithm i.e. the inputs and outputs are fixed, you can only modify the body of the algorithm.\n\nOutput: selected variable (type: Vec<usize>)\n\nYour code must create a variable named selected with the following specification:\n\n- Type: Vec<usize> (vector of unsigned size integers)\n- Content: Indices of items to include in the knapsack solution\n- Valid range: Each element must be in range [0, n-1] where n = challenge.values.len()\n- No duplicates: Each item index can appear at most once\n- Weight constraint: The sum of challenge.weights[i] for all i in selected must be \u2264 challenge.max_weight\n\nThe selected variable is automatically saved after the evolve block ends.\n\nContext:\n- This is a QUADRATIC knapsack problem with interaction values between items\n- Items have: weights, values, and interaction_values (2D matrix)\n- Total value = sum of item values + sum of interaction values for pairs of selected items\n- Constraint: total weight must not exceed max_weight which is half the weight of all items\n- The \"density\" of the knapsack is 25% - meaning interaction values in the symmetric interaction matrix are 0 with probability 0.75; otherwise a random number between 1 and 100.\n\nBENCHMARK:\n- Beat the state-of-the-art result of avg_btb = 0.0015.\n\nHyperparameters (Optional):\nIf your algorithm uses tunable parameters (e.g., iteration counts, thresholds, probabilities),\nyou can define them inside the EVOLVE-BLOCK. Follow these examples exactly.\n\nCRITICAL: The examples below show raw Rust code. Do NOT wrap them in markdown code fences.\n\n\nStep 1 - Define a Hyperparameters struct inside the EVOLVE-BLOCK:\n\n#[derive(Serialize, Deserialize)]\npub struct Hyperparameters {\n    pub max_iterations: usize,\n    pub temperature: f64,\n}\n\nStep 2 - Parse hyperparameters at the start of your code block:\n\nlet hyperparameters = match _hyperparameters {\n    Some(params) => {\n        serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n            .map_err(|e| anyhow!(\"Failed to parse hyperparameters: {}\", e))?\n    }\n    None => Hyperparameters {\n        max_iterations: 100,\n        temperature: 0.95,\n    },\n};\n\nStep 3 - Use the hyperparameter values in your algorithm:\n\nfor _ in 0..hyperparameters.max_iterations {\n    // your algorithm logic here\n}\n\n\nRandom numbers:\nIf you need random numbers, recommend using SmallRng with challenge.seed:\nlet mut rng = SmallRng::from_seed(challenge.seed);\n\nMake sure you use\n- Optimised sorting strategies \n- Efficient data structures for tracking selected items\n\nImportant:\n- Only modify code within the EVOLVE-BLOCK\n- Ensure the algorithm terminates within reasonable time\n- Use the provided Challenge struct fields: values, weights, interaction_values, max_weight\n- The variable selected is automatically saved after the evolve block ends\n\nPERFORMANCE METRICS:\n1. **avg_btb**: Average better than baseline; average percentage that the total value of the knapsack solution is better than a baseline value (PRIMARY OBJECTIVE - maximize)\n2. **combined_score**: progress toward beating the state-of-the-art benchmark\n3. **eval_time**: Execution time in seconds (keep reasonable, prefer accuracy over speed)\n4. **memory**: Memory usage in kilobytes (keep reasonable, prefer accuracy over speed)\n\nTECHNICAL REQUIREMENTS:\n- **Error handling**: Graceful handling of optimization failures or infeasible configurations\n- **Memory efficiency**: Avoid excessive memory allocation for matrix computations\n", "user": "# Current Program Information\n- Fitness: 0.3253\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness unchanged at 0.3253\n- Consider simplifying - code length exceeds 2000 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 1\n- Changes: Unknown changes\n- Metrics: avg_btb: 0.0007, combined_score: 0.3253, eval_time: 0.3075, memory: 371200.0000\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.3253)\n```rust\n// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        // Optionally define hyperparameters here\n    }\n\n    // Phase 1: Iterative greedy construction heuristic.\n    // At each step, it adds the item with the highest marginal gain-to-weight ratio.\n    let num_items = challenge.values.len();\n    let mut selected = Vec::new();\n\n    if num_items > 0 {\n        let mut total_weight: u32 = 0;\n        let mut is_selected = vec![false; num_items];\n        let mut marginal_gains: Vec<f64> = challenge.values.iter().map(|&v| v as f64).collect();\n\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_ratio = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = challenge.weights[i];\n                    if total_weight + item_weight <= challenge.max_weight {\n                        let ratio = if item_weight > 0 {\n                            marginal_gains[i] / item_weight as f64\n                        } else {\n                            if marginal_gains[i] > 0.0 {\n                                f64::INFINITY\n                            } else {\n                                f64::NEG_INFINITY\n                            }\n                        };\n\n                        if ratio > best_ratio {\n                            best_ratio = ratio;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(item_to_add) = best_item {\n                selected.push(item_to_add);\n                is_selected[item_to_add] = true;\n                total_weight += challenge.weights[item_to_add];\n\n                for i in 0..num_items {\n                    if !is_selected[i] {\n                        marginal_gains[i] += challenge.interaction_values[item_to_add][i] as f64;\n                    }\n                }\n            } else {\n                break;\n            }\n        }\n\n        // Phase 2: Local search (1-opt swap) to improve the greedy solution.\n        // This phase iterates and performs the best possible swap (one item in, one item out)\n        // until no further improvements can be made.\n        if !selected.is_empty() {\n            let mut interaction_sums = vec![0i64; num_items];\n            for i in 0..num_items {\n                for &k in &selected {\n                    interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                }\n            }\n\n            loop {\n                let mut improvement_found = false;\n                let mut best_swap: Option<(usize, usize, i64)> = None; // (selected_vec_idx, item_j_idx, delta_value)\n\n                // Best-improvement strategy: find the best possible swap in the entire 1-opt neighborhood.\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx];\n                    for item_j in 0..num_items {\n                        if is_selected[item_j] { continue; }\n\n                        let delta_weight = challenge.weights[item_j] as i64 - challenge.weights[item_i] as i64;\n                        if (total_weight as i64 + delta_weight) > challenge.max_weight as i64 {\n                            continue;\n                        }\n\n                        let delta_value = (challenge.values[item_j] as i64 - challenge.values[item_i] as i64)\n                                        + (interaction_sums[item_j] - challenge.interaction_values[item_j][item_i] as i64)\n                                        - interaction_sums[item_i];\n\n                        if delta_value > 0 {\n                            if best_swap.is_none() || delta_value > best_swap.unwrap().2 {\n                                best_swap = Some((i_vec_idx, item_j, delta_value));\n                            }\n                        }\n                    }\n                }\n\n                if let Some((i_vec_idx_to_swap, item_j_to_swap, _)) = best_swap {\n                    let item_i_to_swap = selected[i_vec_idx_to_swap];\n\n                    let delta_weight = challenge.weights[item_j_to_swap] as i64 - challenge.weights[item_i_to_swap] as i64;\n                    total_weight = (total_weight as i64 + delta_weight) as u32;\n                    is_selected[item_i_to_swap] = false;\n                    is_selected[item_j_to_swap] = true;\n                    selected[i_vec_idx_to_swap] = item_j_to_swap;\n\n                    // Update interaction_sums efficiently in O(N).\n                    for k in 0..num_items {\n                        interaction_sums[k] += (challenge.interaction_values[k][item_j_to_swap] - challenge.interaction_values[k][item_i_to_swap]) as i64;\n                    }\n                    improvement_found = true;\n                }\n\n                if !improvement_found {\n                    break; // Local optimum reached.\n                }\n            }\n        }\n    }\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}\n```\nKey features: Performs well on avg_btb (0.0007), Performs well on combined_score (0.3253), Performs well on eval_time (0.3075), Performs well on memory (371200.0000)\n\n\n\n# Current Program\n```rust\n// DO NOT CHANGE THESE IMPORTS\nuse crate::challenge::{Challenge, Solution};\nuse anyhow::{anyhow, Result};\nuse serde::{Deserialize, Serialize};\nuse serde_json::{Map, Value};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\npub fn solve_challenge(\n    challenge: &Challenge,\n    save_solution: &dyn Fn(&Solution) -> Result<()>,\n    _hyperparameters: &Option<Map<String, Value>>,\n) -> Result<()> {\n    // EVOLVE-BLOCK-START    \n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        // Optionally define hyperparameters here\n    }\n\n    // Phase 1: Iterative greedy construction heuristic.\n    // At each step, it adds the item with the highest marginal gain-to-weight ratio.\n    let num_items = challenge.values.len();\n    let mut selected = Vec::new();\n\n    if num_items > 0 {\n        let mut total_weight: u32 = 0;\n        let mut is_selected = vec![false; num_items];\n        let mut marginal_gains: Vec<f64> = challenge.values.iter().map(|&v| v as f64).collect();\n\n        loop {\n            let mut best_item: Option<usize> = None;\n            let mut best_ratio = f64::NEG_INFINITY;\n\n            for i in 0..num_items {\n                if !is_selected[i] {\n                    let item_weight = challenge.weights[i];\n                    if total_weight + item_weight <= challenge.max_weight {\n                        let ratio = if item_weight > 0 {\n                            marginal_gains[i] / item_weight as f64\n                        } else {\n                            if marginal_gains[i] > 0.0 {\n                                f64::INFINITY\n                            } else {\n                                f64::NEG_INFINITY\n                            }\n                        };\n\n                        if ratio > best_ratio {\n                            best_ratio = ratio;\n                            best_item = Some(i);\n                        }\n                    }\n                }\n            }\n\n            if let Some(item_to_add) = best_item {\n                selected.push(item_to_add);\n                is_selected[item_to_add] = true;\n                total_weight += challenge.weights[item_to_add];\n\n                for i in 0..num_items {\n                    if !is_selected[i] {\n                        marginal_gains[i] += challenge.interaction_values[item_to_add][i] as f64;\n                    }\n                }\n            } else {\n                break;\n            }\n        }\n\n        // Phase 2: Local search (1-opt swap) to improve the greedy solution.\n        // This phase iterates and performs the best possible swap (one item in, one item out)\n        // until no further improvements can be made.\n        if !selected.is_empty() {\n            let mut interaction_sums = vec![0i64; num_items];\n            for i in 0..num_items {\n                for &k in &selected {\n                    interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                }\n            }\n\n            loop {\n                let mut improvement_found = false;\n                let mut best_swap: Option<(usize, usize, i64)> = None; // (selected_vec_idx, item_j_idx, delta_value)\n\n                // Best-improvement strategy: find the best possible swap in the entire 1-opt neighborhood.\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx];\n                    for item_j in 0..num_items {\n                        if is_selected[item_j] { continue; }\n\n                        let delta_weight = challenge.weights[item_j] as i64 - challenge.weights[item_i] as i64;\n                        if (total_weight as i64 + delta_weight) > challenge.max_weight as i64 {\n                            continue;\n                        }\n\n                        let delta_value = (challenge.values[item_j] as i64 - challenge.values[item_i] as i64)\n                                        + (interaction_sums[item_j] - challenge.interaction_values[item_j][item_i] as i64)\n                                        - interaction_sums[item_i];\n\n                        if delta_value > 0 {\n                            if best_swap.is_none() || delta_value > best_swap.unwrap().2 {\n                                best_swap = Some((i_vec_idx, item_j, delta_value));\n                            }\n                        }\n                    }\n                }\n\n                if let Some((i_vec_idx_to_swap, item_j_to_swap, _)) = best_swap {\n                    let item_i_to_swap = selected[i_vec_idx_to_swap];\n\n                    let delta_weight = challenge.weights[item_j_to_swap] as i64 - challenge.weights[item_i_to_swap] as i64;\n                    total_weight = (total_weight as i64 + delta_weight) as u32;\n                    is_selected[item_i_to_swap] = false;\n                    is_selected[item_j_to_swap] = true;\n                    selected[i_vec_idx_to_swap] = item_j_to_swap;\n\n                    // Update interaction_sums efficiently in O(N).\n                    for k in 0..num_items {\n                        interaction_sums[k] += (challenge.interaction_values[k][item_j_to_swap] - challenge.interaction_values[k][item_i_to_swap]) as i64;\n                    }\n                    improvement_found = true;\n                }\n\n                if !improvement_found {\n                    break; // Local optimum reached.\n                }\n            }\n        }\n    }\n    // EVOLVE-BLOCK-END\n    \n    save_solution(&Solution { items: selected })?;\n    Ok(())\n}\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: score, complexity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["This is an excellent starting point. The current algorithm uses a strong greedy construction heuristic followed by a best-improvement local search. Its primary weakness is that it terminates at the first local optimum it finds. To achieve a higher quality solution and surpass the benchmark, we need a strategy to escape these local optima and explore a wider region of the solution space.\n\nMy proposed improvement is to replace the simple hill-climbing local search with **Tabu Search**, a powerful metaheuristic well-suited for combinatorial optimization problems like the Quadratic Knapsack Problem.\n\n### Rationale for Change\n\n1.  **Escaping Local Optima**: Unlike the current local search which only accepts moves that improve the solution's value, Tabu Search can accept non-improving (i.e., \"worse\") moves. This allows the search to traverse valleys in the fitness landscape and escape from local optima to find potentially better regions.\n2.  **Guided Exploration**: To prevent cycling (e.g., swapping an item out and then immediately swapping it back in), Tabu Search maintains a \"tabu list\" of recently performed moves. A move is considered \"tabu\" if it tries to revert a recent change. This forces the algorithm to explore new, unvisited solutions.\n3.  **Aspiration Criterion**: To avoid missing out on excellent solutions, an \"aspiration criterion\" is used. It allows a tabu move if that move leads to a solution better than any found so far during the entire search process.\n4.  **Building on Strength**: This approach retains the effective greedy construction phase for a high-quality starting point and reuses the efficient `O(N)` delta-value calculation and state update logic from the original local search, but embeds it within a more robust search framework.\n\nI will introduce two tunable hyperparameters: `tabu_iterations` to control the search duration and `tabu_tenure` to define how long a move remains tabu. The default tenure will be dynamically calculated based on the problem size, a common and effective practice.\n\nThis change transforms the algorithm from a simple greedy + hill-climbing heuristic into a more sophisticated metaheuristic, significantly increasing its potential to find higher-quality solutions.\n\n<<<<<<< SEARCH\n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        // Optionally define hyperparameters here\n    }\n\n    // Phase 1: Iterative greedy construction heuristic.\n    // At each step, it adds the item with the highest marginal gain-to-weight ratio.\n    let num_items = challenge.values.len();\n=======\n    let num_items = challenge.values.len();\n\n    #[derive(Serialize, Deserialize)]\n    pub struct Hyperparameters {\n        pub tabu_iterations: usize,\n        pub tabu_tenure: usize,\n    }\n\n    let hyperparameters = match _hyperparameters {\n        Some(params) => {\n            serde_json::from_value::<Hyperparameters>(Value::Object(params.clone()))\n                .map_err(|e| anyhow!(\"Failed to parse hyperparameters: {}\", e))?\n        }\n        None => Hyperparameters {\n            tabu_iterations: 2500,\n            // A dynamic tenure based on problem size often works well.\n            tabu_tenure: ((num_items as f64).sqrt().round() as usize).max(5),\n        },\n    };\n\n    // Phase 1: Iterative greedy construction heuristic.\n    // At each step, it adds the item with the highest marginal gain-to-weight ratio.\n>>>>>>> REPLACE\n<<<<<<< SEARCH\n        // Phase 2: Local search (1-opt swap) to improve the greedy solution.\n        // This phase iterates and performs the best possible swap (one item in, one item out)\n        // until no further improvements can be made.\n        if !selected.is_empty() {\n            let mut interaction_sums = vec![0i64; num_items];\n            for i in 0..num_items {\n                for &k in &selected {\n                    interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                }\n            }\n\n            loop {\n                let mut improvement_found = false;\n                let mut best_swap: Option<(usize, usize, i64)> = None; // (selected_vec_idx, item_j_idx, delta_value)\n\n                // Best-improvement strategy: find the best possible swap in the entire 1-opt neighborhood.\n                for i_vec_idx in 0..selected.len() {\n                    let item_i = selected[i_vec_idx];\n                    for item_j in 0..num_items {\n                        if is_selected[item_j] { continue; }\n\n                        let delta_weight = challenge.weights[item_j] as i64 - challenge.weights[item_i] as i64;\n                        if (total_weight as i64 + delta_weight) > challenge.max_weight as i64 {\n                            continue;\n                        }\n\n                        let delta_value = (challenge.values[item_j] as i64 - challenge.values[item_i] as i64)\n                                        + (interaction_sums[item_j] - challenge.interaction_values[item_j][item_i] as i64)\n                                        - interaction_sums[i];\n\n                        if delta_value > 0 {\n                            if best_swap.is_none() || delta_value > best_swap.unwrap().2 {\n                                best_swap = Some((i_vec_idx, item_j, delta_value));\n                            }\n                        }\n                    }\n                }\n\n                if let Some((i_vec_idx_to_swap, item_j_to_swap, _)) = best_swap {\n                    let item_i_to_swap = selected[i_vec_idx_to_swap];\n\n                    let delta_weight = challenge.weights[item_j_to_swap] as i64 - challenge.weights[item_i_to_swap] as i64;\n                    total_weight = (total_weight as i64 + delta_weight) as u32;\n                    is_selected[item_i_to_swap] = false;\n                    is_selected[item_j_to_swap] = true;\n                    selected[i_vec_idx_to_swap] = item_j_to_swap;\n\n                    // Update interaction_sums efficiently in O(N).\n                    for k in 0..num_items {\n                        interaction_sums[k] += (challenge.interaction_values[k][item_j_to_swap] - challenge.interaction_values[k][item_i_to_swap]) as i64;\n                    }\n                    improvement_found = true;\n                }\n\n                if !improvement_found {\n                    break; // Local optimum reached.\n                }\n            }\n        }\n=======\n        // Phase 2: Tabu Search to improve the greedy solution.\n        // This metaheuristic can escape local optima by accepting non-improving moves.\n        if !selected.is_empty() {\n            let mut interaction_sums = vec![0i64; num_items];\n            for i in 0..num_items {\n                for &k in &selected {\n                    interaction_sums[i] += challenge.interaction_values[i][k] as i64;\n                }\n            }\n\n            // Efficiently calculate initial solution value\n            let mut current_value = 0i64;\n            let mut interaction_part = 0i64;\n            for &item in &selected {\n                current_value += challenge.values[item] as i64;\n                interaction_part += interaction_sums[item];\n            }\n            current_value += interaction_part / 2;\n            \n            let mut best_selected = selected.clone();\n            let mut best_value = current_value;\n\n            let mut tabu_list = vec![0usize; num_items]; // Stores iteration when tabu expires\n\n            for iter in 1..=hyperparameters.tabu_iterations {\n                let mut best_move: Option<(usize, usize, i64)> = None; // (selected_vec_idx, item_to_add_idx, delta_value)\n\n                // Find the best move in the 1-opt neighborhood\n                for i_vec_idx in 0..selected.len() {\n                    let item_to_remove = selected[i_vec_idx];\n                    for item_to_add in 0..num_items {\n                        if is_selected[item_to_add] { continue; }\n\n                        let delta_weight = challenge.weights[item_to_add] as i64 - challenge.weights[item_to_remove] as i64;\n                        if (total_weight as i64 + delta_weight) > challenge.max_weight as i64 {\n                            continue;\n                        }\n\n                        let delta_value = (challenge.values[item_to_add] as i64 - challenge.values[item_to_remove] as i64)\n                                        + (interaction_sums[item_to_add] - challenge.interaction_values[item_to_add][item_to_remove] as i64)\n                                        - interaction_sums[item_to_remove];\n\n                        let is_tabu = tabu_list[item_to_add] >= iter;\n                        let is_aspirated = current_value + delta_value > best_value;\n\n                        if !is_tabu || is_aspirated {\n                            if best_move.is_none() || delta_value > best_move.unwrap().2 {\n                                best_move = Some((i_vec_idx, item_to_add, delta_value));\n                            }\n                        }\n                    }\n                }\n\n                // Perform the best move found\n                if let Some((i_vec_idx_to_swap, item_j_to_swap, delta_value)) = best_move {\n                    let item_i_to_swap = selected[i_vec_idx_to_swap];\n\n                    // Update solution state\n                    let delta_weight = challenge.weights[item_j_to_swap] as i64 - challenge.weights[item_i_to_swap] as i64;\n                    total_weight = (total_weight as i64 + delta_weight) as u32;\n                    is_selected[item_i_to_swap] = false;\n                    is_selected[item_j_to_swap] = true;\n                    selected[i_vec_idx_to_swap] = item_j_to_swap;\n                    current_value += delta_value;\n\n                    // Update interaction_sums efficiently\n                    for k in 0..num_items {\n                        interaction_sums[k] += (challenge.interaction_values[k][item_j_to_swap] - challenge.interaction_values[k][item_i_to_swap]) as i64;\n                    }\n                    \n                    // Make the item that was *removed* tabu to be added back in\n                    tabu_list[item_i_to_swap] = iter + hyperparameters.tabu_tenure;\n\n                    // Update best-known solution\n                    if current_value > best_value {\n                        best_value = current_value;\n                        best_selected = selected.clone();\n                    }\n                } else {\n                    // No valid (non-tabu or aspirated) move found, terminate early.\n                    break;\n                }\n            }\n            // The final solution is the best one found during the search\n            selected = best_selected;\n        }\n>>>>>>> REPLACE"]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}