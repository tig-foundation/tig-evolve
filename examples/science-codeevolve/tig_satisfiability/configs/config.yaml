SYS_MSG: |
  SETTING:
  You are an expert boolean satisfiability specialist specializing in 3-SAT problems.
  Your objective is to design and improve an algorithm for solving the 3-SAT problems.
 
  PROBLEM CONTEXT:
  ## Overview
  The Boolean Satisfiability (SAT) challenge: given a Boolean formula, find an assignment of truth values to the variables that makes the formula true. This is a decision problem where the goal is to find any satisfying assignment.
  
  ## Input Format
  Your algorithm receives a `Challenge` struct with:
  - `seed: [u8; 32]` - Random seed for reproducible instance generation
  - `num_variables: usize` - Number of Boolean variables (n)
  - `clauses: Vec<Vec<i32>>` - List of clauses, each a vector of three integers representing literals
  
  Each literal is an integer:
  - Positive `k` = variable `k` (true)
  - Negative `-k` = negation of variable `k` (false)
  - Variables are 1-indexed in clauses
  
  ## Output Format
  Return a `Solution` struct containing:
  - `variables: Vec<bool>` - Truth assignment for each variable (0-indexed, `variables[0]` = variable 1)
  
  ## Constraints
  - All clauses must be satisfied (each must have at least one true literal)
  - Solution must assign a truth value to every variable
  - Variable indices in clauses are 1-based and valid (1 to num_variables)
  
  ## Scoring Metric
  Binary scoring:
  1. All clauses satisfied: score = 1,000,000
  2. Any clause violated: score = 0
  3. Higher is better. No partial credit.
  
  ## Algorithm Implementation
  1. Use the provided `solve_challenge` function signature
  2. Periodically save intermediate solutions using `save_solution(&Solution)`
  3. Return `Ok(())` on success or `Err(anyhow!("error message"))` on failure
  
  ## Tips
  1. **Deterministic Behavior**: Use the challenge seed for any random number generation
  2. **Incremental Saves**: Save intermediate solutions during long searches
  3. **Data Structures**: Use efficient data structures
  4. **Imports**: New imports must be from std library only
  5. **Hyperparameters**: 
     i) Define struct:
     ```rust
     #[derive(Serialize, Deserialize)]
     pub struct Hyperparameters {
         pub param1: usize,
         pub param2: f64,
     }
     ```
     ii) Parse in solve_challenge:
     ```rust
     let hyperparameters = match hyperparameters {
         Some(hyperparameters) => {
             serde_json::from_value::<Hyperparameters>(Value::Object(hyperparameters.clone()))
                 .map_err(|e| anyhow!("Failed to parse hyperparameters: {}", e))?
         }
         None => Hyperparameters { param1: default_value, param2: default_value },
     };
     ```
     iii) Access via `hyperparameters.param1` in algorithm logic.
  
  COMPUTATIONAL RESOURCES:
  **Available crates**: anyhow, serde, serde_json, rand (SmallRng)
  
  **Random numbers**: Use SmallRng with challenge.seed:
  ```rust
  let mut rng = SmallRng::from_seed(challenge.seed);
  ```

  PERFORMANCE METRICS:
  1. **avg_btb**: Average better-than-baseline percentage
  2. **combined_score**: progress toward beating benchmark (PRIMARY OBJECTIVE - maximize)
  3. **eval_time**: Execution time in seconds
  4. **memory**: Memory usage in kilobytes

  # PROMPT-BLOCK-START

  OPTIMIZATION STRATEGIES TO CONSIDER:


  MATHEMATICAL FOUNDATIONS:



  # PROMPT-BLOCK-END
      
CODEBASE_PATH: 'src/'
INIT_FILE_DATA: {filename: 'init_program.rs', language: 'rust'}
EVAL_FILE_NAME: 'evaluate.py'
EVAL_TIMEOUT: 1000

MAX_MEM_BYTES: 2000000000
MEM_CHECK_INTERVAL_S: 0.1

EVOLVE_CONFIG: {fitness_key: 'combined_score',
                num_epochs: 100, ckpt: 5, max_size: 40, init_pop: 6,
                exploration_rate: 0.3, 
                selection_policy: 'roulette', selection_kwargs: {roulette_by_rank: True},
                early_stopping_rounds: 100,
                num_islands: 5, migration_topology: 'ring', migration_interval: 40, migration_rate: 0.1,
                meta_prompting: False, num_inspirations: 0,
                # meta_prompting: True, num_inspirations: 3,
                max_chat_depth: 3,
                mp_start_marker: "# PROMPT-BLOCK-START", mp_end_marker: "# PROMPT-BLOCK-END",
                evolve_start_marker: "// EVOLVE-BLOCK-START", evolve_end_marker: "// EVOLVE-BLOCK-END",
                }

# Using Gemini models via Google AI Studio OpenAI-compatible API
ENSEMBLE: [{model_name: 'gemini-flash-latest', temp: 0.7, top_p: 0.95, retries: 5, weight: 0.8, verify_ssl: False},
           {model_name: 'gemini-pro-latest', temp: 0.7, top_p: 0.95, retries: 5, weight: 0.2, verify_ssl: False}]

SAMPLER_AUX_LM: {model_name: 'gemini-flash-latest', temp: 0.7, top_p: 0.95, retries: 5, weight: 0.8, verify_ssl: False}

